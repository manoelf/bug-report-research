{"comments": {}, "bugs": {"692252": {"comments": [{"id": 5761468, "count": 0, "is_private": false, "author": "netzen@gmail.com", "time": "2011-10-05T20:39:06Z", "creation_time": "2011-10-05T20:39:06Z", "creator": "netzen@gmail.com", "raw_text": "Certain files (maybe places.sqlite?) get fragmented over time.\n\nIt would be good to have the Windows service (or we may not even need the service depending on how we do it) to defrag these files periodically so we have faster startup.\n\nI think we could use this API to do it from the new Windows service component:\nhttp://msdn.microsoft.com/en-us/library/windows/desktop/aa363911(v=vs.85).aspx#defragmenting_a_file\n\nOr perhaps an easy way is to create a new file, allocate it instantly all at once, and then copy the data into it in chunks.\n\nO(1) create a big file:\nCreateFile, SetFilePointerEx, SetEndOfFile, and CloseHandle.", "attachment_id": null, "bug_id": 692252, "text": "Certain files (maybe places.sqlite?) get fragmented over time.\n\nIt would be good to have the Windows service (or we may not even need the service depending on how we do it) to defrag these files periodically so we have faster startup.\n\nI think we could use this API to do it from the new Windows service component:\nhttp://msdn.microsoft.com/en-us/library/windows/desktop/aa363911(v=vs.85).aspx#defragmenting_a_file\n\nOr perhaps an easy way is to create a new file, allocate it instantly all at once, and then copy the data into it in chunks.\n\nO(1) create a big file:\nCreateFile, SetFilePointerEx, SetEndOfFile, and CloseHandle.", "tags": []}, {"attachment_id": null, "raw_text": "As long as we only target our files though I think we can get the same effect by allocating and then writing as the updater does.\nhttp://mxr.mozilla.org/mozilla-central/source/toolkit/mozapps/update/updater/updater.cpp#1320\n\nI'd go with which ever one is safest and if both are safe then fastest.", "bug_id": 692252, "text": "As long as we only target our files though I think we can get the same effect by allocating and then writing as the updater does.\nhttp://mxr.mozilla.org/mozilla-central/source/toolkit/mozapps/update/updater/updater.cpp#1320\n\nI'd go with which ever one is safest and if both are safe then fastest.", "tags": [], "is_private": false, "count": 1, "id": 5761486, "creator": "robert.strong.bugs@gmail.com", "time": "2011-10-05T20:45:57Z", "creation_time": "2011-10-05T20:45:57Z", "author": "robert.strong.bugs@gmail.com"}, {"bug_id": 692252, "text": "Ya that's the same as the second way I mentioned.  I'm not sure if that guarantees it will be sequential on disk (maybe on SetEndOfFile it allocates multiple spots on disk), but probably it is close enough though and a much easier way to implement it.", "tags": [], "raw_text": "Ya that's the same as the second way I mentioned.  I'm not sure if that guarantees it will be sequential on disk (maybe on SetEndOfFile it allocates multiple spots on disk), but probably it is close enough though and a much easier way to implement it.", "attachment_id": null, "author": "netzen@gmail.com", "time": "2011-10-05T20:49:54Z", "creation_time": "2011-10-05T20:49:54Z", "creator": "netzen@gmail.com", "count": 2, "id": 5761501, "is_private": false}, {"author": "robert.strong.bugs@gmail.com", "time": "2011-10-05T20:53:16Z", "creation_time": "2011-10-05T20:53:16Z", "creator": "robert.strong.bugs@gmail.com", "count": 3, "id": 5761512, "is_private": false, "tags": [], "text": "It doesn't gaurantee that it will be sequential but it does allocate sequentially if there is sequential space available on the disk which is not dissimilar to not being able to find sequential space with the defrag method.", "bug_id": 692252, "raw_text": "It doesn't gaurantee that it will be sequential but it does allocate sequentially if there is sequential space available on the disk which is not dissimilar to not being able to find sequential space with the defrag method.", "attachment_id": null}, {"tags": [], "bug_id": 692252, "text": "cool, that should be good enough.", "attachment_id": null, "raw_text": "cool, that should be good enough.", "creator": "netzen@gmail.com", "creation_time": "2011-10-05T20:59:31Z", "time": "2011-10-05T20:59:31Z", "author": "netzen@gmail.com", "is_private": false, "count": 4, "id": 5761533}, {"creator": "taras.mozilla@glek.net", "time": "2011-10-05T21:49:43Z", "creation_time": "2011-10-05T21:49:43Z", "author": "taras.mozilla@glek.net", "is_private": false, "id": 5761749, "count": 5, "text": "This would be of biggest benefit for files in the profile dir and it will result in a more responsive browser, not just faster startup.\n\nRob is right, files installed/updated by us should already not be fragmented. It would be useful to have the service examine which files get most fragmented and report that via telemetry.", "bug_id": 692252, "tags": [], "attachment_id": null, "raw_text": "This would be of biggest benefit for files in the profile dir and it will result in a more responsive browser, not just faster startup.\n\nRob is right, files installed/updated by us should already not be fragmented. It would be useful to have the service examine which files get most fragmented and report that via telemetry."}, {"attachment_id": null, "is_private": false, "id": 5762296, "count": 6, "raw_text": "I'm not sure if places.sqlite gets capped at some size or not but it is 10MB for me currently in my profile.  This is probably the largest file (I may be wrong on what the largest file is). \n\nOne benefit of the first approach (actual file defrag) is that we wouldn't need twice the largest file's disk space and in general there would be less IO when a file is not very fragmented.  \n\nThe second approach though is probably more safe and would ensure no file corruption even if the computer was turned off in the middle of an operation.", "creator": "netzen@gmail.com", "creation_time": "2011-10-06T01:36:01Z", "time": "2011-10-06T01:36:01Z", "author": "netzen@gmail.com", "bug_id": 692252, "text": "I'm not sure if places.sqlite gets capped at some size or not but it is 10MB for me currently in my profile.  This is probably the largest file (I may be wrong on what the largest file is). \n\nOne benefit of the first approach (actual file defrag) is that we wouldn't need twice the largest file's disk space and in general there would be less IO when a file is not very fragmented.  \n\nThe second approach though is probably more safe and would ensure no file corruption even if the computer was turned off in the middle of an operation.", "tags": []}, {"creator": "taras.mozilla@glek.net", "time": "2011-10-06T17:13:53Z", "creation_time": "2011-10-06T17:13:53Z", "author": "taras.mozilla@glek.net", "is_private": false, "id": 5763837, "count": 7, "bug_id": 692252, "text": "I think the size for places is somewhere between 60-100mb(extensions *may* make it bigger). We grow it in 10mb(i think) increments for most people. So it should not fragment to too many pieces, but realistically doing OS-level defrag is the most efficient-way to do this.\n\nThere are also extension-specific databases that likely fragment themselves to death. Thus it would be helpful to do a dumb \"defrag everything in profile directory\" approach.", "tags": [], "attachment_id": null, "raw_text": "I think the size for places is somewhere between 60-100mb(extensions *may* make it bigger). We grow it in 10mb(i think) increments for most people. So it should not fragment to too many pieces, but realistically doing OS-level defrag is the most efficient-way to do this.\n\nThere are also extension-specific databases that likely fragment themselves to death. Thus it would be helpful to do a dumb \"defrag everything in profile directory\" approach."}]}}}