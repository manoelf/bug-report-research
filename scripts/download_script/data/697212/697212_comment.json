{"comments": {}, "bugs": {"697212": {"comments": [{"attachment_id": null, "tags": [], "creator": "stephen.bannasch@gmail.com", "creation_time": "2011-10-25T19:10:02Z", "is_private": false, "raw_text": "User Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_8) AppleWebKit/534.51.22 (KHTML, like Gecko) Version/5.1.1 Safari/534.51.22\n\nSteps to reproduce:\n\nCreated a computational simulation for exploring Self-Organized Criticality.\n\nhttp://stepheneb.github.com/avalanche2d-js/avalanche2d.html\n\nsource: https://github.com/stepheneb/avalanche2d-js\n\nThere are three main parts:\n\n1) A computational engine\n2) A canvas visualization of an array of desks with 0..n folders\n3) A graph that displays the average number of folders per desk for the array.\n\nThis specific simulation is an adaptation of a NetLogo model.\n\nThe point of this research is to understand the performance limitations and capacities for creating and running computational models and visualizations in modern browsers.\u00a0This work has uncovered many useful patterns for writing computationally intensive JavaScript/HTML5 applications..\u00a0It seems clear that modern browsers are a very powerful platform for writing the kinds of applications we used to write in Java.\n\n\n\n\nActual results:\n\nFireFox runs the current simulation at approximately 25% the speed of Chrome 14.\n\nSee benchmark results in the readme here: https://github.com/stepheneb/avalanche2d-js\n\nThe benchmarks report the average number of model-steps/s over a run of 5000 model-steps. The model automatically stops at 5000 model-steps.\n\nThe benchmarks include data for running the model both with and without the Canvas visualization and the real-time grapher.\n\nFireFox 7.0.1 and Nightly are both about 25% ads fast as Chrome.\n\n\nExpected results:\n\nIdeally performance should be similar to Chrome 14.", "time": "2011-10-25T19:10:02Z", "text": "User Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_8) AppleWebKit/534.51.22 (KHTML, like Gecko) Version/5.1.1 Safari/534.51.22\n\nSteps to reproduce:\n\nCreated a computational simulation for exploring Self-Organized Criticality.\n\nhttp://stepheneb.github.com/avalanche2d-js/avalanche2d.html\n\nsource: https://github.com/stepheneb/avalanche2d-js\n\nThere are three main parts:\n\n1) A computational engine\n2) A canvas visualization of an array of desks with 0..n folders\n3) A graph that displays the average number of folders per desk for the array.\n\nThis specific simulation is an adaptation of a NetLogo model.\n\nThe point of this research is to understand the performance limitations and capacities for creating and running computational models and visualizations in modern browsers.\u00a0This work has uncovered many useful patterns for writing computationally intensive JavaScript/HTML5 applications..\u00a0It seems clear that modern browsers are a very powerful platform for writing the kinds of applications we used to write in Java.\n\n\n\n\nActual results:\n\nFireFox runs the current simulation at approximately 25% the speed of Chrome 14.\n\nSee benchmark results in the readme here: https://github.com/stepheneb/avalanche2d-js\n\nThe benchmarks report the average number of model-steps/s over a run of 5000 model-steps. The model automatically stops at 5000 model-steps.\n\nThe benchmarks include data for running the model both with and without the Canvas visualization and the real-time grapher.\n\nFireFox 7.0.1 and Nightly are both about 25% ads fast as Chrome.\n\n\nExpected results:\n\nIdeally performance should be similar to Chrome 14.", "count": 0, "author": "stephen.bannasch@gmail.com", "bug_id": 697212, "id": 5804014}, {"bug_id": 697212, "id": 5804116, "text": "I assume the actual steps to reproduce are to load http://stepheneb.github.com/avalanche2d-js/avalanche2d.html and select the \"Go\" radio button?\n\nIf so, and using the default settings (100x100 desk array size, visualization+graph rendering, Uint8Array), I get numbers like so on Mac OS X 10.6:\n\n  Firefox 7: 2265.5 (steps/s)\n  Current trunk nightly: 5417.1 (steps/s)\n  Chrome dev build (16.x): 7680.5 (steps/s)\n  \nIf I turn off the rendering part, these become:\n\n  Firefox 7: 3043.2 (steps/s)\n  Current trunk nightly: 9124.1 (steps/s)\n  Chrome dev build (16.x): rate: 8741.3 (steps/s)\n\nThough all the numbers are very noisy (about 10% or more noise).\n\nIf I enable either the visualization or the graph we drop down to about the first set of numbers....\n\nStephen, how likely is this page to stick around in its current form?\n\nIn any case, it seems like the main bottleneck at this point for nightly is in fact the canvas bits.\n\nBrian, do you want to look into whatever JS issues are left here and file bugs as needed?", "count": 1, "author": "bzbarsky@mit.edu", "raw_text": "I assume the actual steps to reproduce are to load http://stepheneb.github.com/avalanche2d-js/avalanche2d.html and select the \"Go\" radio button?\n\nIf so, and using the default settings (100x100 desk array size, visualization+graph rendering, Uint8Array), I get numbers like so on Mac OS X 10.6:\n\n  Firefox 7: 2265.5 (steps/s)\n  Current trunk nightly: 5417.1 (steps/s)\n  Chrome dev build (16.x): 7680.5 (steps/s)\n  \nIf I turn off the rendering part, these become:\n\n  Firefox 7: 3043.2 (steps/s)\n  Current trunk nightly: 9124.1 (steps/s)\n  Chrome dev build (16.x): rate: 8741.3 (steps/s)\n\nThough all the numbers are very noisy (about 10% or more noise).\n\nIf I enable either the visualization or the graph we drop down to about the first set of numbers....\n\nStephen, how likely is this page to stick around in its current form?\n\nIn any case, it seems like the main bottleneck at this point for nightly is in fact the canvas bits.\n\nBrian, do you want to look into whatever JS issues are left here and file bugs as needed?", "time": "2011-10-25T19:45:11Z", "creation_time": "2011-10-25T19:45:11Z", "is_private": false, "creator": "bzbarsky@mit.edu", "tags": [], "attachment_id": null}, {"text": "A profile of the testcase with the rendering bits (both visualization and graph) enabled shows:\n\n  7% kernel-level GL stuff\n 15% painting\n 31% JIT-generated JS code\n  7% array_shift\n  7% Non-quickstubbed gets of window.self\n  5% under mjit::ic::Call (some of this is canvas stuff, note).\n  3% under mjit:stibs:SlowCall (likewise)\n  8% stroking on canvas (about 2/3 the path ops and 1/3 invalidation)\n  \nand various array ops, stubs::Pos, js_Date, stubs::sub, BeginPath, etc.\n\nIf I collapse all the libmozjs stuff, then 53% is JS engine code, 8% is canvas stroking, 7% is window.self, 1% is setAttribute on elements, and some minor stuff for getImageData, beginPath, putImageData, etc.\n\nLooks like the window.self gets all happen from this sort of pattern in the grapher:\n\n  y.call(self, pts[0].y, 0)\n\nIs there a reason that's using \"self\" and not just \"window\" or better yet \"null\" as the first argument to call() there?", "count": 2, "author": "bzbarsky@mit.edu", "creator": "bzbarsky@mit.edu", "is_private": false, "creation_time": "2011-10-25T20:09:50Z", "id": 5804184, "bug_id": 697212, "raw_text": "A profile of the testcase with the rendering bits (both visualization and graph) enabled shows:\n\n  7% kernel-level GL stuff\n 15% painting\n 31% JIT-generated JS code\n  7% array_shift\n  7% Non-quickstubbed gets of window.self\n  5% under mjit::ic::Call (some of this is canvas stuff, note).\n  3% under mjit:stibs:SlowCall (likewise)\n  8% stroking on canvas (about 2/3 the path ops and 1/3 invalidation)\n  \nand various array ops, stubs::Pos, js_Date, stubs::sub, BeginPath, etc.\n\nIf I collapse all the libmozjs stuff, then 53% is JS engine code, 8% is canvas stroking, 7% is window.self, 1% is setAttribute on elements, and some minor stuff for getImageData, beginPath, putImageData, etc.\n\nLooks like the window.self gets all happen from this sort of pattern in the grapher:\n\n  y.call(self, pts[0].y, 0)\n\nIs there a reason that's using \"self\" and not just \"window\" or better yet \"null\" as the first argument to call() there?", "attachment_id": null, "time": "2011-10-25T20:09:50Z", "tags": []}, {"time": "2011-10-25T20:13:25Z", "raw_text": "The other interesting thing is the \"Animation loop timing measurements for this browser\" number, which is rather different for us and Chrome.  What is that measuring?", "count": 3, "text": "The other interesting thing is the \"Animation loop timing measurements for this browser\" number, which is rather different for us and Chrome.  What is that measuring?", "author": "bzbarsky@mit.edu", "id": 5804190, "bug_id": 697212, "attachment_id": null, "tags": [], "creator": "bzbarsky@mit.edu", "is_private": false, "creation_time": "2011-10-25T20:13:25Z"}, {"raw_text": "I normally run two tests: model, visualization, and grapher AND just the model.\n\nIt makes sense to describe these results as a pair of numbers so I might describe your Nightly results as 5417/9124\n\nModel, Canvas Visualization, Graph:\n\n1) Close other CPU intensive processes\n2) open page: http://stepheneb.github.com/avalanche2d-js/avalanche2d.html\n3) press \"Go\" and wait for 5000 model-steps to complete\n4) Press \"Reset\"\n5) press \"Go\" and wait for 5000 model-steps to complete\n6) record value displayed in \"rate: nnnn (steps/s)\"\n\nJust Model -- no Canvas Visualization or Graph\n\nThis should mainly just test the computational speed.\n\n1) Close other CPU intensive processes\n2) open page: http://stepheneb.github.com/avalanche2d-js/avalanche2d.html\n3) Uncheck \"Visualization\" and \"Graph\"\n4) press \"Go\" and wait for 5000 model-steps to complete\n5) Press \"Reset\"\n6) press \"Go\" and wait for 5000 model-steps to complete\n7) record value displayed in \"rate: nnnn (steps/s)\"\n\nI run the test twice because there sometimes seems to run slower the first time.\n\nOne reason the result is noisy is that the computational algorithm has chaotic aspects.\n\nA model step consists of randomly \"dropping\" a folder on one of the 'Bureaucrats' desks. If that Bureaucrat has more than 3 folders they take four folders from their desk and distribute them to their neighbors. In this process any Bureaucrat to whom a folder has been distributed must be checked to see if they have more than 3 folders ... and so on. Only when NO Bureaucrat has more than 3 folders is the model-step over. Bureaucrats on the edges throw their folders over the edge and these are lost.\n\nThe graph shows the average folders per desk over time. The sharp drops are in effect \"Avalanches\".\n\nAnother reason is that  I am dynamically adjusting how much work I do before each requestAnimFrame to try and use about 80% of the available time. Normally this would be consider an \"unfriendly\" behavior by a web page but this page is specifically designed to find out how fast a computational simulation can be run. In a real version of this app the user would select what speed, size, and resolution to run the model -- and if they chose a large complex model to run fast presumably they are OK with the larger power usage that would entail.\n\nI just updated my Nightly and I measured 5549/11136 on my Mac OS X 10.6.8, 2.66 GHz Core i7 system. Chrome 14 yesterday was: 9578/12594. I hadn't measure Nightly for a few days and it seems much closer to Chrome than before ...\n\nTo me this new data indicate that the computational performance is close to Chrome and you are correct that the slowdown appears no to be more with the Canvas performance.\n\nWhile the graphing framework uses D3.js (which uses SVG) the \"real-time graphing\" is to a Canvas object that is layered over the plotting section of the SVG graph. This is used while the model is running. When the model stops the Canvas object is placed behind the SVH graph and the SVG graph is re-drawn. \n\nThe graphics performance can be further distinguished by running the model with \"Visualization\" and \"Graph\" on and then with just the \"Visualization\" on and then finally with just the Model running\n\nHere's the data I just collected using this pattern:\n\n  Nightly:  6975/8802/10638\n  Chrome Canary: 10183/11682/13089\n\nI think I am done for a while making performance changes to the application.\n\nI was quite surprised at how much performance I was able to get.\n\nThis graph shows the performance change over the last two weeks. The Y axis is a log scale!\n\nhttps://img.skitch.com/20111023-q8rkqfkhynifqhtj6yefm86aaw.jpg\n\nIf it would be helpful I could also put up a static copy of the current site that wouldn't change.", "time": "2011-10-25T20:47:44Z", "id": 5804318, "bug_id": 697212, "author": "stephen.bannasch@gmail.com", "count": 4, "text": "I normally run two tests: model, visualization, and grapher AND just the model.\n\nIt makes sense to describe these results as a pair of numbers so I might describe your Nightly results as 5417/9124\n\nModel, Canvas Visualization, Graph:\n\n1) Close other CPU intensive processes\n2) open page: http://stepheneb.github.com/avalanche2d-js/avalanche2d.html\n3) press \"Go\" and wait for 5000 model-steps to complete\n4) Press \"Reset\"\n5) press \"Go\" and wait for 5000 model-steps to complete\n6) record value displayed in \"rate: nnnn (steps/s)\"\n\nJust Model -- no Canvas Visualization or Graph\n\nThis should mainly just test the computational speed.\n\n1) Close other CPU intensive processes\n2) open page: http://stepheneb.github.com/avalanche2d-js/avalanche2d.html\n3) Uncheck \"Visualization\" and \"Graph\"\n4) press \"Go\" and wait for 5000 model-steps to complete\n5) Press \"Reset\"\n6) press \"Go\" and wait for 5000 model-steps to complete\n7) record value displayed in \"rate: nnnn (steps/s)\"\n\nI run the test twice because there sometimes seems to run slower the first time.\n\nOne reason the result is noisy is that the computational algorithm has chaotic aspects.\n\nA model step consists of randomly \"dropping\" a folder on one of the 'Bureaucrats' desks. If that Bureaucrat has more than 3 folders they take four folders from their desk and distribute them to their neighbors. In this process any Bureaucrat to whom a folder has been distributed must be checked to see if they have more than 3 folders ... and so on. Only when NO Bureaucrat has more than 3 folders is the model-step over. Bureaucrats on the edges throw their folders over the edge and these are lost.\n\nThe graph shows the average folders per desk over time. The sharp drops are in effect \"Avalanches\".\n\nAnother reason is that  I am dynamically adjusting how much work I do before each requestAnimFrame to try and use about 80% of the available time. Normally this would be consider an \"unfriendly\" behavior by a web page but this page is specifically designed to find out how fast a computational simulation can be run. In a real version of this app the user would select what speed, size, and resolution to run the model -- and if they chose a large complex model to run fast presumably they are OK with the larger power usage that would entail.\n\nI just updated my Nightly and I measured 5549/11136 on my Mac OS X 10.6.8, 2.66 GHz Core i7 system. Chrome 14 yesterday was: 9578/12594. I hadn't measure Nightly for a few days and it seems much closer to Chrome than before ...\n\nTo me this new data indicate that the computational performance is close to Chrome and you are correct that the slowdown appears no to be more with the Canvas performance.\n\nWhile the graphing framework uses D3.js (which uses SVG) the \"real-time graphing\" is to a Canvas object that is layered over the plotting section of the SVG graph. This is used while the model is running. When the model stops the Canvas object is placed behind the SVH graph and the SVG graph is re-drawn. \n\nThe graphics performance can be further distinguished by running the model with \"Visualization\" and \"Graph\" on and then with just the \"Visualization\" on and then finally with just the Model running\n\nHere's the data I just collected using this pattern:\n\n  Nightly:  6975/8802/10638\n  Chrome Canary: 10183/11682/13089\n\nI think I am done for a while making performance changes to the application.\n\nI was quite surprised at how much performance I was able to get.\n\nThis graph shows the performance change over the last two weeks. The Y axis is a log scale!\n\nhttps://img.skitch.com/20111023-q8rkqfkhynifqhtj6yefm86aaw.jpg\n\nIf it would be helpful I could also put up a static copy of the current site that wouldn't change.", "tags": [], "attachment_id": null, "is_private": false, "creation_time": "2011-10-25T20:47:44Z", "creator": "stephen.bannasch@gmail.com"}, {"author": "stephen.bannasch@gmail.com", "count": 5, "text": "(In reply to Boris Zbarsky (:bz) from comment #2)\n> Looks like the window.self gets all happen from this sort of pattern in the\n> grapher:\n> \n>   y.call(self, pts[0].y, 0)\n> \n> Is there a reason that's using \"self\" and not just \"window\" or better yet\n> \"null\" as the first argument to call() there?\n\nNo reason other than that was the same form used in the D3.js example I based the initial work on.", "bug_id": 697212, "id": 5804320, "time": "2011-10-25T20:49:00Z", "raw_text": "(In reply to Boris Zbarsky (:bz) from comment #2)\n> Looks like the window.self gets all happen from this sort of pattern in the\n> grapher:\n> \n>   y.call(self, pts[0].y, 0)\n> \n> Is there a reason that's using \"self\" and not just \"window\" or better yet\n> \"null\" as the first argument to call() there?\n\nNo reason other than that was the same form used in the D3.js example I based the initial work on.", "creator": "stephen.bannasch@gmail.com", "creation_time": "2011-10-25T20:49:00Z", "is_private": false, "attachment_id": null, "tags": []}, {"creator": "bzbarsky@mit.edu", "author": "bzbarsky@mit.edu", "text": "> I am dynamically adjusting how much work I do before each requestAnimFrame to try and\n> use about 80% of the available time.\n\nHmm.  How are you determining the \"available time\"?  Just new Date() and seeing until some threshold is passed?  If so, which threshold?\n\n> No reason other than that was the same form used in the D3.js example\n\nAh.  Passing either \"window\" or \"null\" would be somewhat faster, for what it's worth.\n\nDid you see comment 3?", "count": 6, "id": 5804337, "bug_id": 697212, "creation_time": "2011-10-25T20:55:31Z", "is_private": false, "time": "2011-10-25T20:55:31Z", "attachment_id": null, "raw_text": "> I am dynamically adjusting how much work I do before each requestAnimFrame to try and\n> use about 80% of the available time.\n\nHmm.  How are you determining the \"available time\"?  Just new Date() and seeing until some threshold is passed?  If so, which threshold?\n\n> No reason other than that was the same form used in the D3.js example\n\nAh.  Passing either \"window\" or \"null\" would be somewhat faster, for what it's worth.\n\nDid you see comment 3?", "tags": []}, {"attachment_id": null, "raw_text": "(In reply to Boris Zbarsky (:bz) from comment #3)\n> The other interesting thing is the \"Animation loop timing measurements for\n> this browser\" number, which is rather different for us and Chrome.  What is\n> that measuring?\n\nI'm still learning about how requestAnimFrame works and how best to do this -- the intent is to use a large percentage of the available cycles but not all of them -- and to dynamically adjust this. I have the impression (w/o direct evidence yet) that running a browser on a phone or tablet might not call back every 16ms.\n\nOne hypothesis is that this algorithm ends up using a smaller percentage of the cpu time available than when the same code is running on Chrome.\n\nMy usecase might be a good example where setImmediate:https://github.com/NobleJS/setImmediate would be useful.\n\nHere's what I wrote a couple of days ago about this question.\n\nMy latest implementation is designed to render during every screen re-fresh -- and only render what is necessary for every screen refresh.\n\nIt's definitely makes sense to only do the work to render what can be seen at the maximum screen refresh rate.\n\nTo get the line graph to appear I still render it for every model step.\n\nHowever for the canvas visualization of the folder-count on the array of desks I am only rendering that once per screen re-paint.\n\nThere a bunch of fiddling around to do the maximum amount of work in one screen repaint cycle.\n\nI dynamically adjust the maximum time I spend in the runModelLoop to try and always end at about  70-80% of the interval between a screen refresh.\n\nNominally the screen refresh rate is 60 Hz, about 17ms.\n\nThe browser can choose to make this interval longer. I think this is likely to happen on phones and tablets. It will also happen when the web page is in a tabbed window that is not being displayed (in this situation my algorithm for dynamically adjusting will be more greedy than a good web citizen should be).\n\nHere's some data from a run in Chrome:\n\n\n  avalanches: 5000\n  rate: 9041.6 (steps/s)\n  last sample time: 0 (ms)\n  loop compute maximum: 20\n  anim loop timing: 23\n  folders: 2.122 (ave)\n\nThe variables that pertain to this discussion are:\n\n  loop compute maximum: 20\n\nThis is what the last model loop time took. A model loop time always includes one and usually more than one model step.\n\n  anim loop timing: 23\n\nThis is the most recent time between between callbacks from the browser to my code that executes the runModel loop.\n\nSo at the end of that run I was:\n\n  * Computing and rendering in my runModelLoop until 20 ms were up.\n  * Returning from my runModel loop to the browser.\n  * Then getting called 3 ms later to start the runModelLoop all over again.\n\nAnd I was rendering at 44 times/s (why this is less than 60 I'm not certain right now).\n\nThis is tricky because there are model steps which take more than one screen refresh interval -- this happens in big avalanches.", "time": "2011-10-25T20:57:46Z", "tags": [], "author": "stephen.bannasch@gmail.com", "count": 7, "text": "(In reply to Boris Zbarsky (:bz) from comment #3)\n> The other interesting thing is the \"Animation loop timing measurements for\n> this browser\" number, which is rather different for us and Chrome.  What is\n> that measuring?\n\nI'm still learning about how requestAnimFrame works and how best to do this -- the intent is to use a large percentage of the available cycles but not all of them -- and to dynamically adjust this. I have the impression (w/o direct evidence yet) that running a browser on a phone or tablet might not call back every 16ms.\n\nOne hypothesis is that this algorithm ends up using a smaller percentage of the cpu time available than when the same code is running on Chrome.\n\nMy usecase might be a good example where setImmediate:https://github.com/NobleJS/setImmediate would be useful.\n\nHere's what I wrote a couple of days ago about this question.\n\nMy latest implementation is designed to render during every screen re-fresh -- and only render what is necessary for every screen refresh.\n\nIt's definitely makes sense to only do the work to render what can be seen at the maximum screen refresh rate.\n\nTo get the line graph to appear I still render it for every model step.\n\nHowever for the canvas visualization of the folder-count on the array of desks I am only rendering that once per screen re-paint.\n\nThere a bunch of fiddling around to do the maximum amount of work in one screen repaint cycle.\n\nI dynamically adjust the maximum time I spend in the runModelLoop to try and always end at about  70-80% of the interval between a screen refresh.\n\nNominally the screen refresh rate is 60 Hz, about 17ms.\n\nThe browser can choose to make this interval longer. I think this is likely to happen on phones and tablets. It will also happen when the web page is in a tabbed window that is not being displayed (in this situation my algorithm for dynamically adjusting will be more greedy than a good web citizen should be).\n\nHere's some data from a run in Chrome:\n\n\n  avalanches: 5000\n  rate: 9041.6 (steps/s)\n  last sample time: 0 (ms)\n  loop compute maximum: 20\n  anim loop timing: 23\n  folders: 2.122 (ave)\n\nThe variables that pertain to this discussion are:\n\n  loop compute maximum: 20\n\nThis is what the last model loop time took. A model loop time always includes one and usually more than one model step.\n\n  anim loop timing: 23\n\nThis is the most recent time between between callbacks from the browser to my code that executes the runModel loop.\n\nSo at the end of that run I was:\n\n  * Computing and rendering in my runModelLoop until 20 ms were up.\n  * Returning from my runModel loop to the browser.\n  * Then getting called 3 ms later to start the runModelLoop all over again.\n\nAnd I was rendering at 44 times/s (why this is less than 60 I'm not certain right now).\n\nThis is tricky because there are model steps which take more than one screen refresh interval -- this happens in big avalanches.", "creator": "stephen.bannasch@gmail.com", "is_private": false, "creation_time": "2011-10-25T20:57:46Z", "bug_id": 697212, "id": 5804347}, {"tags": [], "raw_text": "(In reply to Boris Zbarsky (:bz) from comment #6)\n> > I am dynamically adjusting how much work I do before each requestAnimFrame to try and\n> > use about 80% of the available time.\n> \n> Hmm.  How are you determining the \"available time\"?  Just new Date() and\n> seeing until some threshold is passed?  If so, which threshold?\n\nYes.\n\nSee: measureAnimmationLoop()\n  https://github.com/stepheneb/avalanche2d-js/blob/master/avalanche2d.html#L508\n\nwhich calls: runModelLoop();\n  https://github.com/stepheneb/avalanche2d-js/blob/master/avalanche2d.html#L469\n\nWhich runs the modelStep once and if the elapsed time is less than model_loop_time runs the model step again (w/o the rendering the Canvas visualization again.\n\n> > No reason other than that was the same form used in the D3.js example\n> \n> Ah.  Passing either \"window\" or \"null\" would be somewhat faster, for what\n> it's worth.\n> \n> Did you see comment 3?\n\nyes ...  typing as fast as I can ;-)\n\nThanks for your help!", "attachment_id": null, "time": "2011-10-25T21:01:26Z", "is_private": false, "creation_time": "2011-10-25T21:01:26Z", "bug_id": 697212, "id": 5804357, "count": 8, "text": "(In reply to Boris Zbarsky (:bz) from comment #6)\n> > I am dynamically adjusting how much work I do before each requestAnimFrame to try and\n> > use about 80% of the available time.\n> \n> Hmm.  How are you determining the \"available time\"?  Just new Date() and\n> seeing until some threshold is passed?  If so, which threshold?\n\nYes.\n\nSee: measureAnimmationLoop()\n  https://github.com/stepheneb/avalanche2d-js/blob/master/avalanche2d.html#L508\n\nwhich calls: runModelLoop();\n  https://github.com/stepheneb/avalanche2d-js/blob/master/avalanche2d.html#L469\n\nWhich runs the modelStep once and if the elapsed time is less than model_loop_time runs the model step again (w/o the rendering the Canvas visualization again.\n\n> > No reason other than that was the same form used in the D3.js example\n> \n> Ah.  Passing either \"window\" or \"null\" would be somewhat faster, for what\n> it's worth.\n> \n> Did you see comment 3?\n\nyes ...  typing as fast as I can ;-)\n\nThanks for your help!", "author": "stephen.bannasch@gmail.com", "creator": "stephen.bannasch@gmail.com"}, {"creator": "stephen.bannasch@gmail.com", "author": "stephen.bannasch@gmail.com", "count": 9, "text": "(In reply to Stephen Bannasch from comment #8)\n> (In reply to Boris Zbarsky (:bz) from comment #6)\n> > > I am dynamically adjusting how much work I do before each requestAnimFrame to try and\n> > > use about 80% of the available time.\n> > \n> > Hmm.  How are you determining the \"available time\"?  Just new Date() and\n> > seeing until some threshold is passed?  If so, which threshold?\n> \n> Yes.\n> \n> See: measureAnimmationLoop()\n>  \n> https://github.com/stepheneb/avalanche2d-js/blob/master/avalanche2d.html#L508\n\n\n\nThat a red herring!  only used at startup for informational purposes\n\nmodelGo();\nhttps://github.com/stepheneb/avalanche2d-js/blob/master/avalanche2d.html#L381\n\nIs where the process starts and it sets up a callback to runModelLoop();", "id": 5804386, "bug_id": 697212, "creation_time": "2011-10-25T21:10:16Z", "is_private": false, "time": "2011-10-25T21:10:16Z", "attachment_id": null, "raw_text": "(In reply to Stephen Bannasch from comment #8)\n> (In reply to Boris Zbarsky (:bz) from comment #6)\n> > > I am dynamically adjusting how much work I do before each requestAnimFrame to try and\n> > > use about 80% of the available time.\n> > \n> > Hmm.  How are you determining the \"available time\"?  Just new Date() and\n> > seeing until some threshold is passed?  If so, which threshold?\n> \n> Yes.\n> \n> See: measureAnimmationLoop()\n>  \n> https://github.com/stepheneb/avalanche2d-js/blob/master/avalanche2d.html#L508\n\n\n\nThat a red herring!  only used at startup for informational purposes\n\nmodelGo();\nhttps://github.com/stepheneb/avalanche2d-js/blob/master/avalanche2d.html#L381\n\nIs where the process starts and it sets up a callback to runModelLoop();", "tags": []}, {"attachment_id": null, "raw_text": "this is where the the model_loop_goal is dynamically adjusted:\n\nhttps://github.com/stepheneb/avalanche2d-js/blob/master/avalanche2d.html#L489", "time": "2011-10-25T21:12:00Z", "tags": [], "author": "stephen.bannasch@gmail.com", "count": 10, "text": "this is where the the model_loop_goal is dynamically adjusted:\n\nhttps://github.com/stepheneb/avalanche2d-js/blob/master/avalanche2d.html#L489", "creator": "stephen.bannasch@gmail.com", "creation_time": "2011-10-25T21:12:00Z", "is_private": false, "id": 5804391, "bug_id": 697212}, {"bug_id": 697212, "id": 5804728, "author": "stephen.bannasch@gmail.com", "count": 11, "text": "Computational performance plays a larger factor than than it might appear,\n\nThere's a non-linearity in the system because I am only rendering the Canvas visualization once for every time the runModelLoop() is called by the requestAnimFrame() callback.\n\nSo if 5000 model-steps with just the Canvas visualization on takes one second then avalanche2d.displayFolderCanvas(); will execute 60 times.\n\nIf avalanche2d.displayFolderCanvas(); takes 5ms then 60 take 300ms. So that means (discounting the time spent not in the callback) that the model itself on average takes 700ms/5000 => 140 us.\n\nWhat if the model instead averages 170us?\n\n170us * 5000 = 850ms \n\nAdd to that the initial 60 avalanche2d.displayFolderCanvas(); executions for 300ms and you get 1250ms ... but because we're spending another 250ms (at least) we need to add in another 15 avalanche2d.displayFolderCanvas(); executions for another 75ms. So that leaves an intermediate total of 1375.\n\nSo with a 5ms estimate for the Canvas visualization a 21% increase in the time it takes to run the model results in a 38% increase in the time it takes to run 5000 model steps.\n\nI don't actually know how long displayFolderCanvas(); takes -- that would be interesting info.", "raw_text": "Computational performance plays a larger factor than than it might appear,\n\nThere's a non-linearity in the system because I am only rendering the Canvas visualization once for every time the runModelLoop() is called by the requestAnimFrame() callback.\n\nSo if 5000 model-steps with just the Canvas visualization on takes one second then avalanche2d.displayFolderCanvas(); will execute 60 times.\n\nIf avalanche2d.displayFolderCanvas(); takes 5ms then 60 take 300ms. So that means (discounting the time spent not in the callback) that the model itself on average takes 700ms/5000 => 140 us.\n\nWhat if the model instead averages 170us?\n\n170us * 5000 = 850ms \n\nAdd to that the initial 60 avalanche2d.displayFolderCanvas(); executions for 300ms and you get 1250ms ... but because we're spending another 250ms (at least) we need to add in another 15 avalanche2d.displayFolderCanvas(); executions for another 75ms. So that leaves an intermediate total of 1375.\n\nSo with a 5ms estimate for the Canvas visualization a 21% increase in the time it takes to run the model results in a 38% increase in the time it takes to run 5000 model steps.\n\nI don't actually know how long displayFolderCanvas(); takes -- that would be interesting info.", "time": "2011-10-25T22:58:29Z", "creation_time": "2011-10-25T22:58:29Z", "is_private": false, "creator": "stephen.bannasch@gmail.com", "tags": [], "attachment_id": null}, {"text": "(In reply to Stephen Bannasch from comment #11)\n> executions for another 75ms. So that leaves an intermediate total of 1375.\n\nbasic math error ...\n\nactually : 1325 => 33%", "count": 12, "author": "stephen.bannasch@gmail.com", "creator": "stephen.bannasch@gmail.com", "is_private": false, "creation_time": "2011-10-25T23:21:07Z", "bug_id": 697212, "id": 5804775, "raw_text": "(In reply to Stephen Bannasch from comment #11)\n> executions for another 75ms. So that leaves an intermediate total of 1375.\n\nbasic math error ...\n\nactually : 1325 => 33%", "attachment_id": null, "time": "2011-10-25T23:21:07Z", "tags": []}, {"text": "> There's a non-linearity in the system\n\nThank you for doing that analysis!  That's what I was sort of after with trying to understand the way the throttling works.\n\nSo yeah, seems like having slightly slower JS performance could just lead us to have lots more canvas ops (which may also be slower, of course)....", "count": 13, "author": "bzbarsky@mit.edu", "id": 5805092, "bug_id": 697212, "time": "2011-10-26T01:28:04Z", "raw_text": "> There's a non-linearity in the system\n\nThank you for doing that analysis!  That's what I was sort of after with trying to understand the way the throttling works.\n\nSo yeah, seems like having slightly slower JS performance could just lead us to have lots more canvas ops (which may also be slower, of course)....", "creator": "bzbarsky@mit.edu", "creation_time": "2011-10-26T01:28:04Z", "is_private": false, "attachment_id": null, "tags": []}, {"bug_id": 697212, "id": 5811536, "count": 14, "text": "I've updated the deployed code so if you are running the model by itself no callbacks are used. This removes a variable from the measurements for just running the model alone.\n\nHere are some updated measurements:\n\nAvalanche2D-JS Benchmarks\n\nModel-steps/s over 5000 model-steps, visualization and graphing ON                              average   comparison\n--------------------------------------------------------------------------------------------------------------------\nChrome 17.0.920.1 canary              9345.8      9523.8      9276.4      10040.2     10204.1     9678        100%\nChrome 14.0.835.186                   8210.2      9009        9058        9276.4      9191.2      8949        92%\nFireFox Nightly 10.0a1 (2011-10-28)   5861.7      6784.3      7042.3      7278        7052.2      6804        70%\nFireFox 7.0.1                         2161.7      2395.8      2356.3      2343        2401.5      2332        24%\n\nModel-steps/s over 5000 model-steps, visualization and graphing OFF                             average   comparison\n---------------------------------------------------------------------------------------------------------------------\nChrome 17.0.920.1 canary              15822.8     15723.3     16129       16077.2     16233.8     15997       100%\nChrome 14.0.835.186                   15243.9     14619.9     15151.5     14970.1     14925.4     14982       94%\nFireFox Nightly 10.0a1 (2011-10-28)   12626.3     12787.7     13089       12658.2     12468.8     12726       80%\nFireFox 7.0.1                         3728.6      3776.4      3742.5      3652.3      3663        3713        23%\n\npage:      http://stepheneb.github.com/avalanche2d-js/avalanche2d.html                                                                         \ncommit:    https://github.com/stepheneb/avalanche2d-js/commit/f8c4f24df                                                                        \ndate:      10/28/11                                                                     \ncomputer:  Mac OS X 10.6.8, PowerBook Pro, 2.66 GHz Intel Core i7", "author": "stephen.bannasch@gmail.com", "raw_text": "I've updated the deployed code so if you are running the model by itself no callbacks are used. This removes a variable from the measurements for just running the model alone.\n\nHere are some updated measurements:\n\nAvalanche2D-JS Benchmarks\n\nModel-steps/s over 5000 model-steps, visualization and graphing ON                              average   comparison\n--------------------------------------------------------------------------------------------------------------------\nChrome 17.0.920.1 canary              9345.8      9523.8      9276.4      10040.2     10204.1     9678        100%\nChrome 14.0.835.186                   8210.2      9009        9058        9276.4      9191.2      8949        92%\nFireFox Nightly 10.0a1 (2011-10-28)   5861.7      6784.3      7042.3      7278        7052.2      6804        70%\nFireFox 7.0.1                         2161.7      2395.8      2356.3      2343        2401.5      2332        24%\n\nModel-steps/s over 5000 model-steps, visualization and graphing OFF                             average   comparison\n---------------------------------------------------------------------------------------------------------------------\nChrome 17.0.920.1 canary              15822.8     15723.3     16129       16077.2     16233.8     15997       100%\nChrome 14.0.835.186                   15243.9     14619.9     15151.5     14970.1     14925.4     14982       94%\nFireFox Nightly 10.0a1 (2011-10-28)   12626.3     12787.7     13089       12658.2     12468.8     12726       80%\nFireFox 7.0.1                         3728.6      3776.4      3742.5      3652.3      3663        3713        23%\n\npage:      http://stepheneb.github.com/avalanche2d-js/avalanche2d.html                                                                         \ncommit:    https://github.com/stepheneb/avalanche2d-js/commit/f8c4f24df                                                                        \ndate:      10/28/11                                                                     \ncomputer:  Mac OS X 10.6.8, PowerBook Pro, 2.66 GHz Intel Core i7", "time": "2011-10-28T16:20:43Z", "creation_time": "2011-10-28T16:20:43Z", "is_private": false, "creator": "stephen.bannasch@gmail.com", "tags": [], "attachment_id": null}, {"attachment_id": null, "tags": [], "creator": "bzbarsky@mit.edu", "creation_time": "2011-10-28T16:53:22Z", "is_private": false, "time": "2011-10-28T16:53:22Z", "raw_text": "Actually, I'm going to split this into two bugs given that data.  Leaving this as the canvas bug; going to file a separate jseng bug.", "author": "bzbarsky@mit.edu", "count": 15, "text": "Actually, I'm going to split this into two bugs given that data.  Leaving this as the canvas bug; going to file a separate jseng bug.", "id": 5811625, "bug_id": 697212}, {"text": "Filed bug 698017", "count": 16, "author": "bzbarsky@mit.edu", "creator": "bzbarsky@mit.edu", "is_private": false, "creation_time": "2011-10-28T16:57:54Z", "bug_id": 697212, "id": 5811636, "raw_text": "Filed bug 698017", "attachment_id": null, "time": "2011-10-28T16:57:54Z", "tags": []}, {"bug_id": 697212, "id": 5813654, "is_private": false, "creation_time": "2011-10-30T03:14:14Z", "creator": "stephen.bannasch@gmail.com", "author": "stephen.bannasch@gmail.com", "text": "I've updated the code a bit.\n\nBasically I made the canvas rendering part of the avalanche2d.model object and am keeping a persistent copy of the canvas, context, ImageData, and CanvasPixelArray. I am also pre-rendering the alpha values in the CanvasPixelArray so that these bytes don't need to be written during regular rendering.\n\n  https://github.com/stepheneb/avalanche2d-js/commit/608030b\n\nThere is now a google doc with updated timings here:\n\nhttps://docs.google.com/spreadsheet/ccc?key=0AtvlFoSBUC5kdDM4cHJhU0I4NGg5TjlWRkQ0ZExpcGc\n\nIn general an increase of about 10% when running model, visualization, and grapher.", "count": 17, "tags": [], "time": "2011-10-30T03:14:14Z", "attachment_id": null, "raw_text": "I've updated the code a bit.\n\nBasically I made the canvas rendering part of the avalanche2d.model object and am keeping a persistent copy of the canvas, context, ImageData, and CanvasPixelArray. I am also pre-rendering the alpha values in the CanvasPixelArray so that these bytes don't need to be written during regular rendering.\n\n  https://github.com/stepheneb/avalanche2d-js/commit/608030b\n\nThere is now a google doc with updated timings here:\n\nhttps://docs.google.com/spreadsheet/ccc?key=0AtvlFoSBUC5kdDM4cHJhU0I4NGg5TjlWRkQ0ZExpcGc\n\nIn general an increase of about 10% when running model, visualization, and grapher."}]}}}