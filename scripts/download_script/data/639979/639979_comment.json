{"comments": {}, "bugs": {"639979": {"comments": [{"is_private": false, "author": "mimecuvalo@gmail.com", "time": "2011-03-08T21:38:09Z", "count": 0, "id": 5331379, "creation_time": "2011-03-08T21:38:09Z", "tags": [], "attachment_id": null, "raw_text": "User-Agent:       Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_6; en-US) AppleWebKit/534.13 (KHTML, like Gecko) Chrome/9.0.597.107 Safari/534.13\nBuild Identifier: \n\nSorry ahead of time for the length of this explanation...\n\nMy latest project involves making SSH work in javascript only.  It is completed and working: http://firessh.mozdev.org  FireFTP now uses this new engine as well ( http://fireftp.mozdev.org ) and when it comes to manipulating MBs of data as happens when transferring files I was looking for ways to improve upon the speed of the encryption.\n\nI heard about the new JavaScript typed arrays for FF4 and was excited.  It sounded right up my alley.  The main CPU usage, when looking at a profiler of the SSH code, is the conversion of uint8 numbers stored in string form into arrays of uint8 numbers to be put through a cipher (and then back into string form).\n\nThe basic flow of data in the program is:\n  while (packetIncomplete)\n     var newData = nsIBinaryInputStream.readBytes()\n     buffer += newData;\n  var arrayOfUint8 = convertToArray(buffer)\n  var decryptedArray = decrypt(arrayOfUint8)\n  var decryptedString = convertToString(decryptedArray)\n\nOk.  So I decided to convert the code to use nsIBinaryInputStream.readByteArray/writeByteArray.  One issue with that was that they don't accept typed arrays at the moment and there doesn't seem to be a way to take a regular array and casting it into a typed array?\n\nIn any case, after converting the code to use arrays instead of strings, the code ended up being much slower than before.  Despite having gotten rid of the two biggest culprits of CPU (convertToArray and convertToString which mostly deal with ~16kb chunks of data, btw), the new issue was that manipulating arrays just hasn't been optimized for speed the way strings have been.  The two biggest culprits were concat() and slice() which fare far worse than their string counterparts.\n\nSo in the example above, instead of:\n  buffer += newData;\nit would be:\n  buffer = buffer.concat(newData)\nand in many other places in the code, instead of:\n  var chunk = buffer.substring(0, n);\n  buffer = buffer.substring(n);\nit would be:\n  var chunk = buffer.slice(0, n);\n  buffer = buffer.slice(n);\n\nI created a rudimentary benchmark (which I will attach shortly to this bug) and on my machine I get:\n array concatenation (1,000x, ~16kb data): 734 ms\n string concatenation (1,000x, ~16kb data): 224 ms\n array concatenation (100x, growing by ~16kb data at a time): 1556 ms\n string concatenation (100x, growing by ~16kb data): 102 ms\n array slice (1,000x, ~16kb data): 301 ms\n string substring (1,000x, ~16kb data): 0 ms\n\nOther notes:\n- scriptableunicodeconverter seemed nice to use to speed up things in converting uint8 array<->string but doesn't have an \"extended-ascii\" setting to deal with charCodes above 127.  (maybe should be filed as a separate bug?)\n- using the AES cipher through NSS (as through WeaveCrypto.js) instead of doing encryption in javascript (using the Blowfish cipher) ends up being slower than javascript since calling jsctypes seems to have a large overhead (250ms on my machine: mac 2ghz)  (this maybe should be filed as a separate bug as well?)\n\nReproducible: Always", "creator": "mimecuvalo@gmail.com", "bug_id": 639979, "text": "User-Agent:       Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_6; en-US) AppleWebKit/534.13 (KHTML, like Gecko) Chrome/9.0.597.107 Safari/534.13\nBuild Identifier: \n\nSorry ahead of time for the length of this explanation...\n\nMy latest project involves making SSH work in javascript only.  It is completed and working: http://firessh.mozdev.org  FireFTP now uses this new engine as well ( http://fireftp.mozdev.org ) and when it comes to manipulating MBs of data as happens when transferring files I was looking for ways to improve upon the speed of the encryption.\n\nI heard about the new JavaScript typed arrays for FF4 and was excited.  It sounded right up my alley.  The main CPU usage, when looking at a profiler of the SSH code, is the conversion of uint8 numbers stored in string form into arrays of uint8 numbers to be put through a cipher (and then back into string form).\n\nThe basic flow of data in the program is:\n  while (packetIncomplete)\n     var newData = nsIBinaryInputStream.readBytes()\n     buffer += newData;\n  var arrayOfUint8 = convertToArray(buffer)\n  var decryptedArray = decrypt(arrayOfUint8)\n  var decryptedString = convertToString(decryptedArray)\n\nOk.  So I decided to convert the code to use nsIBinaryInputStream.readByteArray/writeByteArray.  One issue with that was that they don't accept typed arrays at the moment and there doesn't seem to be a way to take a regular array and casting it into a typed array?\n\nIn any case, after converting the code to use arrays instead of strings, the code ended up being much slower than before.  Despite having gotten rid of the two biggest culprits of CPU (convertToArray and convertToString which mostly deal with ~16kb chunks of data, btw), the new issue was that manipulating arrays just hasn't been optimized for speed the way strings have been.  The two biggest culprits were concat() and slice() which fare far worse than their string counterparts.\n\nSo in the example above, instead of:\n  buffer += newData;\nit would be:\n  buffer = buffer.concat(newData)\nand in many other places in the code, instead of:\n  var chunk = buffer.substring(0, n);\n  buffer = buffer.substring(n);\nit would be:\n  var chunk = buffer.slice(0, n);\n  buffer = buffer.slice(n);\n\nI created a rudimentary benchmark (which I will attach shortly to this bug) and on my machine I get:\n array concatenation (1,000x, ~16kb data): 734 ms\n string concatenation (1,000x, ~16kb data): 224 ms\n array concatenation (100x, growing by ~16kb data at a time): 1556 ms\n string concatenation (100x, growing by ~16kb data): 102 ms\n array slice (1,000x, ~16kb data): 301 ms\n string substring (1,000x, ~16kb data): 0 ms\n\nOther notes:\n- scriptableunicodeconverter seemed nice to use to speed up things in converting uint8 array<->string but doesn't have an \"extended-ascii\" setting to deal with charCodes above 127.  (maybe should be filed as a separate bug?)\n- using the AES cipher through NSS (as through WeaveCrypto.js) instead of doing encryption in javascript (using the Blowfish cipher) ends up being slower than javascript since calling jsctypes seems to have a large overhead (250ms on my machine: mac 2ghz)  (this maybe should be filed as a separate bug as well?)\n\nReproducible: Always"}, {"id": 5331400, "time": "2011-03-08T21:41:43Z", "author": "mimecuvalo@gmail.com", "count": 1, "is_private": false, "text": "Created attachment 517854\nBenchmark, arrays vs. strings, and NSS vs. JS blowfish", "bug_id": 639979, "raw_text": "", "creator": "mimecuvalo@gmail.com", "creation_time": "2011-03-08T21:41:43Z", "tags": [], "attachment_id": 517854}, {"count": 2, "time": "2011-03-08T21:48:26Z", "text": "So.... String.substring() and Array.slice() just do _very_ different things.  Strings in JS are immutable.  So substring() can point at the same string data; it doesn't have to make a copy.  Arrays are mutable, so slice() must create a copy of the data.  Comparing those is comparing apples and oranges.\n\nIf you're using typed arrays you can get the the equivalent of the string behavior (multiple views on the same underlying buffer), but if you mutate any of the views they will all see the changes.  But it doesn't sound like you're using typed arrays, since those don't have a slice() method to start with.  Did you mean to file this bug on just regular arrays and a separate bug (with testcases) on whatever issues you've had with typed arrays?\n\nFor concatenation, string concatenation is lazy.  Array concatenation is not.  This is, again, because strings are immutable.  So if you concatenate strings S1 and S2 and the concatenation just remembers \"I'm S1 and then S2\" that's OK, because the data in S1 and S2 can't change.  This is not doable for arrays, whose data _can_ change.\n\nScriptableUnicodConverter issues belong in separate bugs, yes.\n\nSo do ctypes issues.", "creator": "bzbarsky@mit.edu", "raw_text": "So.... String.substring() and Array.slice() just do _very_ different things.  Strings in JS are immutable.  So substring() can point at the same string data; it doesn't have to make a copy.  Arrays are mutable, so slice() must create a copy of the data.  Comparing those is comparing apples and oranges.\n\nIf you're using typed arrays you can get the the equivalent of the string behavior (multiple views on the same underlying buffer), but if you mutate any of the views they will all see the changes.  But it doesn't sound like you're using typed arrays, since those don't have a slice() method to start with.  Did you mean to file this bug on just regular arrays and a separate bug (with testcases) on whatever issues you've had with typed arrays?\n\nFor concatenation, string concatenation is lazy.  Array concatenation is not.  This is, again, because strings are immutable.  So if you concatenate strings S1 and S2 and the concatenation just remembers \"I'm S1 and then S2\" that's OK, because the data in S1 and S2 can't change.  This is not doable for arrays, whose data _can_ change.\n\nScriptableUnicodConverter issues belong in separate bugs, yes.\n\nSo do ctypes issues.", "id": 5331417, "is_private": false, "author": "bzbarsky@mit.edu", "bug_id": 639979, "attachment_id": null, "creation_time": "2011-03-08T21:48:26Z", "tags": []}, {"attachment_id": null, "creation_time": "2011-03-08T21:58:29Z", "tags": [], "bug_id": 639979, "author": "bzbarsky@mit.edu", "is_private": false, "id": 5331454, "creator": "bzbarsky@mit.edu", "raw_text": "Ah, looks like this benchmark does a charAt after each string concat, but:\n\n1) It includes the time to convert the string to an array in the array timing for\n   the 1000x benchmark.\n2) For non-typed arrays a lot more data has to be moved around than for strings,\n   so if this is gated on memmove it'll be about 4x slower for arrays than for\n   strings (Arrays have 4x as much data).\n\nFor the 100x benchmark, you're creating arrays with about 16000*100 entries, which means 12.8MB of data.  The string equivalent there is about 6.4MB (since you add dataToEncrypt to |c| twice for some reason), so cache effects might be coming into play at that point to explain the performance difference.", "text": "Ah, looks like this benchmark does a charAt after each string concat, but:\n\n1) It includes the time to convert the string to an array in the array timing for\n   the 1000x benchmark.\n2) For non-typed arrays a lot more data has to be moved around than for strings,\n   so if this is gated on memmove it'll be about 4x slower for arrays than for\n   strings (Arrays have 4x as much data).\n\nFor the 100x benchmark, you're creating arrays with about 16000*100 entries, which means 12.8MB of data.  The string equivalent there is about 6.4MB (since you add dataToEncrypt to |c| twice for some reason), so cache effects might be coming into play at that point to explain the performance difference.", "count": 3, "time": "2011-03-08T21:58:29Z"}, {"id": 5331615, "is_private": false, "count": 4, "author": "mimecuvalo@gmail.com", "time": "2011-03-08T22:51:03Z", "bug_id": 639979, "text": "(In reply to comment #2)\n> it doesn't have to make a copy.  Arrays are mutable, so slice() must create a\n> copy of the data.  Comparing those is comparing apples and oranges.\n\nGotcha - that makes sense now.\n\n> If you're using typed arrays you can get the the equivalent of the string\n> behavior (multiple views on the same underlying buffer), but if you mutate any\n> of the views they will all see the changes.  But it doesn't sound like you're\n> using typed arrays, since those don't have a slice() method to start with.  Did\n> you mean to file this bug on just regular arrays and a separate bug (with\n> testcases) on whatever issues you've had with typed arrays?\n\nLet me update the benchmark to include typed arrays using subarray() and set().  Hmm, now I must sheepishly admit that typed arrays don't seem as bad compared to strings as when I was first testing them.  They're still a little worse than strings (by ~100ms or so) and involve converting them from regular arrays to typed arrays since there doesn't seem to be a way to cast a regular array to a typed array other than looping through and setting each one by one.\n\n> ScriptableUnicodConverter issues belong in separate bugs, yes.\n> So do ctypes issues.\n\nWill do.", "attachment_id": null, "creation_time": "2011-03-08T22:51:03Z", "tags": [], "creator": "mimecuvalo@gmail.com", "raw_text": "(In reply to comment #2)\n> it doesn't have to make a copy.  Arrays are mutable, so slice() must create a\n> copy of the data.  Comparing those is comparing apples and oranges.\n\nGotcha - that makes sense now.\n\n> If you're using typed arrays you can get the the equivalent of the string\n> behavior (multiple views on the same underlying buffer), but if you mutate any\n> of the views they will all see the changes.  But it doesn't sound like you're\n> using typed arrays, since those don't have a slice() method to start with.  Did\n> you mean to file this bug on just regular arrays and a separate bug (with\n> testcases) on whatever issues you've had with typed arrays?\n\nLet me update the benchmark to include typed arrays using subarray() and set().  Hmm, now I must sheepishly admit that typed arrays don't seem as bad compared to strings as when I was first testing them.  They're still a little worse than strings (by ~100ms or so) and involve converting them from regular arrays to typed arrays since there doesn't seem to be a way to cast a regular array to a typed array other than looping through and setting each one by one.\n\n> ScriptableUnicodConverter issues belong in separate bugs, yes.\n> So do ctypes issues.\n\nWill do."}, {"creator": "jwalden@mit.edu", "raw_text": "new Int8Array([1, 2, 3, 4, 5]) should be pretty fast as long as the array you pass in is dense -- which yours should be if they're coming from readByteArray and so on.", "attachment_id": null, "creation_time": "2011-03-08T22:56:48Z", "tags": [], "text": "new Int8Array([1, 2, 3, 4, 5]) should be pretty fast as long as the array you pass in is dense -- which yours should be if they're coming from readByteArray and so on.", "bug_id": 639979, "count": 5, "time": "2011-03-08T22:56:48Z", "author": "jwalden@mit.edu", "is_private": false, "id": 5331641}, {"count": 6, "time": "2011-03-08T22:59:16Z", "text": "(In reply to comment #3)\n> 1) It includes the time to convert the string to an array in the array timing\n> for  the 1000x benchmark.\n\nI'll fix that in the next version of the benchmark but nonetheless it doesn't change the numbers much.\n\n> For the 100x benchmark, you're creating arrays with about 16000*100 entries,\n> which means 12.8MB of data.  The string equivalent there is about 6.4MB (since\n> you add dataToEncrypt to |c| twice for some reason), so cache effects might be\n> coming into play at that point to explain the performance difference.\n\nHuh, actually - it seems to be the opposite - the string one is incorrectly adding double the amount of data.  I've removed that and now it's even much, much faster.  I'll post the next benchmark shortly.", "creator": "mimecuvalo@gmail.com", "raw_text": "(In reply to comment #3)\n> 1) It includes the time to convert the string to an array in the array timing\n> for  the 1000x benchmark.\n\nI'll fix that in the next version of the benchmark but nonetheless it doesn't change the numbers much.\n\n> For the 100x benchmark, you're creating arrays with about 16000*100 entries,\n> which means 12.8MB of data.  The string equivalent there is about 6.4MB (since\n> you add dataToEncrypt to |c| twice for some reason), so cache effects might be\n> coming into play at that point to explain the performance difference.\n\nHuh, actually - it seems to be the opposite - the string one is incorrectly adding double the amount of data.  I've removed that and now it's even much, much faster.  I'll post the next benchmark shortly.", "id": 5331648, "author": "mimecuvalo@gmail.com", "is_private": false, "bug_id": 639979, "attachment_id": null, "creation_time": "2011-03-08T22:59:16Z", "tags": []}, {"id": 5331652, "is_private": false, "count": 7, "author": "mimecuvalo@gmail.com", "time": "2011-03-08T22:59:48Z", "bug_id": 639979, "text": "Created attachment 517888\nBenchmark v2", "attachment_id": 517888, "creation_time": "2011-03-08T22:59:48Z", "tags": [], "creator": "mimecuvalo@gmail.com", "raw_text": ""}, {"id": 5331683, "is_private": false, "time": "2011-03-08T23:09:21Z", "author": "mimecuvalo@gmail.com", "count": 8, "bug_id": 639979, "text": "Created attachment 517892\nBenchmark v3\n\nScratch that last benchmark, wasn't written correctly.\nThis one also now uses new Uint8Array(regularArray) as suggested by Jeff.\nStrings still faster than typed arrays, however. :-/", "creation_time": "2011-03-08T23:09:21Z", "tags": [], "attachment_id": 517892, "raw_text": "Scratch that last benchmark, wasn't written correctly.\nThis one also now uses new Uint8Array(regularArray) as suggested by Jeff.\nStrings still faster than typed arrays, however. :-/", "creator": "mimecuvalo@gmail.com"}, {"time": "2011-03-09T04:12:45Z", "author": "bzbarsky@mit.edu", "count": 9, "is_private": false, "id": 5332283, "raw_text": "> here doesn't seem to be a way to cast a regular array to a typed array\n\nRight; they're totally different kinds of objects that store totally different things (e.g. a typed array can store things that a regular array can't, really, and vice versa).\n\n> Huh, actually - it seems to be the opposite - the string one is incorrectly\n> adding double the amount of data.\n\nYes, I accounted for that.  The string was creating a string with 3.2 million JS characters in it.  JS characters are 2 bytes, so 6.4MB.  The array creating an array with 1.6 million entries, at 8 bytes each, so 12.8MB.\n\nIf you fix the string thing, then your string is 3.2MB, which likely fits in your L2/L3 cache entirely.  So yes, it would be way way faster than the untyped array of equivalent length.  On the other hand, the corresponding typed array would be 1.6MB, so if the length were doubled again chances are it would suddenly be faster than the string.....\n\nI'll look at the details of that last benchmark tomorrow morning; thanks for posting it!", "creator": "bzbarsky@mit.edu", "tags": [], "creation_time": "2011-03-09T04:12:45Z", "attachment_id": null, "text": "> here doesn't seem to be a way to cast a regular array to a typed array\n\nRight; they're totally different kinds of objects that store totally different things (e.g. a typed array can store things that a regular array can't, really, and vice versa).\n\n> Huh, actually - it seems to be the opposite - the string one is incorrectly\n> adding double the amount of data.\n\nYes, I accounted for that.  The string was creating a string with 3.2 million JS characters in it.  JS characters are 2 bytes, so 6.4MB.  The array creating an array with 1.6 million entries, at 8 bytes each, so 12.8MB.\n\nIf you fix the string thing, then your string is 3.2MB, which likely fits in your L2/L3 cache entirely.  So yes, it would be way way faster than the untyped array of equivalent length.  On the other hand, the corresponding typed array would be 1.6MB, so if the length were doubled again chances are it would suddenly be faster than the string.....\n\nI'll look at the details of that last benchmark tomorrow morning; thanks for posting it!", "bug_id": 639979}, {"creator": "mimecuvalo@gmail.com", "raw_text": "(In reply to comment #9)\n> Yes, I accounted for that.  The string was creating a string with 3.2 million\n> JS characters in it.  JS characters are 2 bytes, so 6.4MB.  The array creating\n> an array with 1.6 million entries, at 8 bytes each, so 12.8MB.\n\nInteresting - it's becoming much clearer to me now.\n\n> If you fix the string thing, then your string is 3.2MB, which likely fits in\n> your L2/L3 cache entirely.  So yes, it would be way way faster than the untyped\n> array of equivalent length.  On the other hand, the corresponding typed array\n> would be 1.6MB, so if the length were doubled again chances are it would\n> suddenly be faster than the string..... \n\nAh, I see.  Hmm, well hopefully I'm doing the benchmark of typed arrays correctly in the first place - I think you should double check that.", "attachment_id": null, "creation_time": "2011-03-09T09:34:47Z", "tags": [], "text": "(In reply to comment #9)\n> Yes, I accounted for that.  The string was creating a string with 3.2 million\n> JS characters in it.  JS characters are 2 bytes, so 6.4MB.  The array creating\n> an array with 1.6 million entries, at 8 bytes each, so 12.8MB.\n\nInteresting - it's becoming much clearer to me now.\n\n> If you fix the string thing, then your string is 3.2MB, which likely fits in\n> your L2/L3 cache entirely.  So yes, it would be way way faster than the untyped\n> array of equivalent length.  On the other hand, the corresponding typed array\n> would be 1.6MB, so if the length were doubled again chances are it would\n> suddenly be faster than the string..... \n\nAh, I see.  Hmm, well hopefully I'm doing the benchmark of typed arrays correctly in the first place - I think you should double check that.", "bug_id": 639979, "count": 10, "time": "2011-03-09T09:34:47Z", "author": "mimecuvalo@gmail.com", "is_private": false, "id": 5332611}, {"count": 11, "time": "2011-03-15T15:17:41Z", "text": "Created attachment 519409\nJS shell version of \"benchmark v3\" with no substantive modifications\n\nI just ripped out the NSS/blowfish stuff which is not relevant to the discussion here.  No other changes yet.", "creator": "bzbarsky@mit.edu", "raw_text": "I just ripped out the NSS/blowfish stuff which is not relevant to the discussion here.  No other changes yet.", "id": 5345778, "author": "bzbarsky@mit.edu", "is_private": false, "bug_id": 639979, "attachment_id": 519409, "creation_time": "2011-03-15T15:17:41Z", "tags": []}, {"attachment_id": null, "creation_time": "2011-03-15T16:11:03Z", "tags": [], "bug_id": 639979, "is_private": false, "author": "bzbarsky@mit.edu", "id": 5345876, "creator": "bzbarsky@mit.edu", "raw_text": "So some obvious things:\n\n* The \"concatenation, 1000x, ~16kb data\" benchmark runs totally different code for the string and typed array cases.  For the string case it takes two existing strings and repeatedly concatenates them.  For the array case it creates two new arrays each time through the loop, then creates an array buffer object for some reason, then creates a typed array using the array buffer, etc.  If I fix all this by just creating a typed array of the right length instead of creating intermediate array buffers and creating the data1 and data2 arrays up front before entering the loop (so we're just timing concatenation, not array creation, as for strings), then typed arrays are faster than strings here.\n\nThe normal array concat() case is all due to concat() being dumb.  This is bug 609896.\n\n* The \"concatenation, 100x, growing by ~16kb data\" benchmark has some of the same issues as the 1000x case (and some others as well, including the fact that the second set() call is passed the _untyped_ array, not the typed one).  If I fix them the same way, it gets a bit faster, but it's still slow compared to strings.  The reason is that we end up doing a new alloc+copy on every append with that code, which is NOT the case for strings: those use a doubling algorithm so they only have to alloc+copy every so often, at the cost of some wasted space.  If you cared you could of course duplicate that behavior with typed arrays.", "text": "So some obvious things:\n\n* The \"concatenation, 1000x, ~16kb data\" benchmark runs totally different code for the string and typed array cases.  For the string case it takes two existing strings and repeatedly concatenates them.  For the array case it creates two new arrays each time through the loop, then creates an array buffer object for some reason, then creates a typed array using the array buffer, etc.  If I fix all this by just creating a typed array of the right length instead of creating intermediate array buffers and creating the data1 and data2 arrays up front before entering the loop (so we're just timing concatenation, not array creation, as for strings), then typed arrays are faster than strings here.\n\nThe normal array concat() case is all due to concat() being dumb.  This is bug 609896.\n\n* The \"concatenation, 100x, growing by ~16kb data\" benchmark has some of the same issues as the 1000x case (and some others as well, including the fact that the second set() call is passed the _untyped_ array, not the typed one).  If I fix them the same way, it gets a bit faster, but it's still slow compared to strings.  The reason is that we end up doing a new alloc+copy on every append with that code, which is NOT the case for strings: those use a doubling algorithm so they only have to alloc+copy every so often, at the cost of some wasted space.  If you cared you could of course duplicate that behavior with typed arrays.", "count": 12, "time": "2011-03-15T16:11:03Z"}, {"id": 5345880, "is_private": false, "author": "bzbarsky@mit.edu", "bug_id": 639979, "attachment_id": 519418, "tags": [], "creation_time": "2011-03-15T16:13:01Z", "count": 13, "time": "2011-03-15T16:13:01Z", "text": "Created attachment 519418\nBenchmark v3 shell version with the object-allocation issues fixed, but without capacity-doubling for typed arrays.", "creator": "bzbarsky@mit.edu", "raw_text": ""}]}}}