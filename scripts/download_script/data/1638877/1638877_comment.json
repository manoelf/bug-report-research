{"bugs": {"1638877": {"comments": [{"creation_time": "2020-05-18T15:56:59Z", "creator": "alessio.placitelli@gmail.com", "tags": [], "count": 0, "time": "2020-05-18T15:56:59Z", "is_private": false, "text": "> org-mozilla-fennec-aurora org.everit.json.schema.ValidationException: #/client_info: required key [app_build] not found baseline 927\t\n\nWe're seeing a bunch of failures like the above across all the app ids. We should figure out why that's happening.", "raw_text": "> org-mozilla-fennec-aurora org.everit.json.schema.ValidationException: #/client_info: required key [app_build] not found baseline 927\t\n\nWe're seeing a bunch of failures like the above across all the app ids. We should figure out why that's happening.", "id": 14828762, "author": "alessio.placitelli@gmail.com", "bug_id": 1638877, "attachment_id": null}, {"creator": "tlong@mozilla.com", "author": "tlong@mozilla.com", "creation_time": "2020-05-27T18:01:32Z", "id": 14846928, "text": "Maybe this has something to do with [the way we are getting this info](https://github.com/mozilla/glean/blob/92c586510120d9a442036550edab175355639f74/glean-core/android/src/main/java/mozilla/telemetry/glean/Glean.kt#L452) being [deprecated](https://developer.android.com/reference/kotlin/android/content/pm/PackageInfo#versioncode)?  It says deprecated since API level 28, so I wonder if this is mostly newer devices?", "raw_text": "Maybe this has something to do with [the way we are getting this info](https://github.com/mozilla/glean/blob/92c586510120d9a442036550edab175355639f74/glean-core/android/src/main/java/mozilla/telemetry/glean/Glean.kt#L452) being [deprecated](https://developer.android.com/reference/kotlin/android/content/pm/PackageInfo#versioncode)?  It says deprecated since API level 28, so I wonder if this is mostly newer devices?", "is_private": false, "attachment_id": null, "time": "2020-05-27T18:01:32Z", "count": 1, "bug_id": 1638877, "tags": []}, {"id": 14848996, "author": "alessio.placitelli@gmail.com", "is_private": false, "text": "(In reply to Travis Long [:travis_] from comment #1)\n> Maybe this has something to do with [the way we are getting this info](https://github.com/mozilla/glean/blob/92c586510120d9a442036550edab175355639f74/glean-core/android/src/main/java/mozilla/telemetry/glean/Glean.kt#L452) being [deprecated](https://developer.android.com/reference/kotlin/android/content/pm/PackageInfo#versioncode)?  It says deprecated since API level 28, so I wonder if this is mostly newer devices?\n\nMaybe, but I'd be very surprised. Deprecated doesn't mean removed :)", "raw_text": "(In reply to Travis Long [:travis_] from comment #1)\n> Maybe this has something to do with [the way we are getting this info](https://github.com/mozilla/glean/blob/92c586510120d9a442036550edab175355639f74/glean-core/android/src/main/java/mozilla/telemetry/glean/Glean.kt#L452) being [deprecated](https://developer.android.com/reference/kotlin/android/content/pm/PackageInfo#versioncode)?  It says deprecated since API level 28, so I wonder if this is mostly newer devices?\n\nMaybe, but I'd be very surprised. Deprecated doesn't mean removed :)", "attachment_id": null, "bug_id": 1638877, "creation_time": "2020-05-28T10:16:22Z", "creator": "alessio.placitelli@gmail.com", "time": "2020-05-28T10:16:22Z", "tags": [], "count": 2}, {"creator": "alessio.placitelli@gmail.com", "creation_time": "2020-06-22T12:00:10Z", "count": 3, "tags": [], "time": "2020-06-22T12:00:10Z", "raw_text": "", "text": "*** Bug 1646822 has been marked as a duplicate of this bug. ***", "is_private": false, "author": "alessio.placitelli@gmail.com", "id": 14893788, "bug_id": 1638877, "attachment_id": null}, {"is_private": false, "text": "There are more missing elements than just `app_build` -- it just seems that that is the first one to be checked by the schema validator so it comes up first.  It actually looks like there is anywhere between 1-9 elements missing from `client_info`.\n\nLooking at the first 500 of these errors: https://sql.telemetry.mozilla.org/queries/72154\n\nThe missing elements always match the order in which they are set in `initializeCoreMetrics` -- that is, the ones that are missing are always contiguous and at the end of the order they are set in that function.  This suggests to me that there is a race condition between `initializeCoreMetrics` and ping collection.\n\nThe Python script to confirm this observation.\n\n```python\nimport csv\nimport base64\nimport gzip\nimport json\n\nrows = csv.reader(open(\"Glean_Validation_Errors_2020_06_22.csv\"))\n\nentries = []\nrow = next(rows)\n\nidx = row.index(\"payload\")\n\nsets = set()\n\nfor row in rows:\n    x = base64.b64decode(row[idx])\n    x = gzip.decompress(x)\n    x = json.loads(x)\n    entries.append(x)\n\n    sets.add(tuple(sorted(list(x[\"client_info\"].keys()))))\n\norder = [\n    \"android_sdk_version\",\n    \"os_version\",\n    \"device_manufacturer\",\n    \"device_model\",\n    \"architecture\",\n    \"app_channel\",\n    \"app_build\",\n    \"app_display_version\",\n]\n\nfor set in sets:\n    indices = sorted([order.index(x) for x in set if x in order])\n    if indices != list(range(len(indices))):\n        print(set)\n```\n\nNow to find a way to prevent the race condition.", "raw_text": "There are more missing elements than just `app_build` -- it just seems that that is the first one to be checked by the schema validator so it comes up first.  It actually looks like there is anywhere between 1-9 elements missing from `client_info`.\n\nLooking at the first 500 of these errors: https://sql.telemetry.mozilla.org/queries/72154\n\nThe missing elements always match the order in which they are set in `initializeCoreMetrics` -- that is, the ones that are missing are always contiguous and at the end of the order they are set in that function.  This suggests to me that there is a race condition between `initializeCoreMetrics` and ping collection.\n\nThe Python script to confirm this observation.\n\n```python\nimport csv\nimport base64\nimport gzip\nimport json\n\nrows = csv.reader(open(\"Glean_Validation_Errors_2020_06_22.csv\"))\n\nentries = []\nrow = next(rows)\n\nidx = row.index(\"payload\")\n\nsets = set()\n\nfor row in rows:\n    x = base64.b64decode(row[idx])\n    x = gzip.decompress(x)\n    x = json.loads(x)\n    entries.append(x)\n\n    sets.add(tuple(sorted(list(x[\"client_info\"].keys()))))\n\norder = [\n    \"android_sdk_version\",\n    \"os_version\",\n    \"device_manufacturer\",\n    \"device_model\",\n    \"architecture\",\n    \"app_channel\",\n    \"app_build\",\n    \"app_display_version\",\n]\n\nfor set in sets:\n    indices = sorted([order.index(x) for x in set if x in order])\n    if indices != list(range(len(indices))):\n        print(set)\n```\n\nNow to find a way to prevent the race condition.", "author": "mdroettboom@mozilla.com", "id": 14894722, "bug_id": 1638877, "attachment_id": null, "creation_time": "2020-06-22T18:22:52Z", "creator": "mdroettboom@mozilla.com", "tags": [], "count": 4, "time": "2020-06-22T18:22:52Z"}, {"time": "2020-06-22T18:46:31Z", "attachment_id": 9158309, "tags": [], "bug_id": 1638877, "count": 5, "creation_time": "2020-06-22T18:46:31Z", "id": 14894817, "author": "pulgasaur@mozilla.bugs", "creator": "pulgasaur@mozilla.bugs", "is_private": false, "raw_text": "", "text": "Created attachment 9158309\nLink to GitHub pull-request: https://github.com/mozilla/glean/pull/996"}, {"attachment_id": null, "bug_id": 1638877, "author": "mdroettboom@mozilla.com", "id": 14896596, "is_private": false, "raw_text": "More info: This behavior described in the previous comment is only present in the `dirty_startup` ping.  The `foreground` and `background` pings either have *all* core metrics or *none*.", "text": "More info: This behavior described in the previous comment is only present in the `dirty_startup` ping.  The `foreground` and `background` pings either have *all* core metrics or *none*.", "time": "2020-06-23T14:52:22Z", "tags": [], "count": 6, "creation_time": "2020-06-23T14:52:22Z", "creator": "mdroettboom@mozilla.com"}, {"is_private": false, "text": "I cast my vote for not saving or sending a `dirty_startup` ping if it doesn't have all its core metrics (recording an error metric in that case so we can monitor the number of pings we're not sending as a result)", "raw_text": "I cast my vote for not saving or sending a `dirty_startup` ping if it doesn't have all its core metrics (recording an error metric in that case so we can monitor the number of pings we're not sending as a result)", "author": "chutten@mozilla.com", "id": 14896614, "bug_id": 1638877, "attachment_id": null, "creation_time": "2020-06-23T15:00:32Z", "creator": "chutten@mozilla.com", "tags": [], "count": 7, "time": "2020-06-23T15:00:32Z"}, {"creator": "mdroettboom@mozilla.com", "creation_time": "2020-06-23T15:02:30Z", "time": "2020-06-23T15:02:30Z", "count": 8, "tags": [], "author": "mdroettboom@mozilla.com", "id": 14896618, "text": "This seems to suggest what is happening is that Fenix is stopping *while* initializeCoreMetrics is running.  Upon the next startup, the dirty_startup ping is sent with incomplete data (it's only after this that it's filled in again).\n\nWe have a few imperfect options to resolve this:\n\n1) Don't send a dirty startup ping if some of these values are missing in the database -- if the previous session was really so short, maybe the data's not interesting anyway.  This, from a data analysis perspective, is the same situation we have now since the pings are being dropped at the endpoint.\n\n2) Fill in the missing values with \"unknown\" values so they pass the schema validation and get entered into the database.\n\n3) Fill in the core metrics *before* sending the `dirty_startup` ping.  This wouldn't *strictly* be correct, because we could have updated the app, causing a number of the values to change since we last ran.  But for baseline pings, does that edge case matter?", "raw_text": "This seems to suggest what is happening is that Fenix is stopping *while* initializeCoreMetrics is running.  Upon the next startup, the dirty_startup ping is sent with incomplete data (it's only after this that it's filled in again).\n\nWe have a few imperfect options to resolve this:\n\n1) Don't send a dirty startup ping if some of these values are missing in the database -- if the previous session was really so short, maybe the data's not interesting anyway.  This, from a data analysis perspective, is the same situation we have now since the pings are being dropped at the endpoint.\n\n2) Fill in the missing values with \"unknown\" values so they pass the schema validation and get entered into the database.\n\n3) Fill in the core metrics *before* sending the `dirty_startup` ping.  This wouldn't *strictly* be correct, because we could have updated the app, causing a number of the values to change since we last ran.  But for baseline pings, does that edge case matter?", "is_private": false, "attachment_id": null, "bug_id": 1638877}, {"bug_id": 1638877, "attachment_id": null, "is_private": false, "text": "(In reply to Michael Droettboom [:mdroettboom] from comment #6)\n> More info: This behavior described in the previous comment is only present in the `dirty_startup` ping.  The `foreground` and `background` pings either have *all* core metrics or *none*.\n\nThis is probably indicating a second problem: maybe Fenix had a startup crash?", "raw_text": "(In reply to Michael Droettboom [:mdroettboom] from comment #6)\n> More info: This behavior described in the previous comment is only present in the `dirty_startup` ping.  The `foreground` and `background` pings either have *all* core metrics or *none*.\n\nThis is probably indicating a second problem: maybe Fenix had a startup crash?", "author": "alessio.placitelli@gmail.com", "id": 14896619, "tags": [], "count": 9, "time": "2020-06-23T15:02:59Z", "creation_time": "2020-06-23T15:02:59Z", "creator": "alessio.placitelli@gmail.com"}, {"attachment_id": null, "bug_id": 1638877, "author": "mdroettboom@mozilla.com", "id": 14896635, "is_private": false, "text": "(In reply to Alessio Placitelli [:Dexter] from comment #9)\n> (In reply to Michael Droettboom [:mdroettboom] from comment #6)\n> > More info: This behavior described in the previous comment is only present in the `dirty_startup` ping.  The `foreground` and `background` pings either have *all* core metrics or *none*.\n> \n> This is probably indicating a second problem: maybe Fenix had a startup crash?\n\nHmm...  I wonder if there's any way to correlate with the Sentry data (probably not).  I don't think we have any way of distinguishing a crash from a \"the OS just suddenly shut us down because it can\" event.", "raw_text": "(In reply to Alessio Placitelli [:Dexter] from comment #9)\n> (In reply to Michael Droettboom [:mdroettboom] from comment #6)\n> > More info: This behavior described in the previous comment is only present in the `dirty_startup` ping.  The `foreground` and `background` pings either have *all* core metrics or *none*.\n> \n> This is probably indicating a second problem: maybe Fenix had a startup crash?\n\nHmm...  I wonder if there's any way to correlate with the Sentry data (probably not).  I don't think we have any way of distinguishing a crash from a \"the OS just suddenly shut us down because it can\" event.", "time": "2020-06-23T15:08:29Z", "tags": [], "count": 10, "creation_time": "2020-06-23T15:08:29Z", "creator": "mdroettboom@mozilla.com"}, {"time": "2020-06-23T15:11:26Z", "tags": [], "count": 11, "creation_time": "2020-06-23T15:11:26Z", "creator": "mdroettboom@mozilla.com", "attachment_id": null, "bug_id": 1638877, "id": 14896641, "author": "mdroettboom@mozilla.com", "is_private": false, "raw_text": "Another option (4): we don't set the dirty bit until Glean has successfully completed initialization.  That way, if we \"crash\" or \"stop\" during Glean initialization, we won't get a dirty_startup ping the next time.", "text": "Another option (4): we don't set the dirty bit until Glean has successfully completed initialization.  That way, if we \"crash\" or \"stop\" during Glean initialization, we won't get a dirty_startup ping the next time."}]}}, "comments": {}}