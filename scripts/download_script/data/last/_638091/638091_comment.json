{"comments": {}, "bugs": {"638091": {"comments": [{"id": 5315140, "is_private": false, "author": "hv1989@gmail.com", "bug_id": 638091, "attachment_id": null, "tags": [], "creation_time": "2011-03-02T15:12:18Z", "count": 0, "time": "2011-03-02T15:12:18Z", "text": "User-Agent:       Mozilla/5.0 (X11; Linux i686; rv:2.0b13pre) Gecko/20110302 Firefox/4.0b13pre\nBuild Identifier: \n\nIn string matching when the pattern length is longer than 255 (sBMHPatLenMax), UnrolledMatch<MemCmp> is used or UnrolledMatch<ManualCmp>. In my case (linux) the slower manual loop is used.\n\nThe complexity of the manual loop is O(mn). (m=patternlength, n=textlength) So it isn't that good.\n\nShift-and has the same complexity O(mn), but has some interesting characteristic. Searching itself is actually 0(mn/31). So when the pattern length is lower then is lower then 32. The complexity is actually 0(n). In simulations I've done it's quite obvious that it is linear, but the overhead is to big and BMH is faster for smaller patterns.\n\nBut BHM only works untill a pattern length of 255. Then the shift-and algorithm with some adjustments becomes interesting. The adjustments are as following: use the shift-and algorithm on the first 31 characters of the pattern. When a match is found in the text, use the slower manual loop to check the other part of the pattern. Mostly the slower manual loop is only once used. Because if the first 31 characters match, the chance is quite high the other will match too.\nA nice thing about this implementation is that even in the worst case, when the manual loop is always executed it will be faster or as fast as the manual loop.\n\nNow some timings\n\n- text with 13033779 characters, query had 1722 characters:\n\nWithout shift-and:\nreal\t0m0.941s\nreal\t0m0.933s\nreal\t0m0.945s\nreal\t0m0.943s\n\nWith shift-and:\nreal\t0m0.908s\nreal\t0m0.926s\nreal\t0m0.920s\nreal\t0m0.919s\nreal\t0m0.921s\n\n- Took \"best BMH/normal ratio\" testcase from bug #526348\nI altered it to start with patterns with length 33. I also disabled BHM.\n\nWithout shift-and:\n415 424 434 443 450 455 469 473 486 486 504 503 514 514 528 548 544\n\nWith shift-and:\n343 352 360 370 381 387 400 405 412 426 432 445 450 462 465 478 484 \n\nMy questions: is it worthwhile to keep looking into this? Or is the speedup negligible? I also don't know much MemCmp is faster then ManualCmp? I suppose this would be linux-only, because I think MemCmp is much faster because of the use of SIMD?\n\nReproducible: Always", "creator": "hv1989@gmail.com", "raw_text": "User-Agent:       Mozilla/5.0 (X11; Linux i686; rv:2.0b13pre) Gecko/20110302 Firefox/4.0b13pre\nBuild Identifier: \n\nIn string matching when the pattern length is longer than 255 (sBMHPatLenMax), UnrolledMatch<MemCmp> is used or UnrolledMatch<ManualCmp>. In my case (linux) the slower manual loop is used.\n\nThe complexity of the manual loop is O(mn). (m=patternlength, n=textlength) So it isn't that good.\n\nShift-and has the same complexity O(mn), but has some interesting characteristic. Searching itself is actually 0(mn/31). So when the pattern length is lower then is lower then 32. The complexity is actually 0(n). In simulations I've done it's quite obvious that it is linear, but the overhead is to big and BMH is faster for smaller patterns.\n\nBut BHM only works untill a pattern length of 255. Then the shift-and algorithm with some adjustments becomes interesting. The adjustments are as following: use the shift-and algorithm on the first 31 characters of the pattern. When a match is found in the text, use the slower manual loop to check the other part of the pattern. Mostly the slower manual loop is only once used. Because if the first 31 characters match, the chance is quite high the other will match too.\nA nice thing about this implementation is that even in the worst case, when the manual loop is always executed it will be faster or as fast as the manual loop.\n\nNow some timings\n\n- text with 13033779 characters, query had 1722 characters:\n\nWithout shift-and:\nreal\t0m0.941s\nreal\t0m0.933s\nreal\t0m0.945s\nreal\t0m0.943s\n\nWith shift-and:\nreal\t0m0.908s\nreal\t0m0.926s\nreal\t0m0.920s\nreal\t0m0.919s\nreal\t0m0.921s\n\n- Took \"best BMH/normal ratio\" testcase from bug #526348\nI altered it to start with patterns with length 33. I also disabled BHM.\n\nWithout shift-and:\n415 424 434 443 450 455 469 473 486 486 504 503 514 514 528 548 544\n\nWith shift-and:\n343 352 360 370 381 387 400 405 412 426 432 445 450 462 465 478 484 \n\nMy questions: is it worthwhile to keep looking into this? Or is the speedup negligible? I also don't know much MemCmp is faster then ManualCmp? I suppose this would be linux-only, because I think MemCmp is much faster because of the use of SIMD?\n\nReproducible: Always"}, {"creator": "hv1989@gmail.com", "raw_text": "This patch adds the shift-and algorithm. Code works, but doesn't follow the guidelines atm.", "attachment_id": 516263, "tags": [], "creation_time": "2011-03-02T15:14:34Z", "text": "Created attachment 516263\nTemporary patch\n\nThis patch adds the shift-and algorithm. Code works, but doesn't follow the guidelines atm.", "bug_id": 638091, "count": 1, "time": "2011-03-02T15:14:34Z", "author": "hv1989@gmail.com", "is_private": false, "id": 5315144}, {"bug_id": 638091, "attachment_id": null, "creation_time": "2011-03-02T15:30:38Z", "tags": [], "id": 5315186, "author": "bzbarsky@mit.edu", "is_private": false, "text": "> I also don't know much MemCmp is faster then ManualCmp? \n\nOn Linux it's not; that's why ManualCmp is used there...  We can't tell what the heck the glibc memcmp is doing, but it's slow...\n\nLuke, want to take a look at that patch?", "creator": "bzbarsky@mit.edu", "raw_text": "> I also don't know much MemCmp is faster then ManualCmp? \n\nOn Linux it's not; that's why ManualCmp is used there...  We can't tell what the heck the glibc memcmp is doing, but it's slow...\n\nLuke, want to take a look at that patch?", "count": 2, "time": "2011-03-02T15:30:38Z"}, {"creator": "mail@lukewagner.name", "raw_text": "I like the idea of using a smart algorithm up to some max pattern size and then falling back to the basic O(mn) loop past that.\n\nBoth BMH and shift-and have an up-front pre-processing cost and a small per-iteration cost (compared to the basic O(mn) algorithm) which is payed in  speculation that the algorithm will pay off.  The BMH payoff is that it can skip characters.  IIUC, the shift-and payoff is that the algorithm will be linear even with short partial matches.  In this comparison, the BMH return on investment seems better given comparable investments.\n\nHowever, the additional benefit of the shift-and code you've demonstrated is that it can still be used for longer patterns.  So that raises the question: can BMH be modified, similar to your shift-and code, to work for longer patterns?  If so, then we could get the super-linear behavior of BMH even for long patterns with partial matches of length < sBMHPatLenMax.", "text": "I like the idea of using a smart algorithm up to some max pattern size and then falling back to the basic O(mn) loop past that.\n\nBoth BMH and shift-and have an up-front pre-processing cost and a small per-iteration cost (compared to the basic O(mn) algorithm) which is payed in  speculation that the algorithm will pay off.  The BMH payoff is that it can skip characters.  IIUC, the shift-and payoff is that the algorithm will be linear even with short partial matches.  In this comparison, the BMH return on investment seems better given comparable investments.\n\nHowever, the additional benefit of the shift-and code you've demonstrated is that it can still be used for longer patterns.  So that raises the question: can BMH be modified, similar to your shift-and code, to work for longer patterns?  If so, then we could get the super-linear behavior of BMH even for long patterns with partial matches of length < sBMHPatLenMax.", "count": 3, "time": "2011-03-02T19:38:36Z", "attachment_id": null, "tags": [], "creation_time": "2011-03-02T19:38:36Z", "bug_id": 638091, "author": "mail@lukewagner.name", "is_private": false, "id": 5316043}, {"attachment_id": 516429, "creation_time": "2011-03-02T23:22:53Z", "tags": [], "creator": "hv1989@gmail.com", "raw_text": "Like requested the BMH variant. Again this is not final. (e.g. not using MemCmp when possible)\n\n- text with 13033779 characters, query had 1722 characters:\n\nreal\t0m0.921s\nreal\t0m0.905s\nreal\t0m0.917s\nreal\t0m0.917s\nreal\t0m0.919s\n\nbetter then the loop. Same as shift-and variant. Still I would have thought this would be a bit faster then shift-and. Well probably because there is only one full hit. (There is only one time that the first 255 are the same and that is the hit too.). So actually not a real good testcase. \n\nI'm not sure how to test it with the memcmp (I'm on Linux). But I think it would be interesting to know if the hybrid is faster then memcmp alone.", "bug_id": 638091, "text": "Created attachment 516429\nBMH adjusted\n\nLike requested the BMH variant. Again this is not final. (e.g. not using MemCmp when possible)\n\n- text with 13033779 characters, query had 1722 characters:\n\nreal\t0m0.921s\nreal\t0m0.905s\nreal\t0m0.917s\nreal\t0m0.917s\nreal\t0m0.919s\n\nbetter then the loop. Same as shift-and variant. Still I would have thought this would be a bit faster then shift-and. Well probably because there is only one full hit. (There is only one time that the first 255 are the same and that is the hit too.). So actually not a real good testcase. \n\nI'm not sure how to test it with the memcmp (I'm on Linux). But I think it would be interesting to know if the hybrid is faster then memcmp alone.", "is_private": false, "count": 4, "author": "hv1989@gmail.com", "time": "2011-03-02T23:22:53Z", "id": 5316847}, {"creator": "n.nethercote@gmail.com", "raw_text": "What data are you measuring with?  It'd be good to know if this is affecting real sites.", "text": "What data are you measuring with?  It'd be good to know if this is affecting real sites.", "count": 5, "time": "2011-03-03T06:13:21Z", "attachment_id": null, "tags": [], "creation_time": "2011-03-03T06:13:21Z", "bug_id": 638091, "author": "n.nethercote@gmail.com", "is_private": false, "id": 5317683}, {"bug_id": 638091, "text": "(In reply to comment #5)\n> What data are you measuring with?\n\n- The data is a sequence. So small alphabet (c,t,g,a).\n\n> It'd be good to know if this is affecting real sites.\n\n- I didn't find a site using patterns longer then 255 chars yet. If I do I will definitely run some benchmarks on it.\n\nI did another test, now with a bigger alphabet. So more in line with real searches.\nI took 203733904 characters of lorem ipsum from http://www.lipsum.com.\nAnd for the query/pattern I took the last line (400 characters)\n\n- The loop: \n\nreal\t0m0.974s\nreal\t0m0.935s\nreal\t0m0.953s\n\n- Shift-and algorithm (the loop is really really optimized. Shift-and could use the same optimization (like loop unrolling))\n\nreal\t0m1.731s\nreal\t0m1.727s\nreal\t0m1.743s\nreal\t0m1.736s\n\n- adjusted BMH\n\nreal\t0m0.755s\nreal\t0m0.752s\nreal\t0m0.759s\n\nIn this case it is really clear the adjusted-BMH would be faster.\n\nNote 1: if I need to add my tests, just let me know\nNote 2: I'm leaving Friday for a week. So I won't posting updates next week.", "creation_time": "2011-03-03T13:07:22Z", "tags": [], "attachment_id": null, "raw_text": "(In reply to comment #5)\n> What data are you measuring with?\n\n- The data is a sequence. So small alphabet (c,t,g,a).\n\n> It'd be good to know if this is affecting real sites.\n\n- I didn't find a site using patterns longer then 255 chars yet. If I do I will definitely run some benchmarks on it.\n\nI did another test, now with a bigger alphabet. So more in line with real searches.\nI took 203733904 characters of lorem ipsum from http://www.lipsum.com.\nAnd for the query/pattern I took the last line (400 characters)\n\n- The loop: \n\nreal\t0m0.974s\nreal\t0m0.935s\nreal\t0m0.953s\n\n- Shift-and algorithm (the loop is really really optimized. Shift-and could use the same optimization (like loop unrolling))\n\nreal\t0m1.731s\nreal\t0m1.727s\nreal\t0m1.743s\nreal\t0m1.736s\n\n- adjusted BMH\n\nreal\t0m0.755s\nreal\t0m0.752s\nreal\t0m0.759s\n\nIn this case it is really clear the adjusted-BMH would be faster.\n\nNote 1: if I need to add my tests, just let me know\nNote 2: I'm leaving Friday for a week. So I won't posting updates next week.", "creator": "hv1989@gmail.com", "id": 5318207, "is_private": false, "time": "2011-03-03T13:07:22Z", "author": "hv1989@gmail.com", "count": 6}, {"bug_id": 638091, "tags": [], "creation_time": "2011-03-03T19:21:24Z", "attachment_id": null, "id": 5319373, "is_private": false, "author": "mail@lukewagner.name", "text": "(In reply to comment #6)\n\nThanks for trying out the adjusted-BMH and continuing experimentation.  Using lorem ipsum was a good idea.  Since random English doesn't seem like it would cause the O(mn) worst-case of \"The loop\" to manifest often, it doesn't surprise me that Shift-and would be slower than \"The loop\", unrolling or not, since Shift-and is doing more work per iteration.  The perf of adjusted-BMH is exciting and makes me wonder how much more speedup we could get by uglifying BMH with unrolling analogous to The loop.\n\nSince we are in fancy/speculative-algorithm territory, it would be good to get a few more \"real world\" measurements before seriously considering landing a change.  Lorem ipsum is probably a good sample of English searches, but the web probably has a lot of weird searches that aren't like English.  One idea would be to hack up a browser build to print out the text/pattern for every Nth search, surf around for a bit, and turn the resulting log into a benchmark.  Also useful would be to measure, for this harvested benchmark the average text/pattern length, variance, and max.\n\nIf comment 6 is any predictor, it seems like there is some real optimization potential here, so I hope you are still interested in pursuing this :)", "raw_text": "(In reply to comment #6)\n\nThanks for trying out the adjusted-BMH and continuing experimentation.  Using lorem ipsum was a good idea.  Since random English doesn't seem like it would cause the O(mn) worst-case of \"The loop\" to manifest often, it doesn't surprise me that Shift-and would be slower than \"The loop\", unrolling or not, since Shift-and is doing more work per iteration.  The perf of adjusted-BMH is exciting and makes me wonder how much more speedup we could get by uglifying BMH with unrolling analogous to The loop.\n\nSince we are in fancy/speculative-algorithm territory, it would be good to get a few more \"real world\" measurements before seriously considering landing a change.  Lorem ipsum is probably a good sample of English searches, but the web probably has a lot of weird searches that aren't like English.  One idea would be to hack up a browser build to print out the text/pattern for every Nth search, surf around for a bit, and turn the resulting log into a benchmark.  Also useful would be to measure, for this harvested benchmark the average text/pattern length, variance, and max.\n\nIf comment 6 is any predictor, it seems like there is some real optimization potential here, so I hope you are still interested in pursuing this :)", "creator": "mail@lukewagner.name", "time": "2011-03-03T19:21:24Z", "count": 7}, {"raw_text": "(In reply to comment #7)\n\nI like the idea of creating a benchmark with real life search examples. It would be easier to track if the changes don't regress the search speed and it would definitely help to have some data of 255+ pattern length searches.\n\nI'm willing to test the loop unrolling. I'm also curious how much it would improve BMH. I'll do that when I'm back.", "creator": "hv1989@gmail.com", "text": "(In reply to comment #7)\n\nI like the idea of creating a benchmark with real life search examples. It would be easier to track if the changes don't regress the search speed and it would definitely help to have some data of 255+ pattern length searches.\n\nI'm willing to test the loop unrolling. I'm also curious how much it would improve BMH. I'll do that when I'm back.", "time": "2011-03-04T12:16:58Z", "count": 8, "tags": [], "creation_time": "2011-03-04T12:16:58Z", "attachment_id": null, "bug_id": 638091, "author": "hv1989@gmail.com", "is_private": false, "id": 5321334}, {"id": 5341092, "is_private": false, "author": "hv1989@gmail.com", "time": "2011-03-12T14:30:14Z", "count": 9, "bug_id": 638091, "text": "I've looked a bit further. No loop unrolling yet. Couldn't find any speedup by using it, yet. \n\nBut I've updated my patch to be faster. In my patch there was first a loop running untill the 'reduced' pattern was matched and afterwards a new loop was ran to match the whole pattern. So now I only run the loop to match the whole pattern.\n\nThe times listed here are again from \"lorem ipsum\"\n\n- no patch applied:\nreal\t0m1.015s\nreal\t0m1.001s\nreal\t0m0.983s\nreal\t0m0.996s\nreal\t0m1.042s\nreal\t0m0.997s\n\n- using the patch \"adjusted BMH\":\nreal\t0m0.814s\nreal\t0m0.804s\nreal\t0m0.816s\nreal\t0m0.802s\nreal\t0m0.807s\n\n- using the new patch \"improved adjusted BMH\":\nreal\t0m0.792s\nreal\t0m0.799s\nreal\t0m0.784s\nreal\t0m0.779s\nreal\t0m0.792s\nreal\t0m0.774s\nreal\t0m0.782s\nreal\t0m0.776s", "tags": [], "creation_time": "2011-03-12T14:30:14Z", "attachment_id": null, "raw_text": "I've looked a bit further. No loop unrolling yet. Couldn't find any speedup by using it, yet. \n\nBut I've updated my patch to be faster. In my patch there was first a loop running untill the 'reduced' pattern was matched and afterwards a new loop was ran to match the whole pattern. So now I only run the loop to match the whole pattern.\n\nThe times listed here are again from \"lorem ipsum\"\n\n- no patch applied:\nreal\t0m1.015s\nreal\t0m1.001s\nreal\t0m0.983s\nreal\t0m0.996s\nreal\t0m1.042s\nreal\t0m0.997s\n\n- using the patch \"adjusted BMH\":\nreal\t0m0.814s\nreal\t0m0.804s\nreal\t0m0.816s\nreal\t0m0.802s\nreal\t0m0.807s\n\n- using the new patch \"improved adjusted BMH\":\nreal\t0m0.792s\nreal\t0m0.799s\nreal\t0m0.784s\nreal\t0m0.779s\nreal\t0m0.792s\nreal\t0m0.774s\nreal\t0m0.782s\nreal\t0m0.776s", "creator": "hv1989@gmail.com"}, {"bug_id": 638091, "text": "Created attachment 518937\nImproved adjusted BMH", "tags": [], "creation_time": "2011-03-12T14:31:36Z", "attachment_id": 518937, "raw_text": "", "creator": "hv1989@gmail.com", "id": 5341093, "is_private": false, "time": "2011-03-12T14:31:36Z", "author": "hv1989@gmail.com", "count": 10}, {"id": 5341110, "is_private": false, "author": "hv1989@gmail.com", "bug_id": 638091, "tags": [], "creation_time": "2011-03-12T14:58:52Z", "attachment_id": 518940, "time": "2011-03-12T14:58:52Z", "count": 11, "text": "Created attachment 518940\nTestcase: lorum ipsum", "raw_text": "", "creator": "hv1989@gmail.com"}, {"count": 12, "time": "2011-03-12T15:09:15Z", "creator": "hv1989@gmail.com", "raw_text": "I adjusted the patch to use memcmp. This is to test if the loop is faster or memcmp is faster on windows/mac. If somebody is willing to test the speed-up on those platforms please go ahead. Just report the time it uses to complete the added testcase without any patches, with the \"improved adjusted BMH\" patch and afterwards with the \"Improved adjusted BMH using memcmp\".", "text": "Created attachment 518941\nImproved adjusted BMH using memcmp\n\nI adjusted the patch to use memcmp. This is to test if the loop is faster or memcmp is faster on windows/mac. If somebody is willing to test the speed-up on those platforms please go ahead. Just report the time it uses to complete the added testcase without any patches, with the \"improved adjusted BMH\" patch and afterwards with the \"Improved adjusted BMH using memcmp\".", "author": "hv1989@gmail.com", "is_private": false, "id": 5341115, "attachment_id": 518941, "creation_time": "2011-03-12T15:09:15Z", "tags": [], "bug_id": 638091}, {"is_private": false, "count": 13, "time": "2011-04-02T06:56:47Z", "author": "mail@lukewagner.name", "id": 5388077, "attachment_id": null, "tags": [], "creation_time": "2011-04-02T06:56:47Z", "creator": "mail@lukewagner.name", "raw_text": "I just came across this:\nhttp://lists.freebsd.org/pipermail/freebsd-current/2010-August/019310.html\nThe part that I found relevant was Boyer-Moore+unrolling :)", "bug_id": 638091, "text": "I just came across this:\nhttp://lists.freebsd.org/pipermail/freebsd-current/2010-August/019310.html\nThe part that I found relevant was Boyer-Moore+unrolling :)"}, {"id": 5388486, "author": "hv1989@gmail.com", "time": "2011-04-02T18:15:15Z", "count": 14, "is_private": false, "text": "(In reply to comment #13)\n> I just came across this:\n> http://lists.freebsd.org/pipermail/freebsd-current/2010-August/019310.html\n> The part that I found relevant was Boyer-Moore+unrolling :)\n\nThat post is indeed very interesting. The loop unrolling is different then I have done and I expect some improvements there. Also they use another shift implementation. I'll try to implement that as fast as possible, but I'm having a lot of work and because of that I haven't been able to update/test as regular as I wanted.\n\nNow I've been able to build a windows build to see the difference in performance between the patch with memcmp and without.\n\nthe lorem testcase:\n\nwithout patch:\n0m0.772s\n0m0.765s\n0m0.774s\n0m0.769s\n0m0.762s\n0m0.769s\n\npatch without memcmp\n0m0.638s\n0m0.636s\n0m0.632s\n0m0.636s\n0m0.669s\n0m0.637s\n0m0.674s\n\npatch with memcmp\n0m0.656s\n0m0.657s\n0m0.661s\n0m0.658s\n0m0.670s\n0m0.662s\n0m0.664s\n\nThe only thing I can conclude atm is that the performance is better with patch. The performance between 'with memcmp' and 'without memcmp' isn't that much. It is in favor for 'without memcmp', but maybe the difference isn't big enough to rule it out.", "bug_id": 638091, "raw_text": "(In reply to comment #13)\n> I just came across this:\n> http://lists.freebsd.org/pipermail/freebsd-current/2010-August/019310.html\n> The part that I found relevant was Boyer-Moore+unrolling :)\n\nThat post is indeed very interesting. The loop unrolling is different then I have done and I expect some improvements there. Also they use another shift implementation. I'll try to implement that as fast as possible, but I'm having a lot of work and because of that I haven't been able to update/test as regular as I wanted.\n\nNow I've been able to build a windows build to see the difference in performance between the patch with memcmp and without.\n\nthe lorem testcase:\n\nwithout patch:\n0m0.772s\n0m0.765s\n0m0.774s\n0m0.769s\n0m0.762s\n0m0.769s\n\npatch without memcmp\n0m0.638s\n0m0.636s\n0m0.632s\n0m0.636s\n0m0.669s\n0m0.637s\n0m0.674s\n\npatch with memcmp\n0m0.656s\n0m0.657s\n0m0.661s\n0m0.658s\n0m0.670s\n0m0.662s\n0m0.664s\n\nThe only thing I can conclude atm is that the performance is better with patch. The performance between 'with memcmp' and 'without memcmp' isn't that much. It is in favor for 'without memcmp', but maybe the difference isn't big enough to rule it out.", "creator": "hv1989@gmail.com", "tags": [], "creation_time": "2011-04-02T18:15:15Z", "attachment_id": null}, {"text": "Is this still actual?", "creator": "pppx@i.com.ua", "raw_text": "Is this still actual?", "count": 15, "time": "2012-03-07T12:31:06Z", "bug_id": 638091, "attachment_id": null, "tags": [], "creation_time": "2012-03-07T12:31:06Z", "id": 6120852, "author": "pppx@i.com.ua", "is_private": false}, {"bug_id": 638091, "attachment_id": null, "creation_time": "2012-03-08T15:39:38Z", "tags": [], "id": 6124353, "is_private": false, "author": "hv1989@gmail.com", "text": "A month ago I looked at it again and it still applies.\nIt is a definitely win when searching on strings larger than 256.\n\nI tried loop unrolling, like suggested in Comment 13 by Luke.\nThis didn't give any gains. (I suspect because our implementation there is a bad character test and that made loop unrolling harder).\n\nAlso there is a difference between BMH (what we use) and BM (what grep uses). So I'm not eager to switch to BM without having enough tests. Also BM with loop unrolling uses some tricks and that increases speed mostly. But the worst case scenario also gets slower (noticeably).\n\nI don't have enough time to do those tests atm. Maybe I will in the future. But I can't guarantee.", "creator": "hv1989@gmail.com", "raw_text": "A month ago I looked at it again and it still applies.\nIt is a definitely win when searching on strings larger than 256.\n\nI tried loop unrolling, like suggested in Comment 13 by Luke.\nThis didn't give any gains. (I suspect because our implementation there is a bad character test and that made loop unrolling harder).\n\nAlso there is a difference between BMH (what we use) and BM (what grep uses). So I'm not eager to switch to BM without having enough tests. Also BM with loop unrolling uses some tricks and that increases speed mostly. But the worst case scenario also gets slower (noticeably).\n\nI don't have enough time to do those tests atm. Maybe I will in the future. But I can't guarantee.", "count": 16, "time": "2012-03-08T15:39:38Z"}, {"text": "Is this a duplicate of the more recent string matching bugs?", "bug_id": 638091, "creator": "jdemooij@mozilla.com", "raw_text": "Is this a duplicate of the more recent string matching bugs?", "attachment_id": null, "creation_time": "2014-09-01T18:31:53Z", "tags": [], "id": 9255424, "count": 17, "author": "jdemooij@mozilla.com", "time": "2014-09-01T18:31:53Z", "is_private": false}, {"count": 18, "time": "2014-09-01T18:52:42Z", "creator": "hv1989@gmail.com", "raw_text": "Actually not. \n\nThe recent string matching bugs are for when we cannot use a search table (e.g. table too big or overhead of creating the table doesn't outweigh the search speed gain).\n\nThis patch is to increase the time for when we can create a search table.", "text": "Actually not. \n\nThe recent string matching bugs are for when we cannot use a search table (e.g. table too big or overhead of creating the table doesn't outweigh the search speed gain).\n\nThis patch is to increase the time for when we can create a search table.", "is_private": false, "author": "hv1989@gmail.com", "id": 9255457, "attachment_id": null, "creation_time": "2014-09-01T18:52:42Z", "tags": [], "bug_id": 638091}]}}}