{"comments": {}, "bugs": {"703995": {"comments": [{"attachment_id": null, "time": "2011-11-20T18:11:40Z", "text": "User Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:9.0) Gecko/20100101 Firefox/9.0\nBuild ID: 20111116091359\n\nSteps to reproduce:\n\nWhen loading my page the second time from cache, Firefox 8.0 needs around 43 Seconds on my machine (Windows 7 64 Bit, Intel Core i7, 8 GB RAM, FireBug reports for all request a \"304 Not Modified\") to load. Chromium (14.0.797.0 (Entwickler-Build 89612)) needs under 2 seconds, Internet Explorer 9 around 13 seconds.\n\nThe page I'm developing is a html and javascript only based - i.e. no flash - ePaper: http://www.patrickmueller.li/epaper_ml1110_2/Blaettern_V11_39.html\n\n\nActual results:\n\nFirefox 8.0 is much slower then the competition.\n\nI once even did notice, that with a very fast internet connection (> 50 Mbit/s), loading from the server was even faster then loading from the cache. I will verify that in a week when I have access again to the fast internet.\n\n\nExpected results:\n\nFirefox should load the page much faster.", "raw_text": "User Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:9.0) Gecko/20100101 Firefox/9.0\nBuild ID: 20111116091359\n\nSteps to reproduce:\n\nWhen loading my page the second time from cache, Firefox 8.0 needs around 43 Seconds on my machine (Windows 7 64 Bit, Intel Core i7, 8 GB RAM, FireBug reports for all request a \"304 Not Modified\") to load. Chromium (14.0.797.0 (Entwickler-Build 89612)) needs under 2 seconds, Internet Explorer 9 around 13 seconds.\n\nThe page I'm developing is a html and javascript only based - i.e. no flash - ePaper: http://www.patrickmueller.li/epaper_ml1110_2/Blaettern_V11_39.html\n\n\nActual results:\n\nFirefox 8.0 is much slower then the competition.\n\nI once even did notice, that with a very fast internet connection (> 50 Mbit/s), loading from the server was even faster then loading from the cache. I will verify that in a week when I have access again to the fast internet.\n\n\nExpected results:\n\nFirefox should load the page much faster.", "creation_time": "2011-11-20T18:11:40Z", "bug_id": 703995, "id": 5861366, "tags": [], "is_private": false, "count": 0, "author": "pbcmueller@hotmail.com", "creator": "pbcmueller@hotmail.com"}, {"author": "bzbarsky@mit.edu", "creator": "bzbarsky@mit.edu", "bug_id": 703995, "id": 5862399, "tags": [], "count": 1, "is_private": false, "attachment_id": null, "time": "2011-11-21T15:25:20Z", "text": "Patrick, how are you measuring the times in comment 0?  I see this page load in under 2-3 seconds over here....\n\nPlease make sure to test _without_ Firebug installed, since it has a fairly significant impact on pageload times.", "raw_text": "Patrick, how are you measuring the times in comment 0?  I see this page load in under 2-3 seconds over here....\n\nPlease make sure to test _without_ Firebug installed, since it has a fairly significant impact on pageload times.", "creation_time": "2011-11-21T15:25:20Z"}, {"bug_id": 703995, "tags": [], "count": 2, "is_private": false, "id": 5870502, "text": "Hi Boris\n\nAfter the first (visible) page/picture is loaded (what only takes a few seconds), the remaining 83 pages are dynamically loaded in the background - I do measure the time until all 84 pages are loaded. The loading algorithm is \"smart\": if you jump to a page that is not yet preloaded, that page is loaded next and it continues preloading the pages following your current page - this works also if your flipping the pages in the opposite direction. This shall make the user experience as snappy as possible. Depending on your screen resolution it loads a total of some 7 to 15 MBytes for the whole magazine/ePaper.\n\nYes, I do measure the loading time with Firebug. I will add an in-page indicator this weekend for measuring the pageload times without firebug to check whether firebug has any influence regarding cache.", "creator": "pbcmueller@hotmail.com", "author": "pbcmueller@hotmail.com", "time": "2011-11-24T11:33:40Z", "attachment_id": null, "raw_text": "Hi Boris\n\nAfter the first (visible) page/picture is loaded (what only takes a few seconds), the remaining 83 pages are dynamically loaded in the background - I do measure the time until all 84 pages are loaded. The loading algorithm is \"smart\": if you jump to a page that is not yet preloaded, that page is loaded next and it continues preloading the pages following your current page - this works also if your flipping the pages in the opposite direction. This shall make the user experience as snappy as possible. Depending on your screen resolution it loads a total of some 7 to 15 MBytes for the whole magazine/ePaper.\n\nYes, I do measure the loading time with Firebug. I will add an in-page indicator this weekend for measuring the pageload times without firebug to check whether firebug has any influence regarding cache.", "creation_time": "2011-11-24T11:33:40Z"}, {"text": "Patrick, thanks.  Given an in-page indicator, it'll also be a lot simpler to see where the time is going even if Firebug is not the problem...", "time": "2011-11-24T18:54:50Z", "attachment_id": null, "creation_time": "2011-11-24T18:54:50Z", "raw_text": "Patrick, thanks.  Given an in-page indicator, it'll also be a lot simpler to see where the time is going even if Firebug is not the problem...", "bug_id": 703995, "count": 3, "is_private": false, "tags": [], "id": 5871222, "creator": "bzbarsky@mit.edu", "author": "bzbarsky@mit.edu"}, {"creation_time": "2011-11-24T22:29:54Z", "raw_text": "Hi Boris \n\nI did add some speed/timing information on my page and also did upload the plain/non-minified javascript (its that one: http://www.patrickmueller.li/epaper_ml1110_2/Blaettern_V11_39.js). I tried again and loading from cache is now +/- as fast as IE 9 - but Chromium and Safari are still at least 6 times faster!", "attachment_id": null, "time": "2011-11-24T22:29:54Z", "author": "pbcmueller@hotmail.com", "text": "Hi Boris \n\nI did add some speed/timing information on my page and also did upload the plain/non-minified javascript (its that one: http://www.patrickmueller.li/epaper_ml1110_2/Blaettern_V11_39.js). I tried again and loading from cache is now +/- as fast as IE 9 - but Chromium and Safari are still at least 6 times faster!", "creator": "pbcmueller@hotmail.com", "id": 5871514, "is_private": false, "count": 4, "tags": [], "bug_id": 703995}, {"bug_id": 703995, "id": 5872944, "count": 5, "is_private": false, "tags": [], "time": "2011-11-25T23:08:11Z", "attachment_id": null, "author": "pbcmueller@hotmail.com", "creator": "pbcmueller@hotmail.com", "text": "Another interesting effect I did discover: I did upload the pictures to Amazon S3 to check whether it might be faster: http://www.patrickmueller.li/epaper_ml1110_2/Blaettern_V11_39_AS3.html\nLoading from cache is slower no in Firefox - not so with Chromium, that is as fast as before.", "creation_time": "2011-11-25T23:08:11Z", "raw_text": "Another interesting effect I did discover: I did upload the pictures to Amazon S3 to check whether it might be faster: http://www.patrickmueller.li/epaper_ml1110_2/Blaettern_V11_39_AS3.html\nLoading from cache is slower no in Firefox - not so with Chromium, that is as fast as before."}, {"is_private": false, "count": 6, "tags": [], "id": 5877697, "bug_id": 703995, "raw_text": "Patrick, sorry for the lag.  Holiday weekend here...\n\nI just tried loading http://www.patrickmueller.li/epaper_ml1110_2/Blaettern_V11_39.html and I see the various background image requests, but no in-page indicator of load completion...\n\nHonza, Patrick, want to take a look at this?", "creation_time": "2011-11-29T01:34:07Z", "text": "Patrick, sorry for the lag.  Holiday weekend here...\n\nI just tried loading http://www.patrickmueller.li/epaper_ml1110_2/Blaettern_V11_39.html and I see the various background image requests, but no in-page indicator of load completion...\n\nHonza, Patrick, want to take a look at this?", "creator": "bzbarsky@mit.edu", "time": "2011-11-29T01:34:07Z", "attachment_id": null, "author": "bzbarsky@mit.edu"}, {"creator": "pbcmueller@hotmail.com", "author": "pbcmueller@hotmail.com", "text": "Hi Boris\n\nIt's fixed - I did play too much around - sorry. \n\nOne more thing that I did only notice in FF: I open my page and afterward some tabs and browse a bit inside them. If I switch back to the ePaper the picture/page is white and it takes a few seconds until the pic/page is shown again.", "time": "2011-11-29T07:27:24Z", "attachment_id": null, "creation_time": "2011-11-29T07:27:24Z", "raw_text": "Hi Boris\n\nIt's fixed - I did play too much around - sorry. \n\nOne more thing that I did only notice in FF: I open my page and afterward some tabs and browse a bit inside them. If I switch back to the ePaper the picture/page is white and it takes a few seconds until the pic/page is shown again.", "bug_id": 703995, "count": 7, "is_private": false, "tags": [], "id": 5878089}, {"id": 5891294, "is_private": false, "count": 8, "tags": [], "bug_id": 703995, "creation_time": "2011-12-04T13:29:34Z", "raw_text": "btw. with \"It's fixed\" I did mean the broken links. The issues itself is still present.", "attachment_id": null, "time": "2011-12-04T13:29:34Z", "text": "btw. with \"It's fixed\" I did mean the broken links. The issues itself is still present.", "author": "pbcmueller@hotmail.com", "creator": "pbcmueller@hotmail.com"}, {"bug_id": 703995, "is_private": false, "count": 9, "tags": [], "id": 5977665, "text": "Patrick, I'm finally getting back to this.  Sorry for the lag....  Thank you for those in-page indicators!\n\nI can definitely reproduce this.  After the first load, if I put the cursor in the url bar in Firefox (a current nightly) and hit enter, the load takes about 16s for all the 84 images.  Chrome takes about 2 seconds. \n\nThe 2 second thing (and the <7ms load times I see on a per-image basis) is only possible if they're not sending any sort of revalidation requests at all of if the images are being loaded in parallel: ping time from me to the server the images are on is 100+ms, so it should take at least 8s to load all the images if each one has to do a conditional GET and get a 304.\n\nIs your code doing the requests in parallel, or is it waiting for one image to fire onload before starting the next request?  Do you see Chrome actually hitting the network at all for these images?", "creator": "bzbarsky@mit.edu", "time": "2012-01-13T04:05:27Z", "attachment_id": null, "author": "bzbarsky@mit.edu", "raw_text": "Patrick, I'm finally getting back to this.  Sorry for the lag....  Thank you for those in-page indicators!\n\nI can definitely reproduce this.  After the first load, if I put the cursor in the url bar in Firefox (a current nightly) and hit enter, the load takes about 16s for all the 84 images.  Chrome takes about 2 seconds. \n\nThe 2 second thing (and the <7ms load times I see on a per-image basis) is only possible if they're not sending any sort of revalidation requests at all of if the images are being loaded in parallel: ping time from me to the server the images are on is 100+ms, so it should take at least 8s to load all the images if each one has to do a conditional GET and get a 304.\n\nIs your code doing the requests in parallel, or is it waiting for one image to fire onload before starting the next request?  Do you see Chrome actually hitting the network at all for these images?", "creation_time": "2012-01-13T04:05:27Z"}, {"id": 5977678, "count": 10, "is_private": false, "tags": [], "bug_id": 703995, "creation_time": "2012-01-13T04:19:30Z", "raw_text": "OK, looking at an HTTP log for us, it looks like the next load does in fact start once the previous one completes.  Also, we do load all the images from cache without having to hit the network for the image loads themselves.\n\nThe one thing I see us hitting the network for are URIs of this form: <http://www.patrickmueller.li/epaper_ml1110_2/Bilder/Seite_0061.txt.gz?getid=true>.  These do get cached, but have to be revalidated every time; as the log says:\n\n  Validating based on RFC 2616 section 13.9 (query-url w/o explicit expiration-time)\n\nThese URIs do come back with 304 responses.\n\nPatrick, is the script doing those in series as well (and gating the image loads on those)?  If it is, that would explain the observed behavior in Firefox, though not in Chrome (unless they're violating the relevant part of the HTTP RFC, of course).", "attachment_id": null, "time": "2012-01-13T04:19:30Z", "text": "OK, looking at an HTTP log for us, it looks like the next load does in fact start once the previous one completes.  Also, we do load all the images from cache without having to hit the network for the image loads themselves.\n\nThe one thing I see us hitting the network for are URIs of this form: <http://www.patrickmueller.li/epaper_ml1110_2/Bilder/Seite_0061.txt.gz?getid=true>.  These do get cached, but have to be revalidated every time; as the log says:\n\n  Validating based on RFC 2616 section 13.9 (query-url w/o explicit expiration-time)\n\nThese URIs do come back with 304 responses.\n\nPatrick, is the script doing those in series as well (and gating the image loads on those)?  If it is, that would explain the observed behavior in Firefox, though not in Chrome (unless they're violating the relevant part of the HTTP RFC, of course).", "author": "bzbarsky@mit.edu", "creator": "bzbarsky@mit.edu"}, {"creation_time": "2012-01-16T10:11:43Z", "raw_text": "Hi Boris\n\nSorry for my late replay too: I just came back today from vacation.\n\nYes I do load everything one after another: Actually I do first load the picture of the page and afterwards the containing text, that is compressed with gzip (.gz) (to make the page searchable): that's that URI <http://www.patrickmueller.li/epaper_ml1110_2/Bilder/Seite_0061.txt.gz?getid=true>. Afterwards the next pic and text are loaded.\nYes it looks like Chrome also loads the \"Seite_0061.txt.gz\" from cache - even if I didn't add an expiration date till now for it. But now I did add but Firefox still doesn't loads it from cache - do I do something wrong?", "text": "Hi Boris\n\nSorry for my late replay too: I just came back today from vacation.\n\nYes I do load everything one after another: Actually I do first load the picture of the page and afterwards the containing text, that is compressed with gzip (.gz) (to make the page searchable): that's that URI <http://www.patrickmueller.li/epaper_ml1110_2/Bilder/Seite_0061.txt.gz?getid=true>. Afterwards the next pic and text are loaded.\nYes it looks like Chrome also loads the \"Seite_0061.txt.gz\" from cache - even if I didn't add an expiration date till now for it. But now I did add but Firefox still doesn't loads it from cache - do I do something wrong?", "attachment_id": null, "time": "2012-01-16T10:11:43Z", "is_private": false, "count": 11, "tags": [], "id": 5982422, "bug_id": 703995, "creator": "pbcmueller@hotmail.com", "author": "pbcmueller@hotmail.com"}, {"text": "I did change my code now so also the http://www.patrickmueller.li/epaper_ml1110_2/Bilder/Seite_0061.txt.gz can be loaded from cache - what now also works with Firefox - but Firefox still takes around 5,6 seconds and Chrome around 1,5 seconds with my configuration...", "creator": "pbcmueller@hotmail.com", "author": "pbcmueller@hotmail.com", "attachment_id": null, "time": "2012-01-16T12:56:01Z", "creation_time": "2012-01-16T12:56:01Z", "raw_text": "I did change my code now so also the http://www.patrickmueller.li/epaper_ml1110_2/Bilder/Seite_0061.txt.gz can be loaded from cache - what now also works with Firefox - but Firefox still takes around 5,6 seconds and Chrome around 1,5 seconds with my configuration...", "bug_id": 703995, "tags": [], "count": 12, "is_private": false, "id": 5982592}, {"raw_text": "> But now I did add but Firefox still doesn't loads it from cache - do I do something wrong?\n\nIs the server still in this configuration?  Comment 12 suggests no, making it hard to answer that question...\n\nGoing to look into the time situation with the new setup.", "creation_time": "2012-01-16T16:56:11Z", "text": "> But now I did add but Firefox still doesn't loads it from cache - do I do something wrong?\n\nIs the server still in this configuration?  Comment 12 suggests no, making it hard to answer that question...\n\nGoing to look into the time situation with the new setup.", "time": "2012-01-16T16:56:11Z", "attachment_id": null, "tags": [], "is_private": false, "count": 13, "id": 5982927, "bug_id": 703995, "creator": "bzbarsky@mit.edu", "author": "bzbarsky@mit.edu"}, {"creator": "honzab.moz@firemni.cz", "author": "honzab.moz@firemni.cz", "tags": [], "count": 14, "is_private": false, "id": 5982950, "bug_id": 703995, "raw_text": "With Aurora and Nightly debug I can see a hang of UI for a time (about 5 seconds).  That is also interesting to investigate on.  I can see most of the time spent in Name                                            \tAddress    \tSelf \tChildren \tTotal \t\n mozilla::imagelib::nsJPEGDecoder::WriteInternal\t0x5d1d1254 \t0    \t289      \t289   \t\n\n1 function, Total: 0 self samples, 289 child samples\n\nBut there seems to be lot more other calls.\n\nI'm looking into this too.", "creation_time": "2012-01-16T17:12:25Z", "text": "With Aurora and Nightly debug I can see a hang of UI for a time (about 5 seconds).  That is also interesting to investigate on.  I can see most of the time spent in Name                                            \tAddress    \tSelf \tChildren \tTotal \t\n mozilla::imagelib::nsJPEGDecoder::WriteInternal\t0x5d1d1254 \t0    \t289      \t289   \t\n\n1 function, Total: 0 self samples, 289 child samples\n\nBut there seems to be lot more other calls.\n\nI'm looking into this too.", "time": "2012-01-16T17:12:25Z", "attachment_id": null}, {"creator": "honzab.moz@firemni.cz", "author": "honzab.moz@firemni.cz", "bug_id": 703995, "count": 15, "is_private": false, "tags": [], "id": 5983079, "text": "About the hang, CodeAnalyst tells me the significant amount of time is spent at ycc_rgb_convert_argb function.  Probably worth of reporting a different bug.  I can see the hang just the first time we load the page in a browser session.  Any other attempts by focusing the address bar and pressing enter don't exhibit that behavior and load times are in some 454ms, for me faster then Chrome 16 (it loads the page in some 540ms).  The first load is however about 3700ms in Aurora.", "attachment_id": null, "time": "2012-01-16T18:07:37Z", "creation_time": "2012-01-16T18:07:37Z", "raw_text": "About the hang, CodeAnalyst tells me the significant amount of time is spent at ycc_rgb_convert_argb function.  Probably worth of reporting a different bug.  I can see the hang just the first time we load the page in a browser session.  Any other attempts by focusing the address bar and pressing enter don't exhibit that behavior and load times are in some 454ms, for me faster then Chrome 16 (it loads the page in some 540ms).  The first load is however about 3700ms in Aurora."}, {"creation_time": "2012-01-16T18:10:30Z", "raw_text": "As I recall, Chrome decodes images on paint while we do it eagerly.  There are existing bugs on that.  So if it takes a few seconds to decode all the images, that would explain the difference, esp. if decoding blocks onload for the image.", "time": "2012-01-16T18:10:30Z", "attachment_id": null, "text": "As I recall, Chrome decodes images on paint while we do it eagerly.  There are existing bugs on that.  So if it takes a few seconds to decode all the images, that would explain the difference, esp. if decoding blocks onload for the image.", "id": 5983092, "count": 16, "is_private": false, "tags": [], "bug_id": 703995, "author": "bzbarsky@mit.edu", "creator": "bzbarsky@mit.edu"}, {"text": "(In reply to Patrick M\u00fcller from comment #12)\n> I did change my code now so also the\n> http://www.patrickmueller.li/epaper_ml1110_2/Bilder/Seite_0061.txt.gz can be\n> loaded from cache - what now also works with Firefox - but Firefox still\n> takes around 5,6 seconds and Chrome around 1,5 seconds with my\n> configuration...\n\nMy understanding is that previously Chrome would cache your images but Firefox wouldn't, but then you changed your test so that Firefox would also cache the images.\n\nI am *very* curious about what change you made to cause Firefox to cache your images. (Rather, I am interested why Chrome would cache them in situations that Firefox wouldn't.)", "attachment_id": null, "time": "2012-01-16T18:16:10Z", "raw_text": "(In reply to Patrick M\u00fcller from comment #12)\n> I did change my code now so also the\n> http://www.patrickmueller.li/epaper_ml1110_2/Bilder/Seite_0061.txt.gz can be\n> loaded from cache - what now also works with Firefox - but Firefox still\n> takes around 5,6 seconds and Chrome around 1,5 seconds with my\n> configuration...\n\nMy understanding is that previously Chrome would cache your images but Firefox wouldn't, but then you changed your test so that Firefox would also cache the images.\n\nI am *very* curious about what change you made to cause Firefox to cache your images. (Rather, I am interested why Chrome would cache them in situations that Firefox wouldn't.)", "creation_time": "2012-01-16T18:16:10Z", "bug_id": 703995, "tags": [], "is_private": false, "count": 17, "id": 5983106, "creator": "brian@briansmith.org", "author": "brian@briansmith.org"}, {"attachment_id": null, "time": "2012-01-16T19:08:21Z", "text": "Both Chrome and Firefox were caching the images.\n\nChrome was also caching URIs of the form http://www.patrickmueller.li/epaper_ml1110_2/Bilder/Seite_0061.txt.gz?getid=true that were sent without an explicit Expires and loading them directly from the cache without a conditional GET.  We were caching them too, but revalidating the cache, which requires a server round-trip.  Once we got the 304 response we loaded them from the cache.  As far as I can tell, Chrome is just violating a MUST-level requirement from the HTTP RFC here.  See bug 468594 and nsHttpChannel::MustValidateBasedOnQueryUrl.\n\nThe page has since been changed to send an Expires header for those URIs, so now we are reading them directly from cache.", "raw_text": "Both Chrome and Firefox were caching the images.\n\nChrome was also caching URIs of the form http://www.patrickmueller.li/epaper_ml1110_2/Bilder/Seite_0061.txt.gz?getid=true that were sent without an explicit Expires and loading them directly from the cache without a conditional GET.  We were caching them too, but revalidating the cache, which requires a server round-trip.  Once we got the 304 response we loaded them from the cache.  As far as I can tell, Chrome is just violating a MUST-level requirement from the HTTP RFC here.  See bug 468594 and nsHttpChannel::MustValidateBasedOnQueryUrl.\n\nThe page has since been changed to send an Expires header for those URIs, so now we are reading them directly from cache.", "creation_time": "2012-01-16T19:08:21Z", "bug_id": 703995, "id": 5983236, "is_private": false, "count": 18, "tags": [], "author": "bzbarsky@mit.edu", "creator": "bzbarsky@mit.edu"}, {"raw_text": "Currently we decode all images associated with <img> elements in the current tab, even if those <img> elements are hidden or not in the document at all.  Those decodes may or may not block the document's load event, so depending on what exactly you're measuring, you may see that decode time in your measurements.\n\nWe also currently attempt to synchronously decode all images under a certain size.  When we're getting images off the network we normally don't have the entire image downloaded when decoding begins, but when we get them from the cache, we can decode clear through.  This may be the cause of UI jank you're seeing.\n\nThere are bugs on file for all of this, of course.", "creation_time": "2012-01-16T20:35:36Z", "text": "Currently we decode all images associated with <img> elements in the current tab, even if those <img> elements are hidden or not in the document at all.  Those decodes may or may not block the document's load event, so depending on what exactly you're measuring, you may see that decode time in your measurements.\n\nWe also currently attempt to synchronously decode all images under a certain size.  When we're getting images off the network we normally don't have the entire image downloaded when decoding begins, but when we get them from the cache, we can decode clear through.  This may be the cause of UI jank you're seeing.\n\nThere are bugs on file for all of this, of course.", "time": "2012-01-16T20:35:36Z", "attachment_id": null, "count": 19, "is_private": false, "tags": [], "id": 5983454, "bug_id": 703995, "creator": "khuey@kylehuey.com", "author": "khuey@kylehuey.com"}, {"bug_id": 703995, "id": 5983513, "count": 20, "is_private": false, "tags": [], "attachment_id": null, "time": "2012-01-16T20:52:12Z", "text": "> Those decodes may or may not block the document's load event\n\nI think for purposes of this script what matters is whether they block the image element's load event.\n\nIs there something I can do locally to disable the eager decode just to see what the effect is on the numbers?", "raw_text": "> Those decodes may or may not block the document's load event\n\nI think for purposes of this script what matters is whether they block the image element's load event.\n\nIs there something I can do locally to disable the eager decode just to see what the effect is on the numbers?", "creation_time": "2012-01-16T20:52:12Z", "author": "bzbarsky@mit.edu", "creator": "bzbarsky@mit.edu"}, {"id": 5983534, "tags": [], "count": 21, "is_private": false, "bug_id": 703995, "raw_text": "(In reply to Boris Zbarsky (:bz) from comment #20)\n> Is there something I can do locally to disable the eager decode just to see\n> what the effect is on the numbers?\n\nHack http://mxr.mozilla.org/mozilla-central/source/content/base/src/nsImageLoadingContent.cpp#350 to not requestDecode if the content node is not in the document *and* nuke (Un)LockEnumerator at http://mxr.mozilla.org/mozilla-central/source/content/base/src/nsDocument.cpp#8291.  That should ensure that nodes that are not in the document never get decodes requested.  It will also discard images on the current tab, but that doesn't matter for your perf test.\n\nNote that decodes do not block the image's load event, but they are triggered immediately before firing the load event, and if the decode happens synchronously ...", "creation_time": "2012-01-16T21:01:54Z", "author": "khuey@kylehuey.com", "time": "2012-01-16T21:01:54Z", "attachment_id": null, "creator": "khuey@kylehuey.com", "text": "(In reply to Boris Zbarsky (:bz) from comment #20)\n> Is there something I can do locally to disable the eager decode just to see\n> what the effect is on the numbers?\n\nHack http://mxr.mozilla.org/mozilla-central/source/content/base/src/nsImageLoadingContent.cpp#350 to not requestDecode if the content node is not in the document *and* nuke (Un)LockEnumerator at http://mxr.mozilla.org/mozilla-central/source/content/base/src/nsDocument.cpp#8291.  That should ensure that nodes that are not in the document never get decodes requested.  It will also discard images on the current tab, but that doesn't matter for your perf test.\n\nNote that decodes do not block the image's load event, but they are triggered immediately before firing the load event, and if the decode happens synchronously ..."}, {"author": "khuey@kylehuey.com", "creator": "khuey@kylehuey.com", "id": 5983541, "tags": [], "count": 22, "is_private": false, "bug_id": 703995, "creation_time": "2012-01-16T21:04:54Z", "raw_text": "The images here all look to be about 75 KB, and the cutoff for switching to async decoding is a little under 150 KB, so I expect that the sync decoding off the cache is what's killing us here.", "attachment_id": null, "time": "2012-01-16T21:04:54Z", "text": "The images here all look to be about 75 KB, and the cutoff for switching to async decoding is a little under 150 KB, so I expect that the sync decoding off the cache is what's killing us here."}, {"bug_id": 703995, "count": 23, "is_private": false, "tags": [], "id": 5983601, "text": "One other thing you can do, if you want to test comment 22, is twiddle the image.mem.max_bytes_for_sync_decode pref down to say, 1 byte.", "attachment_id": null, "time": "2012-01-16T21:22:33Z", "raw_text": "One other thing you can do, if you want to test comment 22, is twiddle the image.mem.max_bytes_for_sync_decode pref down to say, 1 byte.", "creation_time": "2012-01-16T21:22:33Z", "creator": "khuey@kylehuey.com", "author": "khuey@kylehuey.com"}, {"author": "honzab.moz@firemni.cz", "creator": "honzab.moz@firemni.cz", "id": 5983612, "count": 24, "is_private": false, "tags": [], "bug_id": 703995, "creation_time": "2012-01-16T21:27:38Z", "raw_text": "(In reply to Kyle Huey [:khuey] (khuey@mozilla.com) from comment #23)\n> One other thing you can do, if you want to test comment 22, is twiddle the\n> image.mem.max_bytes_for_sync_decode pref down to say, 1 byte.\n\nDoesn't help, even after restart.  Still seeing 1300ms of self-time in ycc_rgb_convert_argb.", "time": "2012-01-16T21:27:38Z", "attachment_id": null, "text": "(In reply to Kyle Huey [:khuey] (khuey@mozilla.com) from comment #23)\n> One other thing you can do, if you want to test comment 22, is twiddle the\n> image.mem.max_bytes_for_sync_decode pref down to say, 1 byte.\n\nDoesn't help, even after restart.  Still seeing 1300ms of self-time in ycc_rgb_convert_argb."}, {"raw_text": "Well the decoding is all still going to happen eventually, but it may let the load event fire earlier.", "creation_time": "2012-01-16T21:29:01Z", "text": "Well the decoding is all still going to happen eventually, but it may let the load event fire earlier.", "attachment_id": null, "time": "2012-01-16T21:29:01Z", "is_private": false, "count": 25, "tags": [], "id": 5983614, "bug_id": 703995, "creator": "khuey@kylehuey.com", "author": "khuey@kylehuey.com"}, {"raw_text": "(In reply to Kyle Huey [:khuey] (khuey@mozilla.com) from comment #25)\n> Well the decoding is all still going to happen eventually, but it may let\n> the load event fire earlier.\n\nAnd still the same long loading times... :(", "creation_time": "2012-01-16T21:31:11Z", "attachment_id": null, "time": "2012-01-16T21:31:11Z", "text": "(In reply to Kyle Huey [:khuey] (khuey@mozilla.com) from comment #25)\n> Well the decoding is all still going to happen eventually, but it may let\n> the load event fire earlier.\n\nAnd still the same long loading times... :(", "id": 5983619, "tags": [], "count": 26, "is_private": false, "bug_id": 703995, "author": "honzab.moz@firemni.cz", "creator": "honzab.moz@firemni.cz"}, {"creator": "pbcmueller@hotmail.com", "author": "pbcmueller@hotmail.com", "bug_id": 703995, "tags": [], "is_private": false, "count": 27, "id": 5985017, "text": "Just tell me if I should setup up a testpage like before to show chrome caching without explicit Expires. \n\n(In reply to Boris Zbarsky (:bz) from comment #18)\n> Both Chrome and Firefox were caching the images.\n> \n> Chrome was also caching URIs of the form\n> http://www.patrickmueller.li/epaper_ml1110_2/Bilder/Seite_0061.txt.\n> gz?getid=true that were sent without an explicit Expires and loading them\n> directly from the cache without a conditional GET.  We were caching them\n> too, but revalidating the cache, which requires a server round-trip.  Once\n> we got the 304 response we loaded them from the cache.  As far as I can\n> tell, Chrome is just violating a MUST-level requirement from the HTTP RFC\n> here.  See bug 468594 and nsHttpChannel::MustValidateBasedOnQueryUrl.\n> \n> The page has since been changed to send an Expires header for those URIs, so\n> now we are reading them directly from cache.", "time": "2012-01-17T13:41:50Z", "attachment_id": null, "creation_time": "2012-01-17T13:41:50Z", "raw_text": "Just tell me if I should setup up a testpage like before to show chrome caching without explicit Expires. \n\n(In reply to Boris Zbarsky (:bz) from comment #18)\n> Both Chrome and Firefox were caching the images.\n> \n> Chrome was also caching URIs of the form\n> http://www.patrickmueller.li/epaper_ml1110_2/Bilder/Seite_0061.txt.\n> gz?getid=true that were sent without an explicit Expires and loading them\n> directly from the cache without a conditional GET.  We were caching them\n> too, but revalidating the cache, which requires a server round-trip.  Once\n> we got the 304 response we loaded them from the cache.  As far as I can\n> tell, Chrome is just violating a MUST-level requirement from the HTTP RFC\n> here.  See bug 468594 and nsHttpChannel::MustValidateBasedOnQueryUrl.\n> \n> The page has since been changed to send an Expires header for those URIs, so\n> now we are reading them directly from cache."}, {"time": "2012-01-17T20:55:24Z", "attachment_id": null, "text": "(In reply to Boris Zbarsky (:bz) from comment #18)\n> we got the 304 response we loaded them from the cache.  As far as I can\n> tell, Chrome is just violating a MUST-level requirement from the HTTP RFC\n> here.  See bug 468594 and nsHttpChannel::MustValidateBasedOnQueryUrl.\n\nI filed bug 718797. It seems like there is room for improvement in this area.\n\n> The page has since been changed to send an Expires header for those URIs, so\n> now we are reading them directly from cache.\n\n(In reply to Patrick M\u00fcller from comment #27)\n> Just tell me if I should setup up a testpage like before to show chrome\n> caching without explicit Expires. \n\nFirst, thank you very much for your help here! Like I said, I filed bug 718797 about us possibly being too eager to revalidate in these situations. For bug 718797, it would actually be great to have the one without the Expires header. But, for this bug, it would be better to have the one with the Expires header. So, if it isn't too much work, having both available would be great.", "creation_time": "2012-01-17T20:55:24Z", "raw_text": "(In reply to Boris Zbarsky (:bz) from comment #18)\n> we got the 304 response we loaded them from the cache.  As far as I can\n> tell, Chrome is just violating a MUST-level requirement from the HTTP RFC\n> here.  See bug 468594 and nsHttpChannel::MustValidateBasedOnQueryUrl.\n\nI filed bug 718797. It seems like there is room for improvement in this area.\n\n> The page has since been changed to send an Expires header for those URIs, so\n> now we are reading them directly from cache.\n\n(In reply to Patrick M\u00fcller from comment #27)\n> Just tell me if I should setup up a testpage like before to show chrome\n> caching without explicit Expires. \n\nFirst, thank you very much for your help here! Like I said, I filed bug 718797 about us possibly being too eager to revalidate in these situations. For bug 718797, it would actually be great to have the one without the Expires header. But, for this bug, it would be better to have the one with the Expires header. So, if it isn't too much work, having both available would be great.", "bug_id": 703995, "id": 5986546, "count": 28, "is_private": false, "tags": [], "author": "brian@briansmith.org", "creator": "brian@briansmith.org"}, {"author": "pbcmueller@hotmail.com", "creator": "pbcmueller@hotmail.com", "time": "2012-01-18T09:24:02Z", "attachment_id": null, "text": "Hi Brian\nIt's my pleasure to help - and makes me proud that a nobody like me gets so much attention - thanks (btw. just offtopic how do you guys like my epaper - dos it feel and behave like one would expect it (double click on a pic zooms in, left top is the search field)?).\n\nI did add the testcase without the Expires header for *.txt and *.gz files - *.jpg still have an Expires header like before - if you like to have no expires header for the *.jpg files too just tell me.\n\nYou find it here: http://www.patrickmueller.li/epaper_ml1110_nocache/Blaettern_V11_39.html\nYou can also access all testcases with links and short description on my top URL:\nhttp://www.patrickmueller.li", "raw_text": "Hi Brian\nIt's my pleasure to help - and makes me proud that a nobody like me gets so much attention - thanks (btw. just offtopic how do you guys like my epaper - dos it feel and behave like one would expect it (double click on a pic zooms in, left top is the search field)?).\n\nI did add the testcase without the Expires header for *.txt and *.gz files - *.jpg still have an Expires header like before - if you like to have no expires header for the *.jpg files too just tell me.\n\nYou find it here: http://www.patrickmueller.li/epaper_ml1110_nocache/Blaettern_V11_39.html\nYou can also access all testcases with links and short description on my top URL:\nhttp://www.patrickmueller.li", "creation_time": "2012-01-18T09:24:02Z", "bug_id": 703995, "id": 5988174, "tags": [], "count": 29, "is_private": false}, {"creation_time": "2016-02-11T14:28:59Z", "raw_text": "The issue with caching and query string has been fixed.. comment 19 may or may not have been fixed, I'm not sure.. pushing over to imglib to see", "time": "2016-02-11T14:28:59Z", "attachment_id": null, "author": "mcmanus@ducksong.com", "text": "The issue with caching and query string has been fixed.. comment 19 may or may not have been fixed, I'm not sure.. pushing over to imglib to see", "creator": "mcmanus@ducksong.com", "id": 11157466, "count": 30, "is_private": false, "tags": [], "bug_id": 703995}]}}}