{"comments": {}, "bugs": {"680323": {"comments": [{"count": 0, "is_private": false, "tags": [], "id": 5664478, "bug_id": 680323, "creation_time": "2011-08-19T03:31:12Z", "raw_text": "When a client first signs up, they write to an ldap master in PHX (through sreg), get their node, and immediately start syncing (sometimes to a server in an entirely different datacenter). Our prod ldap replication tree is generally fast enough to handle this, but it would be nice to gracefully fail if replication gets a bit behind.\n\nThis error can also happen if an existing user gets node re-assigned. They hit auth and get a brand new node allocated, then when they try to sync they get 401s because the node allocation hasn't propogated through LDAP (webhead verifies Host: matches the allocated node).\n\nIf after fetching our node the first few hits to our clusterURL result in 401s, we could back off and try again (without showing an error bar).  After so many minutes/tries (5 minutes?), the normal error handling could resume.", "text": "When a client first signs up, they write to an ldap master in PHX (through sreg), get their node, and immediately start syncing (sometimes to a server in an entirely different datacenter). Our prod ldap replication tree is generally fast enough to handle this, but it would be nice to gracefully fail if replication gets a bit behind.\n\nThis error can also happen if an existing user gets node re-assigned. They hit auth and get a brand new node allocated, then when they try to sync they get 401s because the node allocation hasn't propogated through LDAP (webhead verifies Host: matches the allocated node).\n\nIf after fetching our node the first few hits to our clusterURL result in 401s, we could back off and try again (without showing an error bar).  After so many minutes/tries (5 minutes?), the normal error handling could resume.", "creator": "petef@mozilla.com", "attachment_id": null, "time": "2011-08-19T03:31:12Z", "author": "petef@mozilla.com"}, {"author": "bugzilla@twinql.com", "creator": "bugzilla@twinql.com", "attachment_id": null, "time": "2011-08-19T05:56:51Z", "text": "Are there any replication speed guarantees for our LDAP infra? If there are, then there might be a really simple solution here: delay sync in those situations.\n\nIf not (which is what I expect), then I guess this is another item for the error policy wishlist\u2026", "raw_text": "Are there any replication speed guarantees for our LDAP infra? If there are, then there might be a really simple solution here: delay sync in those situations.\n\nIf not (which is what I expect), then I guess this is another item for the error policy wishlist\u2026", "creation_time": "2011-08-19T05:56:51Z", "bug_id": 680323, "id": 5664666, "count": 1, "is_private": false, "tags": []}, {"raw_text": "(In reply to Richard Newman [:rnewman] from comment #1)\n> Are there any replication speed guarantees for our LDAP infra? If there are,\n> then there might be a really simple solution here: delay sync in those\n> situations.\n\nNo speed guarantees. Normally it's pretty instant, but there are a lot of factors (many out of our control, like cross-DC VPN links) that can impact that.", "creation_time": "2011-08-19T18:12:47Z", "attachment_id": null, "time": "2011-08-19T18:12:47Z", "text": "(In reply to Richard Newman [:rnewman] from comment #1)\n> Are there any replication speed guarantees for our LDAP infra? If there are,\n> then there might be a really simple solution here: delay sync in those\n> situations.\n\nNo speed guarantees. Normally it's pretty instant, but there are a lot of factors (many out of our control, like cross-DC VPN links) that can impact that.", "id": 5665910, "tags": [], "count": 2, "is_private": false, "bug_id": 680323, "author": "petef@mozilla.com", "creator": "petef@mozilla.com"}, {"creator": "atoll@mozilla.com", "author": "atoll@mozilla.com", "raw_text": "- From memory, on any given day, <5 seconds lag is normal, and most likely 0-2 seconds. (Everyday life.)\n- From memory, we might see a lag of 2-5 minutes when the intra-site VPN goes down, or when we have to nuke many nodes at once, or when we're doing ldap maintenance. (Once or twice a month.)\n- From memory, our worst lag was 25-30 minutes, when there was a core router crash between PHX-SJC and we had no way to replicate data. (Once or twice a year.)", "creation_time": "2011-10-20T00:44:54Z", "text": "- From memory, on any given day, <5 seconds lag is normal, and most likely 0-2 seconds. (Everyday life.)\n- From memory, we might see a lag of 2-5 minutes when the intra-site VPN goes down, or when we have to nuke many nodes at once, or when we're doing ldap maintenance. (Once or twice a month.)\n- From memory, our worst lag was 25-30 minutes, when there was a core router crash between PHX-SJC and we had no way to replicate data. (Once or twice a year.)", "attachment_id": null, "time": "2011-10-20T00:44:54Z", "count": 3, "is_private": false, "tags": [], "id": 5793576, "bug_id": 680323}, {"tags": [], "is_private": false, "count": 4, "id": 5793620, "bug_id": 680323, "raw_text": "Summary of discussion today:\n\n* LDAP replication lag is a normal event.\n* Fetching node/weave will only succeed after LDAP replication has completed.\n* Consequently, a 401 should have some delay until trying again, and/or some kind of silent retry mechanism to ensure that LDAP replication occurs.\n\nPhilipp's view:\n\n---\nCurrently we do this:\n\n(1) fetch info/collections (first login), get a 401\n(2) refetch node/weave.\n  - if it returns a new node, go to (1)\n  - otherwise report incorrect password\n\nYou would like us to do this:\n\n(0) set counter to 0\n(1) fetch info/collections (first login), get a 401\n(2) refetch node/weave.\n  - if it returns a new node, go to (1)\n  - if counter == 0, increment counter by 1, go to (1)\n  - otherwise report incorrect password\n---\n\natoll's view:\n\n---\n(0) set counter to 0\n(1) fetch whatever, get a 401 or several\n(2) (a) if counter == 0, increment counter by 1, wait 10 minutes, go to (1)\n(2) (b) else, refetch node/weave, compare, report incorrect password, etc.\n\nBecause, if 10 minutes pass and they *still* can't auth, then it's truly an issue, and we're probably already being paged about it anyways.\n---", "creation_time": "2011-10-20T01:33:21Z", "text": "Summary of discussion today:\n\n* LDAP replication lag is a normal event.\n* Fetching node/weave will only succeed after LDAP replication has completed.\n* Consequently, a 401 should have some delay until trying again, and/or some kind of silent retry mechanism to ensure that LDAP replication occurs.\n\nPhilipp's view:\n\n---\nCurrently we do this:\n\n(1) fetch info/collections (first login), get a 401\n(2) refetch node/weave.\n  - if it returns a new node, go to (1)\n  - otherwise report incorrect password\n\nYou would like us to do this:\n\n(0) set counter to 0\n(1) fetch info/collections (first login), get a 401\n(2) refetch node/weave.\n  - if it returns a new node, go to (1)\n  - if counter == 0, increment counter by 1, go to (1)\n  - otherwise report incorrect password\n---\n\natoll's view:\n\n---\n(0) set counter to 0\n(1) fetch whatever, get a 401 or several\n(2) (a) if counter == 0, increment counter by 1, wait 10 minutes, go to (1)\n(2) (b) else, refetch node/weave, compare, report incorrect password, etc.\n\nBecause, if 10 minutes pass and they *still* can't auth, then it's truly an issue, and we're probably already being paged about it anyways.\n---", "attachment_id": null, "time": "2011-10-20T01:33:21Z", "creator": "bugzilla@twinql.com", "author": "bugzilla@twinql.com"}, {"bug_id": 680323, "id": 5793691, "tags": [], "count": 5, "is_private": false, "author": "petef@mozilla.com", "time": "2011-10-20T02:59:15Z", "attachment_id": null, "text": "(In reply to Richard Newman [:rnewman] from comment #4)\n> * Fetching node/weave will only succeed after LDAP replication has completed.\n\nNo, the node servers talk directly to the LDAP master. The issue I'm worried about is when you get assigned a node that is NOT in the same datacenter as the ldap master (master in phx, get an scl2 node). When you ask for node/weave, you're talking to phx and you get pointed to scl2. You may start talking to an scl2 webhead before the ldap slaves in scl2 have replicated the user. Of course, this can happen within phx too (although less likely; master & slave on same VLAN vs going over an internet-backed VPN).\n\nIt might not even be the first request you make to the sync node, because we have multiple LDAP slaves. You might be 3 or 4 requests in to the sync before you see a 401 because of an out-of-date LDAP slave.\n\ntl;dr you will get a 200 fetching node/weave, and still sometimes hit a 401 later because of ldap replication lag", "creator": "petef@mozilla.com", "creation_time": "2011-10-20T02:59:15Z", "raw_text": "(In reply to Richard Newman [:rnewman] from comment #4)\n> * Fetching node/weave will only succeed after LDAP replication has completed.\n\nNo, the node servers talk directly to the LDAP master. The issue I'm worried about is when you get assigned a node that is NOT in the same datacenter as the ldap master (master in phx, get an scl2 node). When you ask for node/weave, you're talking to phx and you get pointed to scl2. You may start talking to an scl2 webhead before the ldap slaves in scl2 have replicated the user. Of course, this can happen within phx too (although less likely; master & slave on same VLAN vs going over an internet-backed VPN).\n\nIt might not even be the first request you make to the sync node, because we have multiple LDAP slaves. You might be 3 or 4 requests in to the sync before you see a 401 because of an out-of-date LDAP slave.\n\ntl;dr you will get a 200 fetching node/weave, and still sometimes hit a 401 later because of ldap replication lag"}, {"author": "bugzilla@twinql.com", "creator": "bugzilla@twinql.com", "time": "2011-10-20T06:50:46Z", "attachment_id": null, "text": "(In reply to Pete Fritchman [:petef] from comment #5)\n> (In reply to Richard Newman [:rnewman] from comment #4)\n> > * Fetching node/weave will only succeed after LDAP replication has completed.\n> \n> No, the node servers talk directly to the LDAP master.\n\nSorry, that was an awful misphrasing on my part. Thanks for correcting!\n\nOur \"we got a 401\" strategy is \"clear our node assignment and schedule another sync to deal with any problem\"; at the start of a sync we hit node/weave to set our local node assignment, and then proceed with syncing.\n\nWhat I ought to have said was \"the node assignment we get from node/weave isn't guaranteed to be 100% functional until some minutes after our last 401\", because we can make subsequent requests and some of them might fail.\n\n(Fortunately, Bug 692714 largely addresses the issue of 401s happening repeatedly in the middle of consecutive syncs. This bug is to cover any other holes.)\n\nAs you can see, I don't have a clear enough head to address those tonight :D", "creation_time": "2011-10-20T06:50:46Z", "raw_text": "(In reply to Pete Fritchman [:petef] from comment #5)\n> (In reply to Richard Newman [:rnewman] from comment #4)\n> > * Fetching node/weave will only succeed after LDAP replication has completed.\n> \n> No, the node servers talk directly to the LDAP master.\n\nSorry, that was an awful misphrasing on my part. Thanks for correcting!\n\nOur \"we got a 401\" strategy is \"clear our node assignment and schedule another sync to deal with any problem\"; at the start of a sync we hit node/weave to set our local node assignment, and then proceed with syncing.\n\nWhat I ought to have said was \"the node assignment we get from node/weave isn't guaranteed to be 100% functional until some minutes after our last 401\", because we can make subsequent requests and some of them might fail.\n\n(Fortunately, Bug 692714 largely addresses the issue of 401s happening repeatedly in the middle of consecutive syncs. This bug is to cover any other holes.)\n\nAs you can see, I don't have a clear enough head to address those tonight :D", "bug_id": 680323, "id": 5793875, "tags": [], "count": 6, "is_private": false}, {"time": "2011-10-20T06:51:04Z", "attachment_id": null, "text": "*** Bug 641911 has been marked as a duplicate of this bug. ***", "creation_time": "2011-10-20T06:51:04Z", "raw_text": "", "bug_id": 680323, "id": 5793877, "is_private": false, "count": 7, "tags": [], "author": "bugzilla@twinql.com", "creator": "bugzilla@twinql.com"}, {"author": "bugzilla@twinql.com", "creator": "bugzilla@twinql.com", "attachment_id": null, "time": "2012-09-30T19:38:08Z", "text": "Possible candidate for WONTFIX with new auth?", "raw_text": "Possible candidate for WONTFIX with new auth?", "creation_time": "2012-09-30T19:38:08Z", "bug_id": 680323, "id": 6680843, "tags": [], "is_private": false, "count": 8}, {"id": 6682925, "is_private": false, "count": 9, "tags": [], "bug_id": 680323, "creation_time": "2012-10-01T17:17:06Z", "raw_text": "New auth makes this irrelevant, but it sounds like that's not happening any time soon.", "time": "2012-10-01T17:17:06Z", "attachment_id": null, "text": "New auth makes this irrelevant, but it sounds like that's not happening any time soon.", "author": "telliott@mozilla.com", "creator": "telliott@mozilla.com"}]}}}