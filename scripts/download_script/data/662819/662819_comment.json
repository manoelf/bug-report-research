{"bugs": {"662819": {"comments": [{"creator": "jruderman@gmail.com", "author": "jruderman@gmail.com", "bug_id": 662819, "tags": [], "is_private": false, "count": 0, "id": 5519928, "text": "IE9 warns if you download software that is not commonly downloaded.\n\n* http://blogs.msdn.com/b/ie/archive/2011/03/22/smartscreen-174-application-reputation-building-reputation.aspx\n\n* http://blogs.msdn.com/b/ie/archive/2011/05/17/smartscreen-174-application-reputation-in-ie9.aspx\n\n* Key quote: \"When it comes to program downloads, other browsers today either warn on every file or don\u2019t warn at all. Neither of these approaches helps the user make a better decision.\"\n\nThis seems like the only sane solution to the problem of socially engineering attacks that entice users to download and run malicious native software.\n\nMicrosoft's system allows reputation to accrue to the download's hash and code-signing certificate.  We might also want reputation to accrue to the page URL and download URL, especially if they use https and/or link fingerprints (bug 292481).\n\nDesigning the feature to have minimal impact on user privacy may be tricky. Resisting sybil attacks on the reputation system may also be tricky.  Microsoft's posts do not address these issues.\n\nIt might be sensible to partner with Microsoft, Google, Soluto, or an anti-virus vendor on this feature.", "attachment_id": null, "time": "2011-06-08T16:21:44Z", "creation_time": "2011-06-08T16:21:44Z", "raw_text": "IE9 warns if you download software that is not commonly downloaded.\n\n* http://blogs.msdn.com/b/ie/archive/2011/03/22/smartscreen-174-application-reputation-building-reputation.aspx\n\n* http://blogs.msdn.com/b/ie/archive/2011/05/17/smartscreen-174-application-reputation-in-ie9.aspx\n\n* Key quote: \"When it comes to program downloads, other browsers today either warn on every file or don\u2019t warn at all. Neither of these approaches helps the user make a better decision.\"\n\nThis seems like the only sane solution to the problem of socially engineering attacks that entice users to download and run malicious native software.\n\nMicrosoft's system allows reputation to accrue to the download's hash and code-signing certificate.  We might also want reputation to accrue to the page URL and download URL, especially if they use https and/or link fingerprints (bug 292481).\n\nDesigning the feature to have minimal impact on user privacy may be tricky. Resisting sybil attacks on the reputation system may also be tricky.  Microsoft's posts do not address these issues.\n\nIt might be sensible to partner with Microsoft, Google, Soluto, or an anti-virus vendor on this feature."}, {"bug_id": 662819, "id": 5520083, "count": 1, "is_private": false, "tags": [], "time": "2011-06-08T17:26:40Z", "attachment_id": null, "author": "blizzard@mozilla.com", "creator": "blizzard@mozilla.com", "text": "Similar feature for Chrome?\n\nhttp://www.computerworld.com/s/article/9217427/Google_adds_download_defense_to_Chrome_patches_15_bugs", "creation_time": "2011-06-08T17:26:40Z", "raw_text": "Similar feature for Chrome?\n\nhttp://www.computerworld.com/s/article/9217427/Google_adds_download_defense_to_Chrome_patches_15_bugs"}, {"bug_id": 662819, "id": 5520436, "count": 2, "is_private": false, "tags": [], "time": "2011-06-08T18:50:20Z", "attachment_id": null, "text": "Is malware uncommonly downloaded?  I'd expect that malware that propagates through, say, Facebook, gets downloaded much more often than developer tools that I download.", "raw_text": "Is malware uncommonly downloaded?  I'd expect that malware that propagates through, say, Facebook, gets downloaded much more often than developer tools that I download.", "creation_time": "2011-06-08T18:50:20Z", "author": "khuey@kylehuey.com", "creator": "khuey@kylehuey.com"}, {"creator": "chofmann@gmail.com", "author": "chofmann@gmail.com", "text": "also related to Bug 646602 - Installing add-ons from AMO should not invoke the security prompt.\n\nwe actually have quite a bit of meta data for addons that we host to help users make an informed decisions about what they are installing.  work would be needed to unlock this data from amo and integrate it into the installation process of amo hosted addons.\n\nthen there is another project that would be needed to gather similar kinds of meta data for non-amo hosted software.", "attachment_id": null, "time": "2011-06-08T19:12:30Z", "creation_time": "2011-06-08T19:12:30Z", "raw_text": "also related to Bug 646602 - Installing add-ons from AMO should not invoke the security prompt.\n\nwe actually have quite a bit of meta data for addons that we host to help users make an informed decisions about what they are installing.  work would be needed to unlock this data from amo and integrate it into the installation process of amo hosted addons.\n\nthen there is another project that would be needed to gather similar kinds of meta data for non-amo hosted software.", "bug_id": 662819, "tags": [], "count": 3, "is_private": false, "id": 5520520}, {"creation_time": "2011-06-08T20:18:54Z", "raw_text": "Kyle, this is intended to help with malware that constantly moves and changes. If any single piece of malware is frequently downloaded, other strategies come into play.", "creator": "jruderman@gmail.com", "text": "Kyle, this is intended to help with malware that constantly moves and changes. If any single piece of malware is frequently downloaded, other strategies come into play.", "time": "2011-06-08T20:18:54Z", "attachment_id": null, "author": "jruderman@gmail.com", "is_private": false, "count": 4, "tags": [], "id": 5520700, "bug_id": 662819}, {"attachment_id": null, "time": "2011-08-16T19:12:03Z", "text": "Aside from the privacy implications of such a feature (which may or may not be something we can engineer around), there is the question if we are able to deploy infrastructure that is effectively receiving and processing everything our 450M+ users download or visit.", "raw_text": "Aside from the privacy implications of such a feature (which may or may not be something we can engineer around), there is the question if we are able to deploy infrastructure that is effectively receiving and processing everything our 450M+ users download or visit.", "creation_time": "2011-08-16T19:12:03Z", "bug_id": 662819, "id": 5657766, "count": 5, "is_private": false, "tags": [], "author": "gpascutto@mozilla.com", "creator": "gpascutto@mozilla.com"}, {"tags": [], "count": 6, "is_private": false, "id": 5745395, "bug_id": 662819, "creation_time": "2011-09-29T06:37:39Z", "raw_text": "FWIW, one idea that came up at some point during the all-hands is that this perhaps only needs to activate 1) on a page where there is a login/password dialog (need to recognize the common and alternate forms, and perhaps some misspellings, in many languages, which sounds doable) 2) when the user downloads something. So the infrastructure load may not be that big, and the privacy issues are reduced to only those 2 type of pages.", "creator": "gpascutto@mozilla.com", "text": "FWIW, one idea that came up at some point during the all-hands is that this perhaps only needs to activate 1) on a page where there is a login/password dialog (need to recognize the common and alternate forms, and perhaps some misspellings, in many languages, which sounds doable) 2) when the user downloads something. So the infrastructure load may not be that big, and the privacy issues are reduced to only those 2 type of pages.", "author": "gpascutto@mozilla.com", "attachment_id": null, "time": "2011-09-29T06:37:39Z"}, {"raw_text": "getting beat up on not having something like this on the site set up at \n\nhttp://yourbrowsermatters.org/  and in the press at \n\nwww.zdnet.com/blog/bott/microsoft-calls-out-firefox-and-chrome-for-security-weaknesses/4070", "creation_time": "2011-10-11T18:29:59Z", "author": "chofmann@gmail.com", "attachment_id": null, "time": "2011-10-11T18:29:59Z", "text": "getting beat up on not having something like this on the site set up at \n\nhttp://yourbrowsermatters.org/  and in the press at \n\nwww.zdnet.com/blog/bott/microsoft-calls-out-firefox-and-chrome-for-security-weaknesses/4070", "creator": "chofmann@gmail.com", "id": 5775162, "tags": [], "count": 7, "is_private": false, "bug_id": 662819}, {"tags": [], "count": 8, "is_private": false, "id": 5786972, "bug_id": 662819, "creation_time": "2011-10-17T19:05:00Z", "raw_text": "Jesse Rederman pointed out in response to my comment 4 that it is not possible to detect login/password prompts reliably. The reasons why are explained in bug 353922, which talks about something similar.", "text": "Jesse Rederman pointed out in response to my comment 4 that it is not possible to detect login/password prompts reliably. The reasons why are explained in bug 353922, which talks about something similar.", "attachment_id": null, "time": "2011-10-17T19:05:00Z", "creator": "gpascutto@mozilla.com", "author": "gpascutto@mozilla.com"}, {"raw_text": "Status: Google has a service for this, we are waiting on an API doc so we know how to interact with it and can finish weighing pros/cons of deploying their app-rep stuff as an extension to safebrowsing.  Taking the bug for now as I'm working with them to get the API.", "creation_time": "2012-07-02T21:23:37Z", "text": "Status: Google has a service for this, we are waiting on an API doc so we know how to interact with it and can finish weighing pros/cons of deploying their app-rep stuff as an extension to safebrowsing.  Taking the bug for now as I'm working with them to get the API.", "attachment_id": null, "time": "2012-07-02T21:23:37Z", "tags": [], "is_private": false, "count": 9, "id": 6439510, "bug_id": 662819, "creator": "mozbugs@sidstamm.com", "author": "mozbugs@sidstamm.com"}, {"is_private": false, "count": 10, "tags": [], "id": 6557959, "bug_id": 662819, "raw_text": "", "creation_time": "2012-08-15T20:52:51Z", "creator": "mozbugs@sidstamm.com", "text": "*** Bug 650546 has been marked as a duplicate of this bug. ***", "time": "2012-08-15T20:52:51Z", "attachment_id": null, "author": "mozbugs@sidstamm.com"}, {"text": "*** Bug 795339 has been marked as a duplicate of this bug. ***", "time": "2012-10-11T10:12:36Z", "attachment_id": null, "raw_text": "", "creation_time": "2012-10-11T10:12:36Z", "bug_id": 662819, "tags": [], "count": 11, "is_private": false, "id": 6718657, "creator": "gpascutto@mozilla.com", "author": "gpascutto@mozilla.com"}, {"creator": "mmc.bugzilla@gmail.com", "author": "mmc.bugzilla@gmail.com", "tags": [], "is_private": false, "count": 12, "id": 6809043, "bug_id": 662819, "creation_time": "2012-11-09T18:51:23Z", "raw_text": "While we're waiting for the \"official\" API, looks like the call in Chromium is here:\n\nhttp://code.google.com/p/chromium/source/search?q=clientdownloadrequest&origq=clientdownloadrequest&btnG=Search+Trunk\n\nWe need to stuff at least one of sha256/sha1/md5sum hashes, the final url along with any redirects, optionally the filetype and other flags into a request, then process the verdict in response.\n\nThe download manager in firefox seems to be here:\n\nhttp://mxr.mozilla.org/mozilla-central/source/toolkit/components/downloads/nsDownloadManager.cpp\n\nI don't see offhand how to follow the chain of redirects, but from reading the protocol buffer we probably only need the target url. Sure would be nice to have an officially supported API, though :)\n\nIf anyone on this bug knows how to track redirects, hints welcome.\n\nMonica", "text": "While we're waiting for the \"official\" API, looks like the call in Chromium is here:\n\nhttp://code.google.com/p/chromium/source/search?q=clientdownloadrequest&origq=clientdownloadrequest&btnG=Search+Trunk\n\nWe need to stuff at least one of sha256/sha1/md5sum hashes, the final url along with any redirects, optionally the filetype and other flags into a request, then process the verdict in response.\n\nThe download manager in firefox seems to be here:\n\nhttp://mxr.mozilla.org/mozilla-central/source/toolkit/components/downloads/nsDownloadManager.cpp\n\nI don't see offhand how to follow the chain of redirects, but from reading the protocol buffer we probably only need the target url. Sure would be nice to have an officially supported API, though :)\n\nIf anyone on this bug knows how to track redirects, hints welcome.\n\nMonica", "time": "2012-11-09T18:51:23Z", "attachment_id": null}, {"author": "khuey@kylehuey.com", "creator": "khuey@kylehuey.com", "creation_time": "2012-11-09T18:55:44Z", "raw_text": "Without knowing anything about what you're trying to do, you can receive redirect notifications via asyncOnChannelRedirect on an nsIChannelEventSink.", "time": "2012-11-09T18:55:44Z", "attachment_id": null, "text": "Without knowing anything about what you're trying to do, you can receive redirect notifications via asyncOnChannelRedirect on an nsIChannelEventSink.", "id": 6809064, "count": 13, "is_private": false, "tags": [], "bug_id": 662819}, {"count": 14, "is_private": false, "tags": [], "id": 6809095, "bug_id": 662819, "raw_text": "I think the idea is that if there's a redirect chain that leads to a downloaded executable, having the chain is useful in classifying whether or not the binary is malicious. I'll poke around more in the Chromium source to see if that's what actually happens.", "creation_time": "2012-11-09T19:00:33Z", "text": "I think the idea is that if there's a redirect chain that leads to a downloaded executable, having the chain is useful in classifying whether or not the binary is malicious. I'll poke around more in the Chromium source to see if that's what actually happens.", "time": "2012-11-09T19:00:33Z", "attachment_id": null, "creator": "mmc.bugzilla@gmail.com", "author": "mmc.bugzilla@gmail.com"}, {"creator": "mmc.bugzilla@gmail.com", "author": "mmc.bugzilla@gmail.com", "text": "Looks like Chromium does set the redirect chain:\n\nhttp://code.google.com/searchframe#OAMlx_jo-ck/src/chrome/browser/safe_browsing/download_protection_service.cc&exact_package=chromium&q=clientdownloadrequest%20set_url&type=cs&l=659\n\n    ClientDownloadRequest request;\n    request.set_url(info_.download_url_chain.back().spec());\n    request.mutable_digests()->set_sha256(info_.sha256_hash);\n    request.set_length(info_.total_bytes);\n    for (size_t i = 0; i < info_.download_url_chain.size(); ++i) {\n      ClientDownloadRequest::Resource* resource = request.add_resources();\n      resource->set_url(info_.download_url_chain[i].spec());\n      if (i == info_.download_url_chain.size() - 1) {\n        // The last URL in the chain is the download URL.\n        resource->set_type(ClientDownloadRequest::DOWNLOAD_URL);\n        resource->set_referrer(info_.referrer_url.spec());\n        if (!info_.remote_address.empty()) {\n          resource->set_remote_ip(info_.remote_address);\n        }\n      } else {\n        resource->set_type(ClientDownloadRequest::DOWNLOAD_REDIRECT);\n      }\n      // TODO(noelutz): fill out the remote IP addresses.\n    }\n    request.set_user_initiated(info_.user_initiated);\n    request.set_file_basename(info_.target_file.BaseName().AsUTF8Unsafe());\n    request.set_download_type(type_);\n    request.mutable_signature()->CopyFrom(signature_info_);", "attachment_id": null, "time": "2012-11-09T19:04:30Z", "raw_text": "Looks like Chromium does set the redirect chain:\n\nhttp://code.google.com/searchframe#OAMlx_jo-ck/src/chrome/browser/safe_browsing/download_protection_service.cc&exact_package=chromium&q=clientdownloadrequest%20set_url&type=cs&l=659\n\n    ClientDownloadRequest request;\n    request.set_url(info_.download_url_chain.back().spec());\n    request.mutable_digests()->set_sha256(info_.sha256_hash);\n    request.set_length(info_.total_bytes);\n    for (size_t i = 0; i < info_.download_url_chain.size(); ++i) {\n      ClientDownloadRequest::Resource* resource = request.add_resources();\n      resource->set_url(info_.download_url_chain[i].spec());\n      if (i == info_.download_url_chain.size() - 1) {\n        // The last URL in the chain is the download URL.\n        resource->set_type(ClientDownloadRequest::DOWNLOAD_URL);\n        resource->set_referrer(info_.referrer_url.spec());\n        if (!info_.remote_address.empty()) {\n          resource->set_remote_ip(info_.remote_address);\n        }\n      } else {\n        resource->set_type(ClientDownloadRequest::DOWNLOAD_REDIRECT);\n      }\n      // TODO(noelutz): fill out the remote IP addresses.\n    }\n    request.set_user_initiated(info_.user_initiated);\n    request.set_file_basename(info_.target_file.BaseName().AsUTF8Unsafe());\n    request.set_download_type(type_);\n    request.mutable_signature()->CopyFrom(signature_info_);", "creation_time": "2012-11-09T19:04:30Z", "bug_id": 662819, "tags": [], "count": 15, "is_private": false, "id": 6809118}, {"author": "jruderman@gmail.com", "creator": "jruderman@gmail.com", "bug_id": 662819, "id": 6827189, "is_private": false, "count": 16, "tags": [], "time": "2012-11-15T23:06:23Z", "attachment_id": null, "text": "Tracking the entire redirect chain scares me a little, because some URL in the chain might (1) contain private data and/or (2) not realize the final destination is an executable.  Hopefully it's all encrypted before being sent to Google, at least?", "creation_time": "2012-11-15T23:06:23Z", "raw_text": "Tracking the entire redirect chain scares me a little, because some URL in the chain might (1) contain private data and/or (2) not realize the final destination is an executable.  Hopefully it's all encrypted before being sent to Google, at least?"}, {"creator": "mmc.bugzilla@gmail.com", "author": "mmc.bugzilla@gmail.com", "is_private": false, "count": 17, "tags": [], "id": 6827251, "bug_id": 662819, "raw_text": "The URL can always contain private data, for sure, whether it's on the redirect chain or the final URL. Chrome sends requests over SSL, so we should be able to as well (http://code.google.com/searchframe#OAMlx_jo-ck/src/chrome/browser/safe_browsing/download_protection_service.cc&exact_package=chromium&q=clientdownloadrequest&type=cs&l=50)\n\nI'm not sure whether the redirect chain improves classification for that particular request, or whether it's used to improve classification for later requests, or whether it's something as yet unused on the server side. I'll ask.", "creation_time": "2012-11-15T23:22:30Z", "text": "The URL can always contain private data, for sure, whether it's on the redirect chain or the final URL. Chrome sends requests over SSL, so we should be able to as well (http://code.google.com/searchframe#OAMlx_jo-ck/src/chrome/browser/safe_browsing/download_protection_service.cc&exact_package=chromium&q=clientdownloadrequest&type=cs&l=50)\n\nI'm not sure whether the redirect chain improves classification for that particular request, or whether it's used to improve classification for later requests, or whether it's something as yet unused on the server side. I'll ask.", "time": "2012-11-15T23:22:30Z", "attachment_id": null}, {"creator": "mmc.bugzilla@gmail.com", "author": "mmc.bugzilla@gmail.com", "raw_text": "- firefox.js: added prefs for turning on application reputation check, and URL for service\n- downloads.js: add event handlers in case of bad application reputation\n- nsDownloadManager.cpp: The bulk of the changes are in here. Change state machine to check application reputation after the download has finished\n- nsDownloadManager.idl: Adds 2 new states, DOWNLOAD_REP_SCANNING and DOWNLOAD_BAD_REP\n- csd.pb.{cc,h}: These are autogenerated files by the protocol compiler from Chrome's implementation of application reputation (http://git.chromium.org/gitweb/?p=chromium/chromium.git;a=blob_plain;f=chrome/common/safe_browsing/csd.proto)\n- test_app_rep.js: Fakes a malware verdict and checks that DOWNLOAD_BAD_REP state is reached", "creation_time": "2013-01-08T00:11:30Z", "text": "Created attachment 698939\nChanges to download manager to query application reputation.\n\n- firefox.js: added prefs for turning on application reputation check, and URL for service\n- downloads.js: add event handlers in case of bad application reputation\n- nsDownloadManager.cpp: The bulk of the changes are in here. Change state machine to check application reputation after the download has finished\n- nsDownloadManager.idl: Adds 2 new states, DOWNLOAD_REP_SCANNING and DOWNLOAD_BAD_REP\n- csd.pb.{cc,h}: These are autogenerated files by the protocol compiler from Chrome's implementation of application reputation (http://git.chromium.org/gitweb/?p=chromium/chromium.git;a=blob_plain;f=chrome/common/safe_browsing/csd.proto)\n- test_app_rep.js: Fakes a malware verdict and checks that DOWNLOAD_BAD_REP state is reached", "attachment_id": 698939, "time": "2013-01-08T00:11:30Z", "tags": [], "is_private": false, "count": 18, "id": 6972356, "bug_id": 662819}, {"author": "mmc.bugzilla@gmail.com", "creator": "mmc.bugzilla@gmail.com", "attachment_id": 698945, "time": "2013-01-08T00:23:03Z", "text": "Created attachment 698945\nscreencap", "creation_time": "2013-01-08T00:23:03Z", "raw_text": "", "bug_id": 662819, "id": 6972402, "tags": [], "count": 19, "is_private": false}, {"id": 6972445, "tags": [], "count": 20, "is_private": false, "bug_id": 662819, "creation_time": "2013-01-08T00:31:55Z", "raw_text": "We need to avoid doing main-thread I/O to calculate the hash from the file on disk. I think that means a slightly more complicated setup than your existing NS_NewLocalFileInputStream/UpdateFromStream setup, though I'm not sure exactly what the best solution is.", "attachment_id": 698939, "time": "2013-01-08T00:31:55Z", "text": "Comment on attachment 698939\nChanges to download manager to query application reputation.\n\nWe need to avoid doing main-thread I/O to calculate the hash from the file on disk. I think that means a slightly more complicated setup than your existing NS_NewLocalFileInputStream/UpdateFromStream setup, though I'm not sure exactly what the best solution is.", "author": "gavin.sharp@gmail.com", "creator": "gavin.sharp@gmail.com"}, {"tags": [], "is_private": false, "count": 21, "id": 6972457, "bug_id": 662819, "raw_text": "Paolo or Marco may have suggestions for ways to address comment 20.", "creation_time": "2013-01-08T00:34:02Z", "text": "Paolo or Marco may have suggestions for ways to address comment 20.", "time": "2013-01-08T00:34:02Z", "attachment_id": null, "creator": "gavin.sharp@gmail.com", "author": "gavin.sharp@gmail.com"}, {"creator": "mmc.bugzilla@gmail.com", "author": "mmc.bugzilla@gmail.com", "tags": [], "count": 22, "is_private": false, "id": 6972462, "bug_id": 662819, "creation_time": "2013-01-08T00:35:14Z", "raw_text": "This patch is kind of working, in the sense that malware verdicts are computed successfully and reach the \"in progress\" download UI. However, it borrows the UI from the windows AV scan, and that UI seems to be broken. In the \"show all downloads\" dialog, it seems that a download that gets a bad verdict (through application reputation or windows scan) stays stuck in \"Starting...\"\n\nSee http://mxr.mozilla.org/mozilla-central/source/toolkit/locales/en-US/chrome/mozapps/downloads/downloads.dtd, where there are strings for \"Starting\" and \"Scanning\" but no strings like \"Blocked: may contain a virus or malware\" like there is in http://mxr.mozilla.org/mozilla-central/source/toolkit/locales/en-US/chrome/mozapps/downloads/downloads.properties\n\nBlockers:\n- Fix \"show all downloads UI\"\n- Make sure save file and app handlers abort on DOWNLOAD_BAD_REP\n- Get API key from Google\n- Implement exponential backoff if the service 503s", "text": "This patch is kind of working, in the sense that malware verdicts are computed successfully and reach the \"in progress\" download UI. However, it borrows the UI from the windows AV scan, and that UI seems to be broken. In the \"show all downloads\" dialog, it seems that a download that gets a bad verdict (through application reputation or windows scan) stays stuck in \"Starting...\"\n\nSee http://mxr.mozilla.org/mozilla-central/source/toolkit/locales/en-US/chrome/mozapps/downloads/downloads.dtd, where there are strings for \"Starting\" and \"Scanning\" but no strings like \"Blocked: may contain a virus or malware\" like there is in http://mxr.mozilla.org/mozilla-central/source/toolkit/locales/en-US/chrome/mozapps/downloads/downloads.properties\n\nBlockers:\n- Fix \"show all downloads UI\"\n- Make sure save file and app handlers abort on DOWNLOAD_BAD_REP\n- Get API key from Google\n- Implement exponential backoff if the service 503s", "attachment_id": null, "time": "2013-01-08T00:35:14Z"}, {"raw_text": "(In reply to :Gavin Sharp (use gavin@gavinsharp.com for email) from comment #20)\n> Comment on attachment 698939\n> Changes to download manager to query application reputation.\n> \n> We need to avoid doing main-thread I/O to calculate the hash from the file\n> on disk. I think that means a slightly more complicated setup than your\n> existing NS_NewLocalFileInputStream/UpdateFromStream setup, though I'm not\n> sure exactly what the best solution is.\n\nHow about computing the hash wherever the transfer is taking place since the transfer has to read the bytes anyway, and saving the results in nsIDownload?", "creation_time": "2013-01-08T00:37:41Z", "time": "2013-01-08T00:37:41Z", "attachment_id": null, "text": "(In reply to :Gavin Sharp (use gavin@gavinsharp.com for email) from comment #20)\n> Comment on attachment 698939\n> Changes to download manager to query application reputation.\n> \n> We need to avoid doing main-thread I/O to calculate the hash from the file\n> on disk. I think that means a slightly more complicated setup than your\n> existing NS_NewLocalFileInputStream/UpdateFromStream setup, though I'm not\n> sure exactly what the best solution is.\n\nHow about computing the hash wherever the transfer is taking place since the transfer has to read the bytes anyway, and saving the results in nsIDownload?", "id": 6972475, "is_private": false, "count": 23, "tags": [], "bug_id": 662819, "author": "mmc.bugzilla@gmail.com", "creator": "mmc.bugzilla@gmail.com"}, {"is_private": false, "count": 24, "tags": [], "id": 6972500, "bug_id": 662819, "raw_text": "That's a good idea!", "creation_time": "2013-01-08T00:42:11Z", "creator": "gavin.sharp@gmail.com", "text": "That's a good idea!", "attachment_id": null, "time": "2013-01-08T00:42:11Z", "author": "gavin.sharp@gmail.com"}, {"author": "ehsan.akhgari@gmail.com", "creator": "ehsan.akhgari@gmail.com", "raw_text": "(In reply to comment #20)\n> Comment on attachment 698939\n>   --> https://bugzilla.mozilla.org/attachment.cgi?id=698939\n> Changes to download manager to query application reputation.\n> \n> We need to avoid doing main-thread I/O to calculate the hash from the file on\n> disk. I think that means a slightly more complicated setup than your existing\n> NS_NewLocalFileInputStream/UpdateFromStream setup, though I'm not sure exactly\n> what the best solution is.\n\nCould we use NS_AsyncCopy or something?", "creation_time": "2013-01-08T00:56:53Z", "attachment_id": null, "time": "2013-01-08T00:56:53Z", "text": "(In reply to comment #20)\n> Comment on attachment 698939\n>   --> https://bugzilla.mozilla.org/attachment.cgi?id=698939\n> Changes to download manager to query application reputation.\n> \n> We need to avoid doing main-thread I/O to calculate the hash from the file on\n> disk. I think that means a slightly more complicated setup than your existing\n> NS_NewLocalFileInputStream/UpdateFromStream setup, though I'm not sure exactly\n> what the best solution is.\n\nCould we use NS_AsyncCopy or something?", "id": 6972552, "tags": [], "count": 25, "is_private": false, "bug_id": 662819}, {"creator": "paolo.mozmail@amadzone.org", "author": "paolo.mozmail@amadzone.org", "bug_id": 662819, "count": 26, "is_private": false, "tags": [], "id": 6973982, "text": "(In reply to :Gavin Sharp (use gavin@gavinsharp.com for email) from comment #20)\n> We need to avoid doing main-thread I/O to calculate the hash from the file\n> on disk. I think that means a slightly more complicated setup than your\n> existing NS_NewLocalFileInputStream/UpdateFromStream setup, though I'm not\n> sure exactly what the best solution is.\n\nUh, avoiding main-thread I/O is absolutely a requirement, though I'm afraid that\nsaying it's \"slightly more complicated\" is definitely euphemistic... I've learned\nfrom bug 789932 that our network components were designed with main-thread I/O\nin mind.\n\nSo, be prepared for a bit of work here. I'll try to summarize briefly, to avoid\nwriting too much, feel free to ask if something is unclear.\n\nOption 1 is computing the hash after the download finished, by reading the data\nfrom disk. To load the file on a background thread, you need to create the input\nstream and then call nsIStreamTransportService::createInputTransport. But, since\nnsICryptoHash::updateFromStream is _not_ able to leverage nsIAsyncInputStream,\nyou must create an nsIInputStreamPump and pass your own implementation of\nnsIStreamListener to it, that calls UpdateFromStream inside OnDataAvailable.\n\nOption 1-B is doing the same thing, but moving your current synchronous code to\nyour own background thread (so, including the hash computation).\n\nOption 2 is computing the hash while the file is being saved. The issue here is\nthat nsIDownload does not generally execute the download; it only receives\nprogress updates and can call into an nsICancelable to abort the original\nsave operation. If a canceled download is resumed, then nsIDownload contains\nsome code to perform the download, but it is used only in that case.\n\nThis means that, to implement option 2, you would need to implement the hash\ncomputation in several different components that save files. In addition, if\na download is paused and resumed, you would need to persist the mathematical\nparameters that were used to compute the hash up to that point, then resume\ncomputation starting with these saved parameters. I'm not sure if this \"resume\"\nfeature is supported by our existing hashing components - otherwise, you\nwould need to read the entire file again on resume, effectively going back\nto implementing option 1.\n\nIn both cases, keep in mind that some downloads can involve multiple files\n(like saving a complete web page), and hash computation might not make sense\nin that case (that is, it shouldn't take place at all).\n\nObviously, option 1 increases the total download time, while option 2 doesn't,\nbut implementing option 2 is definitely more \"challenging\" than option 1\n(euphemism intended).\n\nI'll mention here, for completeness, that we are working on a new JavaScript\nAPI for downloads in bug 825588, substantially unifying the code paths used\nby downloads. At that point, we'll be able to feed a single BackgroundFileSaver\ncomponent per download, and extend it to leverage its existing background\nthread for hash computation as well. We'll also be able to leverage JSON\nserialization to persist the partial hash parameters if needed.", "time": "2013-01-08T11:53:31Z", "attachment_id": null, "creation_time": "2013-01-08T11:53:31Z", "raw_text": "(In reply to :Gavin Sharp (use gavin@gavinsharp.com for email) from comment #20)\n> We need to avoid doing main-thread I/O to calculate the hash from the file\n> on disk. I think that means a slightly more complicated setup than your\n> existing NS_NewLocalFileInputStream/UpdateFromStream setup, though I'm not\n> sure exactly what the best solution is.\n\nUh, avoiding main-thread I/O is absolutely a requirement, though I'm afraid that\nsaying it's \"slightly more complicated\" is definitely euphemistic... I've learned\nfrom bug 789932 that our network components were designed with main-thread I/O\nin mind.\n\nSo, be prepared for a bit of work here. I'll try to summarize briefly, to avoid\nwriting too much, feel free to ask if something is unclear.\n\nOption 1 is computing the hash after the download finished, by reading the data\nfrom disk. To load the file on a background thread, you need to create the input\nstream and then call nsIStreamTransportService::createInputTransport. But, since\nnsICryptoHash::updateFromStream is _not_ able to leverage nsIAsyncInputStream,\nyou must create an nsIInputStreamPump and pass your own implementation of\nnsIStreamListener to it, that calls UpdateFromStream inside OnDataAvailable.\n\nOption 1-B is doing the same thing, but moving your current synchronous code to\nyour own background thread (so, including the hash computation).\n\nOption 2 is computing the hash while the file is being saved. The issue here is\nthat nsIDownload does not generally execute the download; it only receives\nprogress updates and can call into an nsICancelable to abort the original\nsave operation. If a canceled download is resumed, then nsIDownload contains\nsome code to perform the download, but it is used only in that case.\n\nThis means that, to implement option 2, you would need to implement the hash\ncomputation in several different components that save files. In addition, if\na download is paused and resumed, you would need to persist the mathematical\nparameters that were used to compute the hash up to that point, then resume\ncomputation starting with these saved parameters. I'm not sure if this \"resume\"\nfeature is supported by our existing hashing components - otherwise, you\nwould need to read the entire file again on resume, effectively going back\nto implementing option 1.\n\nIn both cases, keep in mind that some downloads can involve multiple files\n(like saving a complete web page), and hash computation might not make sense\nin that case (that is, it shouldn't take place at all).\n\nObviously, option 1 increases the total download time, while option 2 doesn't,\nbut implementing option 2 is definitely more \"challenging\" than option 1\n(euphemism intended).\n\nI'll mention here, for completeness, that we are working on a new JavaScript\nAPI for downloads in bug 825588, substantially unifying the code paths used\nby downloads. At that point, we'll be able to feed a single BackgroundFileSaver\ncomponent per download, and extend it to leverage its existing background\nthread for hash computation as well. We'll also be able to leverage JSON\nserialization to persist the partial hash parameters if needed."}, {"creation_time": "2013-01-08T16:24:23Z", "raw_text": "Hi Paolo,\n\nMany thanks for your thorough consideration. It sounds like option 1A is the easiest to implement correctly, but for large files the delay may be intolerable. I can't find any recent data on malware size other than this: http://nakedsecurity.sophos.com/2010/07/27/large-piece-malware/\n\nSo it seems that malware sizes probably don't overlap substantially with common large downloads, and we may be able to skip the check if the download is, say, over 10M. Additionally, Google probably has similar issues when computing hashes and may truncate the hash to the first X MB anyway, I will ask.\n\nIf it turns that we can't skip malware checks on large files, then for option 2, one incremental approach might be to add optional in-progress hashing to the most common codepath (nsIInputStream?) and fix the cancel-resume case later, which probably also affects only large downloads.\n\nIt also seems that we should skip the multi-part case -- I notice in chromium code that this check is only supposed to trigger on a handful of executable extensions, anyway.\n\nMonica", "author": "mmc.bugzilla@gmail.com", "attachment_id": null, "time": "2013-01-08T16:24:23Z", "text": "Hi Paolo,\n\nMany thanks for your thorough consideration. It sounds like option 1A is the easiest to implement correctly, but for large files the delay may be intolerable. I can't find any recent data on malware size other than this: http://nakedsecurity.sophos.com/2010/07/27/large-piece-malware/\n\nSo it seems that malware sizes probably don't overlap substantially with common large downloads, and we may be able to skip the check if the download is, say, over 10M. Additionally, Google probably has similar issues when computing hashes and may truncate the hash to the first X MB anyway, I will ask.\n\nIf it turns that we can't skip malware checks on large files, then for option 2, one incremental approach might be to add optional in-progress hashing to the most common codepath (nsIInputStream?) and fix the cancel-resume case later, which probably also affects only large downloads.\n\nIt also seems that we should skip the multi-part case -- I notice in chromium code that this check is only supposed to trigger on a handful of executable extensions, anyway.\n\nMonica", "creator": "mmc.bugzilla@gmail.com", "id": 6975083, "tags": [], "count": 27, "is_private": false, "bug_id": 662819}, {"attachment_id": null, "time": "2013-01-08T18:38:54Z", "author": "paolo.mozmail@amadzone.org", "creator": "paolo.mozmail@amadzone.org", "text": "(In reply to Monica Chew from comment #27)\n> So it seems that malware sizes probably don't overlap substantially with\n> common large downloads, and we may be able to skip the check if the download\n> is, say, over 10M. Additionally, Google probably has similar issues when\n> computing hashes and may truncate the hash to the first X MB anyway, I will\n> ask.\n\nLooks like a good idea.\n\n> If it turns that we can't skip malware checks on large files, then for\n> option 2, one incremental approach might be to add optional in-progress\n> hashing to the most common codepath (nsIInputStream?) and fix the\n> cancel-resume case later, which probably also affects only large downloads.\n\nThere are at least two common code paths, \"Save Link As\" and single-click\ndownloads, that should be handled. And yes, not checking on pause and resume\nmay be a compromise we make initially.", "raw_text": "(In reply to Monica Chew from comment #27)\n> So it seems that malware sizes probably don't overlap substantially with\n> common large downloads, and we may be able to skip the check if the download\n> is, say, over 10M. Additionally, Google probably has similar issues when\n> computing hashes and may truncate the hash to the first X MB anyway, I will\n> ask.\n\nLooks like a good idea.\n\n> If it turns that we can't skip malware checks on large files, then for\n> option 2, one incremental approach might be to add optional in-progress\n> hashing to the most common codepath (nsIInputStream?) and fix the\n> cancel-resume case later, which probably also affects only large downloads.\n\nThere are at least two common code paths, \"Save Link As\" and single-click\ndownloads, that should be handled. And yes, not checking on pause and resume\nmay be a compromise we make initially.", "creation_time": "2013-01-08T18:38:54Z", "bug_id": 662819, "id": 6975834, "is_private": false, "count": 28, "tags": []}, {"creator": "dev.akhawe+mozilla@gmail.com", "author": "dev.akhawe+mozilla@gmail.com", "raw_text": "The other side is, \"how common are large downloads\". I would guess that large downloads are extremely uncommon (basically non-existent) on mobile devices; and increasingly uncommon on desktops. And on desktops, I think the delay won't be that bad: users are already used to this for AVs and Windows Spynet etc.\n\nThat said, if Google only uses the first 10MB in their data then that is obviously the way to go. I wonder if we can also ask the Google folks about how common are the large downloads (based on the pings they receive).", "creation_time": "2013-01-08T22:18:04Z", "text": "The other side is, \"how common are large downloads\". I would guess that large downloads are extremely uncommon (basically non-existent) on mobile devices; and increasingly uncommon on desktops. And on desktops, I think the delay won't be that bad: users are already used to this for AVs and Windows Spynet etc.\n\nThat said, if Google only uses the first 10MB in their data then that is obviously the way to go. I wonder if we can also ask the Google folks about how common are the large downloads (based on the pings they receive).", "time": "2013-01-08T22:18:04Z", "attachment_id": null, "tags": [], "count": 29, "is_private": false, "id": 6976822, "bug_id": 662819}, {"creator": "mmc.bugzilla@gmail.com", "text": "Chromium source seems to indicate that the hash is based on the full file, from files in http://code.google.com/p/chromium/source/search?q=secure_hash_+file%3Asrc%2Fcontent%2Fbrowser%2Fdownload&origq=secure_hash_+file%3Asrc%2Fcontent%2Fbrowser%2Fdownload&btnG=Search+Trunk.\n\nAs to large download frequency, I guess they are pretty uncommon with the exception of torrents -- and we should probably shoot for delays that aren't suckier than on Windows :)\n\nI think I can pass the hash in nsExternalHelperAppService, which has pointers nsITransfer (which I think maps to nsDownloadProxy) and nsIBackgroundFileSaver, which has access to the bytes as they are being read. nsExternalHelperAppService can either notify nsDownloadProxy of the hash when the file is done, or perhaps nsIBackgroundFileSaver can add the hash to nsIFile, if hashes are more generally useful.", "attachment_id": null, "time": "2013-01-09T01:24:54Z", "author": "mmc.bugzilla@gmail.com", "raw_text": "Chromium source seems to indicate that the hash is based on the full file, from files in http://code.google.com/p/chromium/source/search?q=secure_hash_+file%3Asrc%2Fcontent%2Fbrowser%2Fdownload&origq=secure_hash_+file%3Asrc%2Fcontent%2Fbrowser%2Fdownload&btnG=Search+Trunk.\n\nAs to large download frequency, I guess they are pretty uncommon with the exception of torrents -- and we should probably shoot for delays that aren't suckier than on Windows :)\n\nI think I can pass the hash in nsExternalHelperAppService, which has pointers nsITransfer (which I think maps to nsDownloadProxy) and nsIBackgroundFileSaver, which has access to the bytes as they are being read. nsExternalHelperAppService can either notify nsDownloadProxy of the hash when the file is done, or perhaps nsIBackgroundFileSaver can add the hash to nsIFile, if hashes are more generally useful.", "creation_time": "2013-01-09T01:24:54Z", "bug_id": 662819, "is_private": false, "count": 30, "tags": [], "id": 6977464}, {"text": "Hashing only the first part of the file would allow the obvious workaround of putting malware in the last part, or making it 10Mb+epsilon bytes in size. So it's no surprise this isn't done.\n\nLarge (10M+) downloads: ISO images, graphics card drivers, software (executable and source distributions), ...\n\nOn a typical desktop system you're going to be saved for many of these because they will still be in the OS cache. However, for very large downloads, it's going to suck a lot.", "attachment_id": null, "time": "2013-01-09T09:09:37Z", "raw_text": "Hashing only the first part of the file would allow the obvious workaround of putting malware in the last part, or making it 10Mb+epsilon bytes in size. So it's no surprise this isn't done.\n\nLarge (10M+) downloads: ISO images, graphics card drivers, software (executable and source distributions), ...\n\nOn a typical desktop system you're going to be saved for many of these because they will still be in the OS cache. However, for very large downloads, it's going to suck a lot.", "creation_time": "2013-01-09T09:09:37Z", "bug_id": 662819, "tags": [], "count": 31, "is_private": false, "id": 6978244, "creator": "gpascutto@mozilla.com", "author": "gpascutto@mozilla.com"}, {"bug_id": 662819, "tags": [], "is_private": false, "count": 32, "id": 6983027, "text": "Created attachment 700164\nstill borked\n\nI need some xpcom help. BackgroundFileSaver is now computing the hash, but I'm having trouble passing it back to nsDownload. I created a new interface, nsIDownloadInfo, and am trying to pass that back to nsITransfer via nsExternalHelperAppService. However, the call to nsITransfer->OnTransferComplete seems to be disappearing into the ether.\n\nI thought that nsDownload and nsDownloadProxy were the only concrete implementations of nsITransfer, but obviously neither of them are getting nsIDownloadInfo.\n\nAny clues? Also, is the existing hash computation (teeing the input stream in BackgroundFileSaver and passing one to the hasher) acceptable?", "attachment_id": 700164, "time": "2013-01-10T01:57:10Z", "raw_text": "I need some xpcom help. BackgroundFileSaver is now computing the hash, but I'm having trouble passing it back to nsDownload. I created a new interface, nsIDownloadInfo, and am trying to pass that back to nsITransfer via nsExternalHelperAppService. However, the call to nsITransfer->OnTransferComplete seems to be disappearing into the ether.\n\nI thought that nsDownload and nsDownloadProxy were the only concrete implementations of nsITransfer, but obviously neither of them are getting nsIDownloadInfo.\n\nAny clues? Also, is the existing hash computation (teeing the input stream in BackgroundFileSaver and passing one to the hasher) acceptable?", "creation_time": "2013-01-10T01:57:10Z", "creator": "mmc.bugzilla@gmail.com", "author": "mmc.bugzilla@gmail.com"}, {"bug_id": 662819, "tags": [], "count": 33, "is_private": false, "id": 6984338, "text": "Comment on attachment 700164\nstill borked\n\nReview of attachment 700164:\n-----------------------------------------------------------------\n\nHandling the hashing in BackgroundFileSaver is indeed the most efficient and reusable way. I just want to reiterate that this currently applies to single-click downloads only. We'll need a follow-up to use BackgroundFileSaver at least in the \"Save Link As\" code path also, which is a Good Thing in any case. Summary of what we're supporting with this patch:\n- Follow link: YES\n- Auto-start by webpage: YES\n- Save Link As: NO\n- Pause then resume: NO\n- Close browser then reopen: NO\n\nI took a quick look at the code. I don't see at first glance why the function isn't called, but I've not investigated in detail since we need some changes to the approach in any case. My considerations:\n- I suggest filing a different bug for the BackgroundFileSaver part.\n- We must have unit tests for it (added to the existing xpcshell tests).\n- We must support both BackgroundFileSaverStreamListener and\n  BackgroundFileSaverOutputStream.\n- More detailed notes follow!\n\n::: netwerk/base/public/nsIBackgroundFileSaver.idl\n@@ +129,5 @@\n> +/**\n> + * Interface for keeping track of file metadata on download\n> + */\n> +[scriptable, uuid(0e4867ee-5aab-11e2-a9df-33c86088709b)]\n> +interface nsIDownloadInfo : nsISupports\n\nBackgroundFileSaver is independent from nsIDownload and nsITransfer, and should be kept such. So, we don't need a new interface here.\n\nAlso, hash computation should be optional (and possibly, allowing to select the hash type as well).\n\nI'm inclined to just have a new attribute \"hasher\" of type nsICryptoHash in BackgroundFileSaver, null by default, that must be populated by the consumers before calling setTarget. This will allow us to also support quick resuming in the future, if we extend nsICryptoHash to support initialization data.\n\nTo read the hash, we may put a readonly attribute \"hash\" in nsIBackgroundFileSaver, or just let consumers read the result from nsICryptoHash directly, after onSaveComplete is called.\n\n::: netwerk/base/src/BackgroundFileSaver.cpp\n@@ +777,5 @@\n> +  rv = hashOutput->Close();\n> +\n> +  // Update the hash from hashInput\n> +  rv = mHasher->UpdateFromStream(hashInput, UINT32_MAX);\n> +  NS_ENSURE_SUCCESS(rv, rv);\n\nWe should move the hash computation to the background thread, operating on the data available from mPipeInputStream (or written to the file's nsIOutputStream). In addition to leveraging multi-core processors for computations, this way we support both BackgroundFileSaverStreamListener and BackgroundFileSaverOutputStream.\n\nI'm not sure if we can avoid creating a second pipe - but for sure we must not create a new pipe every time OnDataAvailable is called. I'm not an expert in the networking components, different combinations of nsIInputStreamTee/nsIInputStreamPump/nsIStreamListenerTee/nsIPipe can be tried. But in the end, I think the most memory-efficient way is to proxy the file's nsIOutputStream through our own nsIOutputStream implementation, similarly to what \"nsCheckSummedOutputStream.cpp\" does.\n\n::: uriloader/base/nsIWebProgressListener2.idl\n@@ +71,5 @@\n> +\n> +  /**\n> +   * When the transfer is complete, passes metadata about the download.\n> +   */\n> +  void onTransferComplete(in nsIDownloadInfo aDownloadInfo);\n\nnsIWebProgressListener2 is a widely used interface and I wouldn't extend it for this specific use. I'd be fine with adding a specific method on nsITransfer to communicate the hash; nsITransfer is only implemented in the Download Manager (though it's proxied sometimes).\n\n::: uriloader/exthandler/nsIExternalHelperAppService.idl\n@@ +115,5 @@\n>     * information on the current helper app launcher download.\n>     * This reference will be released when the download is finished (after the\n>     * listener receives the STATE_STOP notification).\n>     */\n> +  void setWebProgressListener(in nsITransfer aWebProgressListener);\n\nYou don't need to change the type here, you can QueryInterface to nsITransfer in the function if needed. By the way, you don't seem to be doing anything different with aWebProgressListener?", "attachment_id": 700164, "time": "2013-01-10T11:41:23Z", "raw_text": "Review of attachment 700164:\n-----------------------------------------------------------------\n\nHandling the hashing in BackgroundFileSaver is indeed the most efficient and reusable way. I just want to reiterate that this currently applies to single-click downloads only. We'll need a follow-up to use BackgroundFileSaver at least in the \"Save Link As\" code path also, which is a Good Thing in any case. Summary of what we're supporting with this patch:\n- Follow link: YES\n- Auto-start by webpage: YES\n- Save Link As: NO\n- Pause then resume: NO\n- Close browser then reopen: NO\n\nI took a quick look at the code. I don't see at first glance why the function isn't called, but I've not investigated in detail since we need some changes to the approach in any case. My considerations:\n- I suggest filing a different bug for the BackgroundFileSaver part.\n- We must have unit tests for it (added to the existing xpcshell tests).\n- We must support both BackgroundFileSaverStreamListener and\n  BackgroundFileSaverOutputStream.\n- More detailed notes follow!\n\n::: netwerk/base/public/nsIBackgroundFileSaver.idl\n@@ +129,5 @@\n> +/**\n> + * Interface for keeping track of file metadata on download\n> + */\n> +[scriptable, uuid(0e4867ee-5aab-11e2-a9df-33c86088709b)]\n> +interface nsIDownloadInfo : nsISupports\n\nBackgroundFileSaver is independent from nsIDownload and nsITransfer, and should be kept such. So, we don't need a new interface here.\n\nAlso, hash computation should be optional (and possibly, allowing to select the hash type as well).\n\nI'm inclined to just have a new attribute \"hasher\" of type nsICryptoHash in BackgroundFileSaver, null by default, that must be populated by the consumers before calling setTarget. This will allow us to also support quick resuming in the future, if we extend nsICryptoHash to support initialization data.\n\nTo read the hash, we may put a readonly attribute \"hash\" in nsIBackgroundFileSaver, or just let consumers read the result from nsICryptoHash directly, after onSaveComplete is called.\n\n::: netwerk/base/src/BackgroundFileSaver.cpp\n@@ +777,5 @@\n> +  rv = hashOutput->Close();\n> +\n> +  // Update the hash from hashInput\n> +  rv = mHasher->UpdateFromStream(hashInput, UINT32_MAX);\n> +  NS_ENSURE_SUCCESS(rv, rv);\n\nWe should move the hash computation to the background thread, operating on the data available from mPipeInputStream (or written to the file's nsIOutputStream). In addition to leveraging multi-core processors for computations, this way we support both BackgroundFileSaverStreamListener and BackgroundFileSaverOutputStream.\n\nI'm not sure if we can avoid creating a second pipe - but for sure we must not create a new pipe every time OnDataAvailable is called. I'm not an expert in the networking components, different combinations of nsIInputStreamTee/nsIInputStreamPump/nsIStreamListenerTee/nsIPipe can be tried. But in the end, I think the most memory-efficient way is to proxy the file's nsIOutputStream through our own nsIOutputStream implementation, similarly to what \"nsCheckSummedOutputStream.cpp\" does.\n\n::: uriloader/base/nsIWebProgressListener2.idl\n@@ +71,5 @@\n> +\n> +  /**\n> +   * When the transfer is complete, passes metadata about the download.\n> +   */\n> +  void onTransferComplete(in nsIDownloadInfo aDownloadInfo);\n\nnsIWebProgressListener2 is a widely used interface and I wouldn't extend it for this specific use. I'd be fine with adding a specific method on nsITransfer to communicate the hash; nsITransfer is only implemented in the Download Manager (though it's proxied sometimes).\n\n::: uriloader/exthandler/nsIExternalHelperAppService.idl\n@@ +115,5 @@\n>     * information on the current helper app launcher download.\n>     * This reference will be released when the download is finished (after the\n>     * listener receives the STATE_STOP notification).\n>     */\n> +  void setWebProgressListener(in nsITransfer aWebProgressListener);\n\nYou don't need to change the type here, you can QueryInterface to nsITransfer in the function if needed. By the way, you don't seem to be doing anything different with aWebProgressListener?", "creation_time": "2013-01-10T11:41:23Z", "creator": "paolo.mozmail@amadzone.org", "author": "paolo.mozmail@amadzone.org"}, {"creation_time": "2013-01-12T00:06:13Z", "raw_text": "Getting closer -- the cleanest way to compute the hash seems to be to add hashing to nsLocalFileOutputStream (or rather, nsFileStreamBase), which BackgroundFileSaver uses in the async copy. This requires no extra pipes or streams, doesn't change blocking/nonblocking semantics, and would automatically support BackgroundFileSaver/StreamListener/OutputStream.\n\nExcept that nsICryptoHash is not threadsafe, but according to bsmith nsICryptoHash should only be called from js anyway, I need Digest from ScopedNSSTypes.h\n\nNote that that's not an idl so the Digest/DigestContext are going to have to live in nsFileStreams. But at the moment I am blocked on a compile error that I can't clobber away:\n\n4:10.94 In file included from ../../../dist/include/ScopedNSSTypes.h:16:0,\n 4:10.94                  from /home/mchew/mozilla-central/netwerk/base/src/nsFileStreams.cpp:6:\n 4:10.94 ../../../dist/system_wrappers/cert.h:3:23: fatal error: cert.h: No such file or directory\n\nNext week is a work week, so I might not have time to work on this until the week after.", "attachment_id": null, "time": "2013-01-12T00:06:13Z", "text": "Getting closer -- the cleanest way to compute the hash seems to be to add hashing to nsLocalFileOutputStream (or rather, nsFileStreamBase), which BackgroundFileSaver uses in the async copy. This requires no extra pipes or streams, doesn't change blocking/nonblocking semantics, and would automatically support BackgroundFileSaver/StreamListener/OutputStream.\n\nExcept that nsICryptoHash is not threadsafe, but according to bsmith nsICryptoHash should only be called from js anyway, I need Digest from ScopedNSSTypes.h\n\nNote that that's not an idl so the Digest/DigestContext are going to have to live in nsFileStreams. But at the moment I am blocked on a compile error that I can't clobber away:\n\n4:10.94 In file included from ../../../dist/include/ScopedNSSTypes.h:16:0,\n 4:10.94                  from /home/mchew/mozilla-central/netwerk/base/src/nsFileStreams.cpp:6:\n 4:10.94 ../../../dist/system_wrappers/cert.h:3:23: fatal error: cert.h: No such file or directory\n\nNext week is a work week, so I might not have time to work on this until the week after.", "id": 6993024, "count": 34, "is_private": false, "tags": [], "bug_id": 662819, "author": "mmc.bugzilla@gmail.com", "creator": "mmc.bugzilla@gmail.com"}, {"author": "mmc.bugzilla@gmail.com", "creator": "mmc.bugzilla@gmail.com", "time": "2013-02-01T19:24:47Z", "attachment_id": null, "text": "Status:\n- broke this bug up because probably not everyone cc'ed is interested in code reviews\n- BackgroundFileSaver is nearly hash enabled (bug 829832)\n\nTo be done:\n1) Make nsExtAppHandlerService pass hashes from BackgroundFileSaver to DownloadManager, and DownloadManager actually query the reputation service (bug 837199)\n2) Get API key from Google so they can turn us off in case of emergency\n3) Write metrics, so we know how useful this feature is (bug 837202)\n4) Make all downlaod paths go through BackgroundFileSsaver (bug 837195, bug 837194)", "raw_text": "Status:\n- broke this bug up because probably not everyone cc'ed is interested in code reviews\n- BackgroundFileSaver is nearly hash enabled (bug 829832)\n\nTo be done:\n1) Make nsExtAppHandlerService pass hashes from BackgroundFileSaver to DownloadManager, and DownloadManager actually query the reputation service (bug 837199)\n2) Get API key from Google so they can turn us off in case of emergency\n3) Write metrics, so we know how useful this feature is (bug 837202)\n4) Make all downlaod paths go through BackgroundFileSsaver (bug 837195, bug 837194)", "creation_time": "2013-02-01T19:24:47Z", "bug_id": 662819, "id": 7062519, "is_private": false, "count": 35, "tags": []}, {"creator": "gavin.sharp@gmail.com", "author": "gavin.sharp@gmail.com", "count": 36, "is_private": false, "tags": [], "id": 7063457, "bug_id": 662819, "creation_time": "2013-02-01T23:03:07Z", "raw_text": "You may be interested in bug 835890 as well.", "text": "You may be interested in bug 835890 as well.", "attachment_id": null, "time": "2013-02-01T23:03:07Z"}, {"creator": "jruderman@gmail.com", "author": "jruderman@gmail.com", "is_private": false, "count": 37, "tags": [], "id": 7299081, "bug_id": 662819, "creation_time": "2013-04-10T13:59:20Z", "raw_text": "More from Google:\n\nhttp://www.csoonline.com/article/731494/camp-for-chrome-catches-99-of-malware-google-says\n\nhttps://www.cs.jhu.edu/~moheeb/aburajab-ndss-13.pdf", "text": "More from Google:\n\nhttp://www.csoonline.com/article/731494/camp-for-chrome-catches-99-of-malware-google-says\n\nhttps://www.cs.jhu.edu/~moheeb/aburajab-ndss-13.pdf", "attachment_id": null, "time": "2013-04-10T13:59:20Z"}, {"raw_text": "Since application reputation would be transmitting information about URLs and file contents that would sometimes be protected by TLS (e.g. https://example.org/example.exe), it should be protected by HTTPS. So, I think that bug 783047 should also be a prerequisite for enabling application reputation, unless application reputation is somehow already using HTTPS independently of fixing bug 783047. (In which case, please just remove the bug dependency.)", "creation_time": "2013-07-08T18:29:31Z", "attachment_id": null, "time": "2013-07-08T18:29:31Z", "text": "Since application reputation would be transmitting information about URLs and file contents that would sometimes be protected by TLS (e.g. https://example.org/example.exe), it should be protected by HTTPS. So, I think that bug 783047 should also be a prerequisite for enabling application reputation, unless application reputation is somehow already using HTTPS independently of fixing bug 783047. (In which case, please just remove the bug dependency.)", "id": 7610906, "tags": [], "count": 38, "is_private": false, "bug_id": 662819, "author": "brian@briansmith.org", "creator": "brian@briansmith.org"}, {"creation_time": "2013-07-08T18:56:53Z", "raw_text": "mmc said that the application reputation endpoint is already HTTPS so bug 783047 isn't a prerequisite.", "attachment_id": null, "time": "2013-07-08T18:56:53Z", "text": "mmc said that the application reputation endpoint is already HTTPS so bug 783047 isn't a prerequisite.", "id": 7611033, "tags": [], "count": 39, "is_private": false, "bug_id": 662819, "author": "brian@briansmith.org", "creator": "brian@briansmith.org"}, {"creation_time": "2013-09-27T21:07:51Z", "raw_text": "This is waiting on bug 895476 and bug 887044 to be minimally useful (i.e., turned on in Nightly).", "time": "2013-09-27T21:07:51Z", "attachment_id": null, "text": "This is waiting on bug 895476 and bug 887044 to be minimally useful (i.e., turned on in Nightly).", "id": 7912479, "tags": [], "count": 40, "is_private": false, "bug_id": 662819, "author": "mmc.bugzilla@gmail.com", "creator": "mmc.bugzilla@gmail.com"}, {"author": "bkerensa@gmail.com", "creator": "bkerensa@gmail.com", "creation_time": "2014-04-21T05:41:10Z", "raw_text": "Tracking for now so Relman can keep an eye on this.", "attachment_id": null, "time": "2014-04-21T05:41:10Z", "text": "Tracking for now so Relman can keep an eye on this.", "id": 8686585, "tags": [], "count": 41, "is_private": false, "bug_id": 662819}, {"bug_id": 662819, "count": 42, "is_private": false, "tags": [], "id": 8769379, "creator": "lukasblakk+bugs@gmail.com", "text": "We do not typically track the tracking bugs, when the feature is landed and enabled in m-c we can track it if we are intending to uplift to channels.  This bug, and associated work, looks like it is spread out around a bunch of smaller bugs where none of them look like major features we should be monitoring or noting for a specific version. If there are any specific bugs that counter this perception, please nominate them.", "attachment_id": null, "time": "2014-05-08T18:35:32Z", "author": "lukasblakk+bugs@gmail.com", "creation_time": "2014-05-08T18:35:32Z", "raw_text": "We do not typically track the tracking bugs, when the feature is landed and enabled in m-c we can track it if we are intending to uplift to channels.  This bug, and associated work, looks like it is spread out around a bunch of smaller bugs where none of them look like major features we should be monitoring or noting for a specific version. If there are any specific bugs that counter this perception, please nominate them."}, {"creator": "sledru@mozilla.com", "author": "sledru@mozilla.com", "is_private": false, "count": 43, "tags": [], "id": 9071988, "bug_id": 662819, "creation_time": "2014-07-18T12:08:14Z", "raw_text": "Added to the 31 release notes with the wording: \"New Block malware from downloaded files (learn more)\"\n\nlearn more points to https://wiki.mozilla.org/Security/Features/Application_Reputation_Design_Doc", "text": "Added to the 31 release notes with the wording: \"New Block malware from downloaded files (learn more)\"\n\nlearn more points to https://wiki.mozilla.org/Security/Features/Application_Reputation_Design_Doc", "time": "2014-07-18T12:08:14Z", "attachment_id": null}, {"id": 9185467, "count": 44, "is_private": false, "tags": [], "bug_id": 662819, "creation_time": "2014-08-14T19:58:32Z", "raw_text": "Is there a good reason not to mark this FIXED?", "attachment_id": null, "time": "2014-08-14T19:58:32Z", "text": "Is there a good reason not to mark this FIXED?", "author": "gavin.sharp@gmail.com", "creator": "gavin.sharp@gmail.com"}, {"count": 45, "is_private": false, "tags": [], "id": 9185471, "bug_id": 662819, "creation_time": "2014-08-14T19:59:17Z", "raw_text": "", "text": "*** Bug 452176 has been marked as a duplicate of this bug. ***", "time": "2014-08-14T19:59:17Z", "attachment_id": null, "creator": "gavin.sharp@gmail.com", "author": "gavin.sharp@gmail.com"}, {"bug_id": 662819, "tags": [], "count": 46, "is_private": false, "id": 9441302, "text": "(In reply to :Gavin Sharp [email: gavin@gavinsharp.com] from comment #44)\n> Is there a good reason not to mark this FIXED?\n\nThe strings are still being discussed in bug 1053890, even though the bug is marked as fixed. (No, I'm not the only one discussing it.) And there's the issue of users who, due to the current lack of a per-file override, may have disabled the entire anti-malware or safebrowsing features, despite only wanting to bypass it in a specific instance. We may want to consider resetting those preferences (with a release note explaining why).", "attachment_id": null, "time": "2014-10-14T00:14:59Z", "raw_text": "(In reply to :Gavin Sharp [email: gavin@gavinsharp.com] from comment #44)\n> Is there a good reason not to mark this FIXED?\n\nThe strings are still being discussed in bug 1053890, even though the bug is marked as fixed. (No, I'm not the only one discussing it.) And there's the issue of users who, due to the current lack of a per-file override, may have disabled the entire anti-malware or safebrowsing features, despite only wanting to bypass it in a specific instance. We may want to consider resetting those preferences (with a release note explaining why).", "creation_time": "2014-10-14T00:14:59Z", "creator": "terrell.kelley@gmail.com", "author": "terrell.kelley@gmail.com"}, {"time": "2014-10-14T11:38:05Z", "attachment_id": null, "author": "gpascutto@mozilla.com", "text": "(In reply to Terrell Kelley from comment #46)\n> (In reply to :Gavin Sharp [email: gavin@gavinsharp.com] from comment #44)\n> > Is there a good reason not to mark this FIXED?\n> \n> The strings are still being discussed in bug 1053890,\n\nFurther bikeshedding around the exact strings is a trivial issue compared to the actual override not being implemented yet.\n\nThe problem is that without an override, we're uncomfortable enabling the remote lookups, which were envisioned as part of this feature and are needed for it's full effectiveness. So I think we can leave this open until that part is completed.\n\n> We may want to consider resetting those preferences (with a release note explaining why).\n\nThey have a privacy impact so I think that's a tough sell. Bug 1057848 modified the preferences to add specific ones for the new feature.", "creator": "gpascutto@mozilla.com", "creation_time": "2014-10-14T11:38:05Z", "raw_text": "(In reply to Terrell Kelley from comment #46)\n> (In reply to :Gavin Sharp [email: gavin@gavinsharp.com] from comment #44)\n> > Is there a good reason not to mark this FIXED?\n> \n> The strings are still being discussed in bug 1053890,\n\nFurther bikeshedding around the exact strings is a trivial issue compared to the actual override not being implemented yet.\n\nThe problem is that without an override, we're uncomfortable enabling the remote lookups, which were envisioned as part of this feature and are needed for it's full effectiveness. So I think we can leave this open until that part is completed.\n\n> We may want to consider resetting those preferences (with a release note explaining why).\n\nThey have a privacy impact so I think that's a tough sell. Bug 1057848 modified the preferences to add specific ones for the new feature.", "bug_id": 662819, "id": 9443342, "is_private": false, "count": 47, "tags": []}, {"creator": "heaven-seven@yandex.ru", "author": "heaven-seven@yandex.ru", "bug_id": 662819, "count": 48, "is_private": false, "tags": [], "id": 9932782, "text": "It would be great if this feature is implemented as a plug-in which everybody can add to FF in case they need it.", "time": "2015-02-18T20:45:34Z", "attachment_id": null, "creation_time": "2015-02-18T20:45:34Z", "raw_text": "It would be great if this feature is implemented as a plug-in which everybody can add to FF in case they need it."}, {"author": "gpascutto@mozilla.com", "creator": "gpascutto@mozilla.com", "bug_id": 662819, "id": 9932823, "tags": [], "count": 49, "is_private": false, "time": "2015-02-18T20:52:47Z", "attachment_id": null, "text": "This feature was implemented quite a while ago, the problem was/is that being able to \"unblock\" blocked files turned out to be impossible without rewriting large parts of Firefox' download UI. See for example bug 1068656.", "creation_time": "2015-02-18T20:52:47Z", "raw_text": "This feature was implemented quite a while ago, the problem was/is that being able to \"unblock\" blocked files turned out to be impossible without rewriting large parts of Firefox' download UI. See for example bug 1068656."}, {"creator": "heaven-seven@yandex.ru", "author": "heaven-seven@yandex.ru", "tags": [], "is_private": false, "count": 50, "id": 9932850, "bug_id": 662819, "creation_time": "2015-02-18T20:58:54Z", "raw_text": "I wonder why it's implementation was started without the ability to \"unblock\" blocked files! I wonder twice why it is not optional, but silently enabled by default!\n\nBTW, there must be sources of download manager in the repo without this \"feature\". Guess, rollback is much more easy than rewriting those large parts.", "text": "I wonder why it's implementation was started without the ability to \"unblock\" blocked files! I wonder twice why it is not optional, but silently enabled by default!\n\nBTW, there must be sources of download manager in the repo without this \"feature\". Guess, rollback is much more easy than rewriting those large parts.", "time": "2015-02-18T20:58:54Z", "attachment_id": null}, {"id": 9933219, "is_private": false, "count": 51, "tags": [], "bug_id": 662819, "raw_text": "Implementations of new things tend to start from nothing, the feature is optional, togglable via preferences, and generally speaking every feature which is considered a net benefit is enabled by default in Firefox. Most parts of it (the ones who could give most false positives) are disabled until the unblock UI can be finished.", "creation_time": "2015-02-18T22:07:52Z", "attachment_id": null, "time": "2015-02-18T22:07:52Z", "text": "Implementations of new things tend to start from nothing, the feature is optional, togglable via preferences, and generally speaking every feature which is considered a net benefit is enabled by default in Firefox. Most parts of it (the ones who could give most false positives) are disabled until the unblock UI can be finished.", "author": "gpascutto@mozilla.com", "creator": "gpascutto@mozilla.com"}, {"id": 11407804, "tags": [], "count": 52, "is_private": false, "bug_id": 662819, "raw_text": "There is a complete UI for this in 48 and we are blocking all verdict types.", "creation_time": "2016-05-13T17:59:31Z", "time": "2016-05-13T17:59:31Z", "attachment_id": null, "text": "There is a complete UI for this in 48 and we are blocking all verdict types.", "author": "francois@fmarier.org", "creator": "francois@fmarier.org"}]}}, "comments": {}}