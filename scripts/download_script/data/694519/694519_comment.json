{"bugs": {"694519": {"comments": [{"attachment_id": 567037, "raw_text": "", "tags": [], "bug_id": 694519, "text": "Created attachment 567037\nCrude python web sockets server", "is_private": false, "count": 0, "id": 5782278, "creator": "dirkjan@ochtman.nl", "time": "2011-10-14T09:59:57Z", "creation_time": "2011-10-14T09:59:57Z", "author": "dirkjan@ochtman.nl"}, {"creation_time": "2011-10-14T10:00:35Z", "time": "2011-10-14T10:00:35Z", "creator": "dirkjan@ochtman.nl", "author": "dirkjan@ochtman.nl", "id": 5782279, "count": 1, "is_private": false, "text": "Created attachment 567038\nHTML web sockets client", "bug_id": 694519, "tags": [], "attachment_id": 567038, "raw_text": ""}, {"author": "dirkjan@ochtman.nl", "creator": "dirkjan@ochtman.nl", "time": "2011-10-14T10:08:48Z", "creation_time": "2011-10-14T10:08:48Z", "is_private": false, "count": 2, "id": 5782290, "tags": [], "text": "These files represent a simplified example of an application I wrote at work. First start the server (tested with Python 2.7, should hopefully also work with 2.6 or 2.5, might require minor changes, I'm happy to help). Then open the HTML page (it should listen to localhost:8000 by default).\n\nOn my computer, with THROTTLE = 0.0 (see top of Python code), the browser UI starts being unresponsive, more so with time (e.g. there seems to be a backlog of messages to process). This is mostly noticeable to me in the tab bar: closing the tab containing the test page is sluggish, so is opening a new tab, the tab bar seems to lag the content chrome. Clicking a link on the test page to go to another page also gets exceedingly slow. Note also that the timers getting set up (to clear the background marking of a fresh values) tend not to fire (on very high rates) or bunch up and get fired with a group at once.\n\nIt all seems to work rather better in Chrome. And I wasn't sure what component this bug fit with... But I talked about it with bz on IRC a while ago, so I hope he might fix that for me.", "bug_id": 694519, "raw_text": "These files represent a simplified example of an application I wrote at work. First start the server (tested with Python 2.7, should hopefully also work with 2.6 or 2.5, might require minor changes, I'm happy to help). Then open the HTML page (it should listen to localhost:8000 by default).\n\nOn my computer, with THROTTLE = 0.0 (see top of Python code), the browser UI starts being unresponsive, more so with time (e.g. there seems to be a backlog of messages to process). This is mostly noticeable to me in the tab bar: closing the tab containing the test page is sluggish, so is opening a new tab, the tab bar seems to lag the content chrome. Clicking a link on the test page to go to another page also gets exceedingly slow. Note also that the timers getting set up (to clear the background marking of a fresh values) tend not to fire (on very high rates) or bunch up and get fired with a group at once.\n\nIt all seems to work rather better in Chrome. And I wasn't sure what component this bug fit with... But I talked about it with bz on IRC a while ago, so I hope he might fix that for me.", "attachment_id": null}, {"attachment_id": 567039, "raw_text": "", "text": "Created attachment 567039\nAdded link, fixed IP.", "bug_id": 694519, "tags": [], "count": 3, "id": 5782294, "is_private": false, "creation_time": "2011-10-14T10:10:56Z", "time": "2011-10-14T10:10:56Z", "creator": "dirkjan@ochtman.nl", "author": "dirkjan@ochtman.nl"}, {"attachment_id": null, "raw_text": "I get\nException in thread Thread-1:\nTraceback (most recent call last):\n  File \"/usr/lib/python2.6/threading.py\", line 525, in __bootstrap_inner\n    self.run()\n  File \"/usr/lib/python2.6/threading.py\", line 477, in run\n    self.__target(*self.__args, **self.__kwargs)\n  File \"ws.py\", line 119, in handle\n    sock.send(self.proto.handshake(headers, lines))\nAttributeError: 'Handle' object has no attribute 'proto'", "tags": [], "bug_id": 694519, "text": "I get\nException in thread Thread-1:\nTraceback (most recent call last):\n  File \"/usr/lib/python2.6/threading.py\", line 525, in __bootstrap_inner\n    self.run()\n  File \"/usr/lib/python2.6/threading.py\", line 477, in run\n    self.__target(*self.__args, **self.__kwargs)\n  File \"ws.py\", line 119, in handle\n    sock.send(self.proto.handshake(headers, lines))\nAttributeError: 'Handle' object has no attribute 'proto'", "count": 4, "id": 5782320, "is_private": false, "time": "2011-10-14T10:30:40Z", "creation_time": "2011-10-14T10:30:40Z", "creator": "bugs@pettay.fi", "author": "bugs@pettay.fi"}, {"is_private": false, "id": 5782342, "count": 5, "creator": "bugs@pettay.fi", "creation_time": "2011-10-14T10:45:02Z", "time": "2011-10-14T10:45:02Z", "author": "bugs@pettay.fi", "attachment_id": null, "raw_text": "But in general, if I read the server code correctly, it just sends lots of messages to\nbrowser, and especially if the server is running in the same machine as browser, that leads to\nnew events in the event loop all the time. And when those events are processed, they\nend up changing DOM which causes layout changes etc.\n\nBut need to profile this anyway, once I get a working server ;)\n\nChrome has separate process for its UI, so it can handle this situation better.\nI wonder if the page itself is laggy in Chrome?", "bug_id": 694519, "text": "But in general, if I read the server code correctly, it just sends lots of messages to\nbrowser, and especially if the server is running in the same machine as browser, that leads to\nnew events in the event loop all the time. And when those events are processed, they\nend up changing DOM which causes layout changes etc.\n\nBut need to profile this anyway, once I get a working server ;)\n\nChrome has separate process for its UI, so it can handle this situation better.\nI wonder if the page itself is laggy in Chrome?", "tags": []}, {"tags": [], "bug_id": 694519, "text": "Created attachment 567047\nCrude python web sockets server (take 2)\n\nThis server should not exhibit the traceback shown above.", "attachment_id": 567047, "raw_text": "This server should not exhibit the traceback shown above.", "creator": "dirkjan@ochtman.nl", "time": "2011-10-14T10:57:34Z", "creation_time": "2011-10-14T10:57:34Z", "author": "dirkjan@ochtman.nl", "is_private": false, "count": 6, "id": 5782374}, {"tags": [], "bug_id": 694519, "text": "Exception in thread Thread-1:\nTraceback (most recent call last):\n  File \"/usr/lib/python2.6/threading.py\", line 525, in __bootstrap_inner\n    self.run()\n  File \"/usr/lib/python2.6/threading.py\", line 477, in run\n    self.__target(*self.__args, **self.__kwargs)\n  File \"server.py\", line 119, in handle\n    sock.send(self.proto.handshake(headers, lines))\n  File \"server.py\", line 27, in handshake\n    key = headers['Sec-WebSocket-Key']\nKeyError: 'Sec-WebSocket-Key'", "raw_text": "Exception in thread Thread-1:\nTraceback (most recent call last):\n  File \"/usr/lib/python2.6/threading.py\", line 525, in __bootstrap_inner\n    self.run()\n  File \"/usr/lib/python2.6/threading.py\", line 477, in run\n    self.__target(*self.__args, **self.__kwargs)\n  File \"server.py\", line 119, in handle\n    sock.send(self.proto.handshake(headers, lines))\n  File \"server.py\", line 27, in handshake\n    key = headers['Sec-WebSocket-Key']\nKeyError: 'Sec-WebSocket-Key'", "attachment_id": null, "author": "bugs@pettay.fi", "creator": "bugs@pettay.fi", "time": "2011-10-14T15:14:52Z", "creation_time": "2011-10-14T15:14:52Z", "is_private": false, "count": 7, "id": 5782782}, {"count": 8, "id": 5782982, "is_private": false, "author": "dirkjan@ochtman.nl", "time": "2011-10-14T16:42:56Z", "creation_time": "2011-10-14T16:42:56Z", "creator": "dirkjan@ochtman.nl", "raw_text": "Are you visiting the port on which the server runs? The server *only* contains the web socket server, you have to load the test.html into the browser as a local file.", "attachment_id": null, "bug_id": 694519, "text": "Are you visiting the port on which the server runs? The server *only* contains the web socket server, you have to load the test.html into the browser as a local file.", "tags": []}, {"tags": [], "bug_id": 694519, "text": "Oh, oops. yes. I somehow thought the server can handle http and ws", "attachment_id": null, "raw_text": "Oh, oops. yes. I somehow thought the server can handle http and ws", "time": "2011-10-14T16:45:37Z", "creation_time": "2011-10-14T16:45:37Z", "creator": "bugs@pettay.fi", "author": "bugs@pettay.fi", "id": 5782994, "count": 9, "is_private": false}, {"id": 5783316, "count": 10, "is_private": false, "creation_time": "2011-10-14T18:38:11Z", "time": "2011-10-14T18:38:11Z", "creator": "bzbarsky@mit.edu", "author": "bzbarsky@mit.edu", "attachment_id": null, "raw_text": "> I wonder if the page itself is laggy in Chrome?\n\ndjc, any data on that?\n\nWhat sort of data is comming in the messages?  Is this setting up and clearing thousands of timeouts at a time?", "tags": [], "bug_id": 694519, "text": "> I wonder if the page itself is laggy in Chrome?\n\ndjc, any data on that?\n\nWhat sort of data is comming in the messages?  Is this setting up and clearing thousands of timeouts at a time?"}, {"tags": [], "text": "You could try Chrome for yourself? :) I tried Chrome for a bit and hit the link, and it was quick, but maybe I didn't let it run long enough before clicking. But I think our actual app also flips to the next page much quicker.\n\nYeah, it's setting up a lot of timeouts. I'd guess it's a lot like the messages the test script sends; see line 123 in the server script. They would tend to be a little bursty in my real-world app, and probably less-uniformly distributed over the table rows.", "bug_id": 694519, "attachment_id": null, "raw_text": "You could try Chrome for yourself? :) I tried Chrome for a bit and hit the link, and it was quick, but maybe I didn't let it run long enough before clicking. But I think our actual app also flips to the next page much quicker.\n\nYeah, it's setting up a lot of timeouts. I'd guess it's a lot like the messages the test script sends; see line 123 in the server script. They would tend to be a little bursty in my real-world app, and probably less-uniformly distributed over the table rows.", "time": "2011-10-14T19:59:47Z", "creation_time": "2011-10-14T19:59:47Z", "creator": "dirkjan@ochtman.nl", "author": "dirkjan@ochtman.nl", "count": 11, "id": 5783513, "is_private": false}, {"count": 12, "id": 5783580, "is_private": false, "author": "bzbarsky@mit.edu", "creation_time": "2011-10-14T20:35:09Z", "time": "2011-10-14T20:35:09Z", "creator": "bzbarsky@mit.edu", "raw_text": "> You could try Chrome for yourself?\n\nI could once I take the time to figure out how to actually run your server, etc.  Step-by-step steps to reproduce would go a long way here....", "attachment_id": null, "tags": [], "text": "> You could try Chrome for yourself?\n\nI could once I take the time to figure out how to actually run your server, etc.  Step-by-step steps to reproduce would go a long way here....", "bug_id": 694519}, {"bug_id": 694519, "text": "So are we reading from network faster than we can process in the main thread.", "tags": [], "raw_text": "So are we reading from network faster than we can process in the main thread.", "attachment_id": null, "author": "bugs@pettay.fi", "creation_time": "2011-10-14T20:44:54Z", "time": "2011-10-14T20:44:54Z", "creator": "bugs@pettay.fi", "id": 5783597, "count": 13, "is_private": false}, {"tags": [], "text": "(In reply to Boris Zbarsky (:bz) from comment #12)\n> I could once I take the time to figure out how to actually run your server,\n> etc.  Step-by-step steps to reproduce would go a long way here....\n\nYeah, I know this is not exactly minimal. But I lack enough knowledge of internals to say why it's slow or makes the UI sluggish, sorry...", "bug_id": 694519, "raw_text": "(In reply to Boris Zbarsky (:bz) from comment #12)\n> I could once I take the time to figure out how to actually run your server,\n> etc.  Step-by-step steps to reproduce would go a long way here....\n\nYeah, I know this is not exactly minimal. But I lack enough knowledge of internals to say why it's slow or makes the UI sluggish, sorry...", "attachment_id": null, "author": "dirkjan@ochtman.nl", "time": "2011-10-14T20:50:30Z", "creation_time": "2011-10-14T20:50:30Z", "creator": "dirkjan@ochtman.nl", "id": 5783611, "count": 14, "is_private": false}, {"is_private": false, "attachment_id": null, "id": 5783642, "count": 15, "raw_text": "I have knowledge of internals and a profiler.  What I don't have is good step-by-step instructions on what to do with the two attachments to this bug.  Neither does Olli, who's already spent several hours trying to make use of them.  I'm happy to look into the actual issue, but I don't have several hours to spend sorting out what to do with those attachments... Again, step-by-step instructions would be much appreciated.", "creator": "bzbarsky@mit.edu", "time": "2011-10-14T21:00:47Z", "creation_time": "2011-10-14T21:00:47Z", "author": "bzbarsky@mit.edu", "bug_id": 694519, "text": "I have knowledge of internals and a profiler.  What I don't have is good step-by-step instructions on what to do with the two attachments to this bug.  Neither does Olli, who's already spent several hours trying to make use of them.  I'm happy to look into the actual issue, but I don't have several hours to spend sorting out what to do with those attachments... Again, step-by-step instructions would be much appreciated.", "tags": []}, {"tags": [], "text": "On linux:\npython server.py\n\nand load the html file in the browser.\n(I loaded it from local harddrive)", "bug_id": 694519, "raw_text": "On linux:\npython server.py\n\nand load the html file in the browser.\n(I loaded it from local harddrive)", "attachment_id": null, "author": "bugs@pettay.fi", "time": "2011-10-14T21:04:58Z", "creation_time": "2011-10-14T21:04:58Z", "creator": "bugs@pettay.fi", "count": 16, "id": 5783650, "is_private": false}, {"tags": [], "text": "Thanks.  Looking.", "bug_id": 694519, "raw_text": "Thanks.  Looking.", "attachment_id": null, "author": "bzbarsky@mit.edu", "creation_time": "2011-10-14T21:10:43Z", "time": "2011-10-14T21:10:43Z", "creator": "bzbarsky@mit.edu", "count": 17, "id": 5783671, "is_private": false}, {"id": 5783731, "count": 18, "is_private": false, "time": "2011-10-14T21:30:32Z", "creation_time": "2011-10-14T21:30:32Z", "creator": "bzbarsky@mit.edu", "author": "bzbarsky@mit.edu", "attachment_id": null, "raw_text": "OK, so on my machine (Mac) one core was just pegged by the python server.\n\nThe other core was mostly us.\n\nFor our process, 15% of the time is kernel time; lots of select() and recvfrom and read and write.\n\n13% of our time is the socket transport thread polling, posting events to the main thread via WebSocketChannel::ProcessInput, reading from the websocket async streams, etc, etc.\n\n2-3% on the CC thread.\n\nBack on the main thread, 23% of the time is painting and 10% is reflow flushed via WillPaint notifications.  This will get better when we paint off the refresh driver, I bet.\n\nThe remaining 30% of the time or so is the actual websocket event processing on the main thread.  A bit of this is the native event processing that the mac event loop does on every plevent, but about 25% is calling out into JS.  This breaks down as:\n\n  13% SetInnerHTML calls (2/3 is removing the old content and its frames, actually;\n      painting off the refresh driver would help here too, since those frames would not\n      exist).\n   7% is setTimeout and clearTimeout; half is xpconnect overhead and the other half is\n      the actual object management and so forth.\n   3% is JS jitcode\n 0.5% getElementsByTagName\n 0.5% setAttribute\n\nSo actionable items:\n\n1) Land bug 598482.\n2) Quickstub setTimeout and clearTimeout (why aren't they already?)\n3) Figure out how to deal with the event loop swampage better.\n\nIdeally, in a e10s world, the socket transport thread would just directly post events to the content process....\n\nWhat I see in Chrome is that the UI is responsive (no surprise) but the renderer process is completely hosed: I can't select text in the webpage, the cells update at 1/10 the rate the update at in Gecko, getting slower and slower until they freeze altogether, and after clicking the link in the page there is no response for 20 seconds or so even when the cells are updating.\n\nOh, and we're definitely getting the events off the network faster than we can process them; I just killed the python server about 40 seconds ago and we're still updating table cells now.  Chrome seems to handle it like this: after killing the python server the content process is still frozen for a minute or two and then there is a single update that repaints.", "tags": [], "text": "OK, so on my machine (Mac) one core was just pegged by the python server.\n\nThe other core was mostly us.\n\nFor our process, 15% of the time is kernel time; lots of select() and recvfrom and read and write.\n\n13% of our time is the socket transport thread polling, posting events to the main thread via WebSocketChannel::ProcessInput, reading from the websocket async streams, etc, etc.\n\n2-3% on the CC thread.\n\nBack on the main thread, 23% of the time is painting and 10% is reflow flushed via WillPaint notifications.  This will get better when we paint off the refresh driver, I bet.\n\nThe remaining 30% of the time or so is the actual websocket event processing on the main thread.  A bit of this is the native event processing that the mac event loop does on every plevent, but about 25% is calling out into JS.  This breaks down as:\n\n  13% SetInnerHTML calls (2/3 is removing the old content and its frames, actually;\n      painting off the refresh driver would help here too, since those frames would not\n      exist).\n   7% is setTimeout and clearTimeout; half is xpconnect overhead and the other half is\n      the actual object management and so forth.\n   3% is JS jitcode\n 0.5% getElementsByTagName\n 0.5% setAttribute\n\nSo actionable items:\n\n1) Land bug 598482.\n2) Quickstub setTimeout and clearTimeout (why aren't they already?)\n3) Figure out how to deal with the event loop swampage better.\n\nIdeally, in a e10s world, the socket transport thread would just directly post events to the content process....\n\nWhat I see in Chrome is that the UI is responsive (no surprise) but the renderer process is completely hosed: I can't select text in the webpage, the cells update at 1/10 the rate the update at in Gecko, getting slower and slower until they freeze altogether, and after clicking the link in the page there is no response for 20 seconds or so even when the cells are updating.\n\nOh, and we're definitely getting the events off the network faster than we can process them; I just killed the python server about 40 seconds ago and we're still updating table cells now.  Chrome seems to handle it like this: after killing the python server the content process is still frozen for a minute or two and then there is a single update that repaints.", "bug_id": 694519}, {"is_private": false, "count": 19, "id": 5783733, "author": "bzbarsky@mit.edu", "creator": "bzbarsky@mit.edu", "time": "2011-10-14T21:32:29Z", "creation_time": "2011-10-14T21:32:29Z", "raw_text": "And to make it clear, the only reason the _browser_ UI doesn't freeze in Chrome is because it's in a separate process.", "attachment_id": null, "tags": [], "text": "And to make it clear, the only reason the _browser_ UI doesn't freeze in Chrome is because it's in a separate process.", "bug_id": 694519}, {"creator": "dirkjan@ochtman.nl", "creation_time": "2011-10-14T21:43:16Z", "time": "2011-10-14T21:43:16Z", "author": "dirkjan@ochtman.nl", "is_private": false, "count": 20, "id": 5783761, "bug_id": 694519, "text": "Thanks for taking such a thorough look.\n\nSorry, the instructions to set this up are in comment 2, perhaps I should have had them stand out more. It's weird that you see slow updates in Chrome; on my Windows 7 box, Chrome seemed to be better at keeping up with the message stream. At the very least it was doing much better with resetting the cell backgrounds. Is it possible that there would be an OS interaction there?\n\nSome kind of trick to interrupt the event loop for UI interaction once in a while would probably be useful seems like it would definitely be useful (mostly until e10s comes along, of course, although I suppose it still has some value after that?).", "tags": [], "attachment_id": null, "raw_text": "Thanks for taking such a thorough look.\n\nSorry, the instructions to set this up are in comment 2, perhaps I should have had them stand out more. It's weird that you see slow updates in Chrome; on my Windows 7 box, Chrome seemed to be better at keeping up with the message stream. At the very least it was doing much better with resetting the cell backgrounds. Is it possible that there would be an OS interaction there?\n\nSome kind of trick to interrupt the event loop for UI interaction once in a while would probably be useful seems like it would definitely be useful (mostly until e10s comes along, of course, although I suppose it still has some value after that?)."}, {"count": 21, "id": 5784029, "is_private": false, "time": "2011-10-14T23:40:10Z", "creation_time": "2011-10-14T23:40:10Z", "creator": "jduell.mcbugs@gmail.com", "author": "jduell.mcbugs@gmail.com", "attachment_id": null, "raw_text": "> Ideally, in a e10s world, the socket transport thread would just directly \n> post events to the content process....\n\nHow would this help exactly?  This would reduce overhead of msg processing a little, but it's not going to solve flow control.  And I suspect the UI on the main process won't freeze from the socket transport's events, which get passed along to the IPDL thread w/o much processing generally AFAICT.   The big queue of not-yet processed msgs is probably on the child end.\n\nSo one thing I just noticed in chrome's websockets test suite is that they have a test that makes sure websockets are \"suspended\" while event processing takes place: specifically one test pops up an alert, and they make sure no later ws msgs get delivered to JS until the alert is closed.  We seem to not do the right thing for that, AFAICT.  But that's probably a separate bug, right?\n\nDo we need to add in some notion of flow control for WS msgs?  We already queue messages manually on the child in the IPDL Recv function: we could implement suspend/resume on the parent, and have the child send a msg to suspend when the queue gets too big.", "tags": [], "text": "> Ideally, in a e10s world, the socket transport thread would just directly \n> post events to the content process....\n\nHow would this help exactly?  This would reduce overhead of msg processing a little, but it's not going to solve flow control.  And I suspect the UI on the main process won't freeze from the socket transport's events, which get passed along to the IPDL thread w/o much processing generally AFAICT.   The big queue of not-yet processed msgs is probably on the child end.\n\nSo one thing I just noticed in chrome's websockets test suite is that they have a test that makes sure websockets are \"suspended\" while event processing takes place: specifically one test pops up an alert, and they make sure no later ws msgs get delivered to JS until the alert is closed.  We seem to not do the right thing for that, AFAICT.  But that's probably a separate bug, right?\n\nDo we need to add in some notion of flow control for WS msgs?  We already queue messages manually on the child in the IPDL Recv function: we could implement suspend/resume on the parent, and have the child send a msg to suspend when the queue gets too big.", "bug_id": 694519}, {"is_private": false, "id": 5784032, "count": 22, "author": "jduell.mcbugs@gmail.com", "creator": "jduell.mcbugs@gmail.com", "time": "2011-10-14T23:42:39Z", "creation_time": "2011-10-14T23:42:39Z", "raw_text": "BTW I mention calling IPDL directly from the socket transport thread in bug 648433.  I'm guessing it would be a fair amount of work to get everything right.", "attachment_id": null, "tags": [], "bug_id": 694519, "text": "BTW I mention calling IPDL directly from the socket transport thread in bug 648433.  I'm guessing it would be a fair amount of work to get everything right."}, {"tags": [], "bug_id": 694519, "text": "It's entirely possible that there are OS differences here; event loop stuff is one of the not entirely cross-platform bits at least in gecko.\n\nIn our case, the event loop JS runs from _is_ the event loop for UI interaction (which is in JS itself), so throttling would have to be done on the level of websockets posting events to that event loop, not throttling the event loop itself.\n\n> How would this help exactly? \n\nAgain, in the e10s world, it would keep all the events involved out of the main UI event loop.  So it could still hose the event loop in the content process and on the socket thread, but you could close the tab easily, for example.\n\n> And I suspect the UI on the main process won't freeze from the socket transport's\n> events, which get passed along to the IPDL thread w/o much processing generally\n> AFAICT.\n\nWell, that would be the hope.  But if we avoid the main UI event loop altogether, then it's not even a theoretical possibility.\n\nAgain, in this testcase just the posting of events from the socket thread was 13-30% of total time, depending on how much of the poll/select time gets blamed on that.\n\n> But that's probably a separate bug, right?\n\nYep.\n\n> Do we need to add in some notion of flow control for WS msgs? \n\nMaybe.  It's not clear how it would help unless the message flow spike is transient....  Does the ws protocol have any way to make the server back off?  Is it allowed to drop messages once buffers fill up?\n\n> I'm guessing it would be a fair amount of work to get everything right.\n\nYeah; the direct IPDL message from the socket thread would be ideal, but not necessary in the e10s world.", "attachment_id": null, "raw_text": "It's entirely possible that there are OS differences here; event loop stuff is one of the not entirely cross-platform bits at least in gecko.\n\nIn our case, the event loop JS runs from _is_ the event loop for UI interaction (which is in JS itself), so throttling would have to be done on the level of websockets posting events to that event loop, not throttling the event loop itself.\n\n> How would this help exactly? \n\nAgain, in the e10s world, it would keep all the events involved out of the main UI event loop.  So it could still hose the event loop in the content process and on the socket thread, but you could close the tab easily, for example.\n\n> And I suspect the UI on the main process won't freeze from the socket transport's\n> events, which get passed along to the IPDL thread w/o much processing generally\n> AFAICT.\n\nWell, that would be the hope.  But if we avoid the main UI event loop altogether, then it's not even a theoretical possibility.\n\nAgain, in this testcase just the posting of events from the socket thread was 13-30% of total time, depending on how much of the poll/select time gets blamed on that.\n\n> But that's probably a separate bug, right?\n\nYep.\n\n> Do we need to add in some notion of flow control for WS msgs? \n\nMaybe.  It's not clear how it would help unless the message flow spike is transient....  Does the ws protocol have any way to make the server back off?  Is it allowed to drop messages once buffers fill up?\n\n> I'm guessing it would be a fair amount of work to get everything right.\n\nYeah; the direct IPDL message from the socket thread would be ideal, but not necessary in the e10s world.", "creator": "bzbarsky@mit.edu", "time": "2011-10-15T01:41:58Z", "creation_time": "2011-10-15T01:41:58Z", "author": "bzbarsky@mit.edu", "is_private": false, "id": 5784184, "count": 23}, {"attachment_id": null, "raw_text": "No, there's no flow control in the WS protocol (and you're not allowed to drop messages), so all suspending would do is push the problem back to the server (we'd stop reading TCP traffic), which could in theory detect the issue (but in practice probably wouldn't).  It would at least keep the browser from OOMing or whatever other Bad Things happen as we pile on msgs to the queue.", "tags": [], "text": "No, there's no flow control in the WS protocol (and you're not allowed to drop messages), so all suspending would do is push the problem back to the server (we'd stop reading TCP traffic), which could in theory detect the issue (but in practice probably wouldn't).  It would at least keep the browser from OOMing or whatever other Bad Things happen as we pile on msgs to the queue.", "bug_id": 694519, "count": 24, "id": 5784190, "is_private": false, "creation_time": "2011-10-15T01:46:49Z", "time": "2011-10-15T01:46:49Z", "creator": "jduell.mcbugs@gmail.com", "author": "jduell.mcbugs@gmail.com"}, {"author": "jduell.mcbugs@gmail.com", "time": "2011-10-15T01:48:14Z", "creation_time": "2011-10-15T01:48:14Z", "creator": "jduell.mcbugs@gmail.com", "id": 5784192, "count": 25, "is_private": false, "tags": [], "text": "re: off-main-thread delivery.  Given that e10s is coming soon, I'm inclined to not try to implement that, as it's a lot of work, would complicate the existing code, and then not get used much or at all once e10s is used for desktop.", "bug_id": 694519, "raw_text": "re: off-main-thread delivery.  Given that e10s is coming soon, I'm inclined to not try to implement that, as it's a lot of work, would complicate the existing code, and then not get used much or at all once e10s is used for desktop.", "attachment_id": null}, {"tags": [], "bug_id": 694519, "text": "(In reply to Jason Duell (:jduell) from comment #25)\n> re: off-main-thread delivery.  Given that e10s is coming soon, I'm inclined\n> to not try to implement that, as it's a lot of work, would complicate the\n> existing code, and then not get used much or at all once e10s is used for\n> desktop.\n\nJason, can you reprioritize this now that e10s has been postponed?", "attachment_id": null, "raw_text": "(In reply to Jason Duell (:jduell) from comment #25)\n> re: off-main-thread delivery.  Given that e10s is coming soon, I'm inclined\n> to not try to implement that, as it's a lot of work, would complicate the\n> existing code, and then not get used much or at all once e10s is used for\n> desktop.\n\nJason, can you reprioritize this now that e10s has been postponed?", "time": "2011-11-28T17:49:57Z", "creation_time": "2011-11-28T17:49:57Z", "creator": "taras.mozilla@glek.net", "author": "taras.mozilla@glek.net", "count": 26, "id": 5875989, "is_private": false}, {"attachment_id": null, "raw_text": ">>  re: off-main-thread delivery\n>\n> Jason, can you reprioritize this now that e10s has been postponed?\n\nI'm not sure why we'd be reprioritizing it from the discussion here so far.\n\nThere are two kinds of off-main-thread necko delivery that have been proposed:\n\n1) under e10s, deliver necko msgs to the child process directly from the socket thread.  Requires IPDL to be multithreaded (so mostly IPC work, not necko). That's the kind we've mentioned in this bug, but it's moot for non-e10s.  So priority is low (except insofar at it might affect mobile HTTP perf, not this bug).\n\n2) Deliver OnDataAvailable and/or WS data msgs directly to a client that is not on the main thread.  The use case has always been the HTML 5 parser.  This doesn't make sense for WebSockets which are on the main thread, but could possibly be an optimization for websockets used by web workers.  It wouldn't help the application here.", "text": ">>  re: off-main-thread delivery\n>\n> Jason, can you reprioritize this now that e10s has been postponed?\n\nI'm not sure why we'd be reprioritizing it from the discussion here so far.\n\nThere are two kinds of off-main-thread necko delivery that have been proposed:\n\n1) under e10s, deliver necko msgs to the child process directly from the socket thread.  Requires IPDL to be multithreaded (so mostly IPC work, not necko). That's the kind we've mentioned in this bug, but it's moot for non-e10s.  So priority is low (except insofar at it might affect mobile HTTP perf, not this bug).\n\n2) Deliver OnDataAvailable and/or WS data msgs directly to a client that is not on the main thread.  The use case has always been the HTML 5 parser.  This doesn't make sense for WebSockets which are on the main thread, but could possibly be an optimization for websockets used by web workers.  It wouldn't help the application here.", "bug_id": 694519, "tags": [], "is_private": false, "id": 5884782, "count": 27, "creator": "jduell.mcbugs@gmail.com", "time": "2011-12-01T11:26:35Z", "creation_time": "2011-12-01T11:26:35Z", "author": "jduell.mcbugs@gmail.com"}, {"tags": [], "bug_id": 694519, "text": "(In reply to Jason Duell (:jduell) from comment #27)\n> >>  re: off-main-thread delivery\n> >\n> > Jason, can you reprioritize this now that e10s has been postponed?\n> \n> I'm not sure why we'd be reprioritizing it from the discussion here so far.\n> \n> There are two kinds of off-main-thread necko delivery that have been\n> proposed:\n> \n> 1) under e10s, deliver necko msgs to the child process directly from the\n> socket thread.  Requires IPDL to be multithreaded (so mostly IPC work, not\n> necko). That's the kind we've mentioned in this bug, but it's moot for\n> non-e10s.  So priority is low (except insofar at it might affect mobile HTTP\n> perf, not this bug).\n> \n> 2) Deliver OnDataAvailable and/or WS data msgs directly to a client that is\n> not on the main thread.  The use case has always been the HTML 5 parser. \n> This doesn't make sense for WebSockets which are on the main thread, but\n> could possibly be an optimization for websockets used by web workers.  It\n> wouldn't help the application here.\n\nWhat I was asking is whether we can fix this given that e10s isn't happening. Comment 24 sounds like it would alleviate the problem well.", "raw_text": "(In reply to Jason Duell (:jduell) from comment #27)\n> >>  re: off-main-thread delivery\n> >\n> > Jason, can you reprioritize this now that e10s has been postponed?\n> \n> I'm not sure why we'd be reprioritizing it from the discussion here so far.\n> \n> There are two kinds of off-main-thread necko delivery that have been\n> proposed:\n> \n> 1) under e10s, deliver necko msgs to the child process directly from the\n> socket thread.  Requires IPDL to be multithreaded (so mostly IPC work, not\n> necko). That's the kind we've mentioned in this bug, but it's moot for\n> non-e10s.  So priority is low (except insofar at it might affect mobile HTTP\n> perf, not this bug).\n> \n> 2) Deliver OnDataAvailable and/or WS data msgs directly to a client that is\n> not on the main thread.  The use case has always been the HTML 5 parser. \n> This doesn't make sense for WebSockets which are on the main thread, but\n> could possibly be an optimization for websockets used by web workers.  It\n> wouldn't help the application here.\n\nWhat I was asking is whether we can fix this given that e10s isn't happening. Comment 24 sounds like it would alleviate the problem well.", "attachment_id": null, "author": "taras.mozilla@glek.net", "time": "2011-12-01T22:18:48Z", "creation_time": "2011-12-01T22:18:48Z", "creator": "taras.mozilla@glek.net", "id": 5886573, "count": 28, "is_private": false}, {"author": "bug-husbandry-bot@mozilla.bugs", "bug_id": 694519, "text": "https://bugzilla.mozilla.org/show_bug.cgi?id=1472046\n\nMove all DOM bugs that haven\u2019t been updated in more than 3 years and has no one currently assigned to P5.\n\nIf you have questions, please contact :mdaly.", "tags": [], "creator": "bug-husbandry-bot@mozilla.bugs", "creation_time": "2018-06-29T04:49:03Z", "time": "2018-06-29T04:49:03Z", "raw_text": "https://bugzilla.mozilla.org/show_bug.cgi?id=1472046\n\nMove all DOM bugs that haven\u2019t been updated in more than 3 years and has no one currently assigned to P5.\n\nIf you have questions, please contact :mdaly.", "attachment_id": null, "is_private": false, "count": 29, "id": 13436051}]}}, "comments": {}}