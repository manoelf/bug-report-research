{"comments": {}, "bugs": {"664291": {"comments": [{"tags": [], "bug_id": 664291, "text": "Right now we don't have a good way of notifying code when we're running low on memory.  We try to sound warning bells when an allocation fails, but by then it's probably way too late.\n\nA better approach would be to notice when the browser is being paged out by the OS.  If we catch it early enough, we may be able to reduce our footprint by running a GC/CC or by dropping caches, etc.  This was suggested in bug 661304 comment 32 and at [1].\n\nA paper [2, from 1] suggests using the simple heuristic of \"since the last time I checked, have we had 10 or more hard page faults, or has our resident size decreased?\"  (In the paper's context, the RSS never decreases except due to paging.)\n\nI presume we can tune the heuristic without much difficulty, although we'll need to figure out how to determine whether an RSS decrease is due to paging.  The harder problem, I think, will be determining the hard page fault count on Windows [3].  (Unix has getrusage, which makes it easy.)  It looks like we may be able to use ETW on Windows, although it's not clear whether that carries a performance penalty.  Chrome does something with ETW and page faults [4], although I don't know if they use it in production or only for debugging.\n\n[1] https://groups.google.com/forum/#!topic/mozilla.dev.platform/DMqQ_HKEMp4\n[2] http://www.cs.rochester.edu/~xiaoming/publications/ismm11-b.pdf\n[3] http://glandium.org/blog/?p=1963\n[4] http://code.google.com/p/sawbuck/source/browse/trunk/sawbuck/py/etw/etw/descriptors/pagefault.py", "attachment_id": null, "raw_text": "Right now we don't have a good way of notifying code when we're running low on memory.  We try to sound warning bells when an allocation fails, but by then it's probably way too late.\n\nA better approach would be to notice when the browser is being paged out by the OS.  If we catch it early enough, we may be able to reduce our footprint by running a GC/CC or by dropping caches, etc.  This was suggested in bug 661304 comment 32 and at [1].\n\nA paper [2, from 1] suggests using the simple heuristic of \"since the last time I checked, have we had 10 or more hard page faults, or has our resident size decreased?\"  (In the paper's context, the RSS never decreases except due to paging.)\n\nI presume we can tune the heuristic without much difficulty, although we'll need to figure out how to determine whether an RSS decrease is due to paging.  The harder problem, I think, will be determining the hard page fault count on Windows [3].  (Unix has getrusage, which makes it easy.)  It looks like we may be able to use ETW on Windows, although it's not clear whether that carries a performance penalty.  Chrome does something with ETW and page faults [4], although I don't know if they use it in production or only for debugging.\n\n[1] https://groups.google.com/forum/#!topic/mozilla.dev.platform/DMqQ_HKEMp4\n[2] http://www.cs.rochester.edu/~xiaoming/publications/ismm11-b.pdf\n[3] http://glandium.org/blog/?p=1963\n[4] http://code.google.com/p/sawbuck/source/browse/trunk/sawbuck/py/etw/etw/descriptors/pagefault.py", "creator": "justin.lebar+bug@gmail.com", "creation_time": "2011-06-14T21:27:32Z", "time": "2011-06-14T21:27:32Z", "author": "justin.lebar+bug@gmail.com", "is_private": false, "id": 5532434, "count": 0}, {"raw_text": "(In reply to comment #0)\n> \n> A paper [2, from 1] suggests using the simple heuristic of \"since the last\n> time I checked, have we had 10 or more hard page faults, or has our resident\n> size decreased?\"  (In the paper's context, the RSS never decreases except\n> due to paging.)\n\nThe other part of this heuristic is how often it's run.  You start off doing it every N events (where \"events\" needs to be chosen, it could even be time-based).  Every time you don't have high memory pressure, you increase N by 1.  Every time you do have high memory pressure, you decrease N by a factor of 10.  That gives fast response when memory becomes tight, but slowly decreasing overhead when memory is plentiful.\n\nIf this is done well it might be enough to mitigate any overhead of using ETW on Windows?", "attachment_id": null, "tags": [], "text": "(In reply to comment #0)\n> \n> A paper [2, from 1] suggests using the simple heuristic of \"since the last\n> time I checked, have we had 10 or more hard page faults, or has our resident\n> size decreased?\"  (In the paper's context, the RSS never decreases except\n> due to paging.)\n\nThe other part of this heuristic is how often it's run.  You start off doing it every N events (where \"events\" needs to be chosen, it could even be time-based).  Every time you don't have high memory pressure, you increase N by 1.  Every time you do have high memory pressure, you decrease N by a factor of 10.  That gives fast response when memory becomes tight, but slowly decreasing overhead when memory is plentiful.\n\nIf this is done well it might be enough to mitigate any overhead of using ETW on Windows?", "bug_id": 664291, "is_private": false, "id": 5532856, "count": 1, "author": "n.nethercote@gmail.com", "creator": "n.nethercote@gmail.com", "creation_time": "2011-06-14T23:58:48Z", "time": "2011-06-14T23:58:48Z"}, {"tags": [], "text": "I blogged about running Firefox with a reduced max-RSS so as to force it to page [1].  But since this is more persistent than my blog, here's the short version.  On Ubuntu 11.04:\n\n* Install the cgroup-bin package.\n\n* Edit /etc/cgconfig.config and create a group with limited memory.  For\n  instance, I added:\n\n      group limited {\n        memory {\n          memory.limit_in_bytes = 50M;\n        }\n      }\n\n* Run\n\n    # restart cgconfig\n    # chown jlebar /sys/fs/cgroup/memory/limited\n    # chown jlebar /sys/fs/cgroup/memory/limited/*\n    $ cgexec -g memory:limited dist/bin/firefox\n\nAnd have at it.  I observed FF holding to a 93M RSS when I asked it to have a\n50M limit, but that's no problem for me.  It did page, spectacularly.\n\ncgclassify theoretically lets you attach restrictions to a running process, but\nit didn't appear to do anything when used in conjunction with the RSS limit.\n\n[1] http://jlebar.com/2011/6/15/Limiting_the_amount_of_RAM_a_program_can_use.html", "bug_id": 664291, "attachment_id": null, "raw_text": "I blogged about running Firefox with a reduced max-RSS so as to force it to page [1].  But since this is more persistent than my blog, here's the short version.  On Ubuntu 11.04:\n\n* Install the cgroup-bin package.\n\n* Edit /etc/cgconfig.config and create a group with limited memory.  For\n  instance, I added:\n\n      group limited {\n        memory {\n          memory.limit_in_bytes = 50M;\n        }\n      }\n\n* Run\n\n    # restart cgconfig\n    # chown jlebar /sys/fs/cgroup/memory/limited\n    # chown jlebar /sys/fs/cgroup/memory/limited/*\n    $ cgexec -g memory:limited dist/bin/firefox\n\nAnd have at it.  I observed FF holding to a 93M RSS when I asked it to have a\n50M limit, but that's no problem for me.  It did page, spectacularly.\n\ncgclassify theoretically lets you attach restrictions to a running process, but\nit didn't appear to do anything when used in conjunction with the RSS limit.\n\n[1] http://jlebar.com/2011/6/15/Limiting_the_amount_of_RAM_a_program_can_use.html", "creator": "justin.lebar+bug@gmail.com", "time": "2011-06-15T23:06:22Z", "creation_time": "2011-06-15T23:06:22Z", "author": "justin.lebar+bug@gmail.com", "is_private": false, "count": 2, "id": 5535481}, {"is_private": false, "count": 3, "id": 5543528, "author": "justin.lebar+bug@gmail.com", "creator": "justin.lebar+bug@gmail.com", "creation_time": "2011-06-20T20:28:56Z", "time": "2011-06-20T20:28:56Z", "raw_text": "On Windows, it appears we can get a systemwide hard page fault rate with performance counters [1].  That might be good enough for this bug -- If the hard page fault rate is high, either because FF is faulting pages in or some other program is, dump our caches.\n\nAnyone have thoughts on this?\n\n[1] http://msdn.microsoft.com/en-us/library/aa373083%28v=vs.85%29.aspx", "attachment_id": null, "tags": [], "bug_id": 664291, "text": "On Windows, it appears we can get a systemwide hard page fault rate with performance counters [1].  That might be good enough for this bug -- If the hard page fault rate is high, either because FF is faulting pages in or some other program is, dump our caches.\n\nAnyone have thoughts on this?\n\n[1] http://msdn.microsoft.com/en-us/library/aa373083%28v=vs.85%29.aspx"}, {"bug_id": 664291, "text": "Created attachment 540647\nWIP v1, Linux/Mac only.", "tags": [], "raw_text": "", "attachment_id": 540647, "author": "justin.lebar+bug@gmail.com", "creation_time": "2011-06-21T01:27:00Z", "time": "2011-06-21T01:27:00Z", "creator": "justin.lebar+bug@gmail.com", "count": 4, "id": 5544388, "is_private": false}, {"author": "n.nethercote@gmail.com", "creation_time": "2011-06-21T01:52:27Z", "time": "2011-06-21T01:52:27Z", "creator": "n.nethercote@gmail.com", "count": 5, "id": 5544421, "is_private": false, "text": "Comment on attachment 540647\nWIP v1, Linux/Mac only.\n\nReview of attachment 540647:\n-----------------------------------------------------------------\n\nA couple of drive-by comments from a quick skim...\n\n::: xpcom/base/LowMemoryDetector.cpp\n@@ +48,5 @@\n> +static PRLogModuleInfo* gLogModule = PR_LOG_DEFINE(\"LowMemoryDetector\");\n> +#define DEBUG(format) PR_LOG(gLogModule, PR_LOG_DEBUG, format)\n> +#define INFO(format) PR_LOG(gLogModule, PR_LOG_WARNING, format)\n> +\n> +class LowMemoryNotificationReporter : public nsIMemoryReporter\n\nI think you can use the NS_MEMORY_REPORTER_IMPLEMENT macro to avoid some boilerplate code here.  See js/src/xpconnect/src/xpcjsruntime.cpp for some examples of its use.\n\n@@ +70,5 @@\n> +\n> +  nsresult GetKind(PRInt32 *aKind)\n> +  {\n> +    NS_ENSURE_ARG_POINTER(aKind);\n> +    *aKind = MR_COUNT;\n\nDoes this patch compile?  MR_COUNT doesn't exist.  aboutMemory.js will also need modification in order to print the appropriate units -- it currently assumes all measurements are in bytes and prints \"B\" or \"MB\" as the unit.", "bug_id": 664291, "tags": [], "raw_text": "Review of attachment 540647:\n-----------------------------------------------------------------\n\nA couple of drive-by comments from a quick skim...\n\n::: xpcom/base/LowMemoryDetector.cpp\n@@ +48,5 @@\n> +static PRLogModuleInfo* gLogModule = PR_LOG_DEFINE(\"LowMemoryDetector\");\n> +#define DEBUG(format) PR_LOG(gLogModule, PR_LOG_DEBUG, format)\n> +#define INFO(format) PR_LOG(gLogModule, PR_LOG_WARNING, format)\n> +\n> +class LowMemoryNotificationReporter : public nsIMemoryReporter\n\nI think you can use the NS_MEMORY_REPORTER_IMPLEMENT macro to avoid some boilerplate code here.  See js/src/xpconnect/src/xpcjsruntime.cpp for some examples of its use.\n\n@@ +70,5 @@\n> +\n> +  nsresult GetKind(PRInt32 *aKind)\n> +  {\n> +    NS_ENSURE_ARG_POINTER(aKind);\n> +    *aKind = MR_COUNT;\n\nDoes this patch compile?  MR_COUNT doesn't exist.  aboutMemory.js will also need modification in order to print the appropriate units -- it currently assumes all measurements are in bytes and prints \"B\" or \"MB\" as the unit.", "attachment_id": 540647}, {"raw_text": "This patch depends on the patch in bug 664486, which adds page faults to about:memory for Linux/Mac and implements MR_COUNT (with the appropriate changes to aboutMemory.js).", "attachment_id": null, "text": "This patch depends on the patch in bug 664486, which adds page faults to about:memory for Linux/Mac and implements MR_COUNT (with the appropriate changes to aboutMemory.js).", "bug_id": 664291, "tags": [], "is_private": false, "id": 5544422, "count": 6, "author": "justin.lebar+bug@gmail.com", "creator": "justin.lebar+bug@gmail.com", "time": "2011-06-21T01:55:16Z", "creation_time": "2011-06-21T01:55:16Z"}, {"raw_text": "(In reply to comment #1)\n> The other part of this heuristic is how often it's run.  You start off doing\n> it every N events (where \"events\" needs to be chosen, it could even be\n> time-based).  Every time you don't have high memory pressure, you increase N\n> by 1.  Every time you do have high memory pressure, you decrease N by a\n> factor of 10.  That gives fast response when memory becomes tight, but\n> slowly decreasing overhead when memory is plentiful\n\nI don't think this heuristic makes much sense in our context.  We lose unless we react quickly to low memory.  If we don't check for low memory often while we think everything is fine, then it's likely that by the time we notice that memory is low, the OS has already paged us out (that's what we were trying to avoid in the first place!).\n\nSimilarly, it doesn't make much sense to check for low memory more often right after we notice that memory is low.  That might make sense if we were able to dramatically decrease our footprint in response to memory pressure -- if we didn't release enough stuff on the first low memory event, maybe the second one will do it.  But in our case, there's relatively little I expect us to be able to release, so I don't expect that firing the notification many times in succession will do much good.\n\nIf we want any kind of backoff, I think we might want to back off when we hit a low memory notification (i.e. the opposite of what the paper suggests).  If we keep observing low memory, then clearly our notification isn't doing much good.  If a low-memory notification triggers, say, a GC, we wouldn't want to do that over and over while we're paging.", "attachment_id": null, "is_private": false, "id": 5546690, "count": 7, "author": "justin.lebar+bug@gmail.com", "tags": [], "bug_id": 664291, "text": "(In reply to comment #1)\n> The other part of this heuristic is how often it's run.  You start off doing\n> it every N events (where \"events\" needs to be chosen, it could even be\n> time-based).  Every time you don't have high memory pressure, you increase N\n> by 1.  Every time you do have high memory pressure, you decrease N by a\n> factor of 10.  That gives fast response when memory becomes tight, but\n> slowly decreasing overhead when memory is plentiful\n\nI don't think this heuristic makes much sense in our context.  We lose unless we react quickly to low memory.  If we don't check for low memory often while we think everything is fine, then it's likely that by the time we notice that memory is low, the OS has already paged us out (that's what we were trying to avoid in the first place!).\n\nSimilarly, it doesn't make much sense to check for low memory more often right after we notice that memory is low.  That might make sense if we were able to dramatically decrease our footprint in response to memory pressure -- if we didn't release enough stuff on the first low memory event, maybe the second one will do it.  But in our case, there's relatively little I expect us to be able to release, so I don't expect that firing the notification many times in succession will do much good.\n\nIf we want any kind of backoff, I think we might want to back off when we hit a low memory notification (i.e. the opposite of what the paper suggests).  If we keep observing low memory, then clearly our notification isn't doing much good.  If a low-memory notification triggers, say, a GC, we wouldn't want to do that over and over while we're paging.", "creator": "justin.lebar+bug@gmail.com", "creation_time": "2011-06-21T21:54:54Z", "time": "2011-06-21T21:54:54Z"}, {"attachment_id": null, "raw_text": "> We lose unless we react quickly to low memory.\n\nOn the other hand, I'm also kind of worried about checking all the time when it's not necessary.\n\nOn Windows, I can detect when the system as a whole starts paging.  When the system starts paging, we want to drop caches even if we haven't been doing anything lately, both to be a good citizen and to keep more important parts of FF from being paged out.  But to detect that, we have to check even while we're idle.\n\nIt remains to be seen how much CPU checking once a second will use.", "tags": [], "bug_id": 664291, "text": "> We lose unless we react quickly to low memory.\n\nOn the other hand, I'm also kind of worried about checking all the time when it's not necessary.\n\nOn Windows, I can detect when the system as a whole starts paging.  When the system starts paging, we want to drop caches even if we haven't been doing anything lately, both to be a good citizen and to keep more important parts of FF from being paged out.  But to detect that, we have to check even while we're idle.\n\nIt remains to be seen how much CPU checking once a second will use.", "is_private": false, "count": 8, "id": 5546765, "creator": "justin.lebar+bug@gmail.com", "creation_time": "2011-06-21T22:10:31Z", "time": "2011-06-21T22:10:31Z", "author": "justin.lebar+bug@gmail.com"}, {"attachment_id": null, "raw_text": "bz or anyone else: Do you have an opinion on whether this should run in a separate thread or in the main event loop?  Right now it's only checking once a second.", "tags": [], "bug_id": 664291, "text": "bz or anyone else: Do you have an opinion on whether this should run in a separate thread or in the main event loop?  Right now it's only checking once a second.", "id": 5549090, "count": 9, "is_private": false, "time": "2011-06-22T19:58:48Z", "creation_time": "2011-06-22T19:58:48Z", "creator": "justin.lebar+bug@gmail.com", "author": "justin.lebar+bug@gmail.com"}, {"creator": "justin.lebar+bug@gmail.com", "creation_time": "2011-06-22T20:03:03Z", "time": "2011-06-22T20:03:03Z", "author": "justin.lebar+bug@gmail.com", "is_private": false, "count": 10, "id": 5549105, "tags": [], "text": "Doug, it looks like you did something like this for Android and then backed it out.  Do you have any comments about the approach here?  Do you think we should turn it off for Android, since AIUI Android doesn't have swap?", "bug_id": 664291, "attachment_id": null, "raw_text": "Doug, it looks like you did something like this for Android and then backed it out.  Do you have any comments about the approach here?  Do you think we should turn it off for Android, since AIUI Android doesn't have swap?"}, {"author": "bzbarsky@mit.edu", "creator": "bzbarsky@mit.edu", "creation_time": "2011-06-22T20:06:07Z", "time": "2011-06-22T20:06:07Z", "is_private": false, "id": 5549117, "count": 11, "text": "From what I understand, once-per-second wakeups would be a serious problem for mobile.  Can we do whatever the JS folks did for periodic GC that doesn't run if nothing has happened here?\n\nWhat's the practical difference between separate thread and main event loop?  Aren't you proxying to the main thread anyway?", "bug_id": 664291, "tags": [], "raw_text": "From what I understand, once-per-second wakeups would be a serious problem for mobile.  Can we do whatever the JS folks did for periodic GC that doesn't run if nothing has happened here?\n\nWhat's the practical difference between separate thread and main event loop?  Aren't you proxying to the main thread anyway?", "attachment_id": null}, {"count": 12, "id": 5549149, "is_private": false, "author": "justin.lebar+bug@gmail.com", "creation_time": "2011-06-22T20:17:11Z", "time": "2011-06-22T20:17:11Z", "creator": "justin.lebar+bug@gmail.com", "raw_text": "(In reply to comment #11)\n> From what I understand, once-per-second wakeups would be a serious problem\n> for mobile.  Can we do whatever the JS folks did for periodic GC that\n> doesn't run if nothing has happened here?\n\nSure, although it's not clear whether it should even be on for mobile in its current form.  Right now, on *nix, it warns about low memory when it sees that we're paging in, but AIUI there's no paging on Android at all.\n\nWe might want to do the same thing as the periodic GC to avoid wakeups on desktop, too.  I'll look into it.\n\nMaybe we can watch something else on Android.  There's [1], but that seems to have been ill-fated (it was backed out [2]).\n\n> What's the practical difference between separate thread and main event loop?\n> Aren't you proxying to the main thread anyway?\n\nIt only proxies to the main thread if it needs to fire a low-memory event.  It's not clear how fast the syscall to get the memory info runs on Windows...\n\n[1] http://hg.mozilla.org/mozilla-central/rev/37e4ab3abc44\n[2] http://hg.mozilla.org/mozilla-central/rev/99af9d6485bb", "attachment_id": null, "tags": [], "bug_id": 664291, "text": "(In reply to comment #11)\n> From what I understand, once-per-second wakeups would be a serious problem\n> for mobile.  Can we do whatever the JS folks did for periodic GC that\n> doesn't run if nothing has happened here?\n\nSure, although it's not clear whether it should even be on for mobile in its current form.  Right now, on *nix, it warns about low memory when it sees that we're paging in, but AIUI there's no paging on Android at all.\n\nWe might want to do the same thing as the periodic GC to avoid wakeups on desktop, too.  I'll look into it.\n\nMaybe we can watch something else on Android.  There's [1], but that seems to have been ill-fated (it was backed out [2]).\n\n> What's the practical difference between separate thread and main event loop?\n> Aren't you proxying to the main thread anyway?\n\nIt only proxies to the main thread if it needs to fire a low-memory event.  It's not clear how fast the syscall to get the memory info runs on Windows...\n\n[1] http://hg.mozilla.org/mozilla-central/rev/37e4ab3abc44\n[2] http://hg.mozilla.org/mozilla-central/rev/99af9d6485bb"}, {"tags": [], "text": "If you _can_ stay off the main thread, that seems clearly superior to me.", "bug_id": 664291, "attachment_id": null, "raw_text": "If you _can_ stay off the main thread, that seems clearly superior to me.", "creator": "bzbarsky@mit.edu", "creation_time": "2011-06-22T20:22:18Z", "time": "2011-06-22T20:22:18Z", "author": "bzbarsky@mit.edu", "is_private": false, "id": 5549165, "count": 13}, {"text": "justin - right, no swapping on most devices.  the n900/maemo had an option to enable swap to sdcard, but that is generally the exception.\n\nregarding the android patches to detect low memory -- there was a system release for the Nexus S which, when low memory was hit, the kernel would panic.  This was fixed with a point release.  in order to work around this, we attempted to watch for low memory (MemFree, etc).  however, we found this to be not a good indicator of actually memory available.  on linux, free memory typically gets used for fs caches and, when needed, are given back to user space processes.\n \nAndroid does send a 'system is low on memory' notification, but typically we this event very late.  Most other processes at the point of this notification have already been killed.  However, this might be a good enough signal for what you are trying to do.", "bug_id": 664291, "tags": [], "attachment_id": null, "raw_text": "justin - right, no swapping on most devices.  the n900/maemo had an option to enable swap to sdcard, but that is generally the exception.\n\nregarding the android patches to detect low memory -- there was a system release for the Nexus S which, when low memory was hit, the kernel would panic.  This was fixed with a point release.  in order to work around this, we attempted to watch for low memory (MemFree, etc).  however, we found this to be not a good indicator of actually memory available.  on linux, free memory typically gets used for fs caches and, when needed, are given back to user space processes.\n \nAndroid does send a 'system is low on memory' notification, but typically we this event very late.  Most other processes at the point of this notification have already been killed.  However, this might be a good enough signal for what you are trying to do.", "creation_time": "2011-06-22T20:25:46Z", "time": "2011-06-22T20:25:46Z", "creator": "doug.turner@gmail.com", "author": "doug.turner@gmail.com", "count": 14, "id": 5549176, "is_private": false}, {"id": 5549289, "count": 15, "is_private": false, "author": "continuation@gmail.com", "time": "2011-06-22T21:03:04Z", "creation_time": "2011-06-22T21:03:04Z", "creator": "continuation@gmail.com", "raw_text": "I think the JS GC trigger waits until allocations, which won't work as well for general memory watching, as there are all sorts of allocations all over the place, and I don't know if you'd be able to instrument them all.", "attachment_id": null, "tags": [], "text": "I think the JS GC trigger waits until allocations, which won't work as well for general memory watching, as there are all sorts of allocations all over the place, and I don't know if you'd be able to instrument them all.", "bug_id": 664291}, {"text": "Created attachment 541401\nWIP v2\n\nThis is almost ready for review.  The main thing that's left to do is tune how often we check for memory pressure (currently every second when there's no memory pressure, backing off to once every 20s when there is pressure) and what page fault / page out rate we declare is indicative of pressure (right now it's 10 faults or page outs in one second).\n\nI'm tempted to change the 10 to 1000 or something, so we can have some confidence that we're not firing these notifications when there's plenty of available memory.  But that might not let us react quickly enough to memory pressure.  Suggestions on this point are welcome!\n\nI also need to check that writing to an mmap'ed file on Windows doesn't cause the page out counter to increase.", "bug_id": 664291, "tags": [], "raw_text": "This is almost ready for review.  The main thing that's left to do is tune how often we check for memory pressure (currently every second when there's no memory pressure, backing off to once every 20s when there is pressure) and what page fault / page out rate we declare is indicative of pressure (right now it's 10 faults or page outs in one second).\n\nI'm tempted to change the 10 to 1000 or something, so we can have some confidence that we're not firing these notifications when there's plenty of available memory.  But that might not let us react quickly enough to memory pressure.  Suggestions on this point are welcome!\n\nI also need to check that writing to an mmap'ed file on Windows doesn't cause the page out counter to increase.", "attachment_id": 541401, "author": "justin.lebar+bug@gmail.com", "time": "2011-06-23T16:21:46Z", "creation_time": "2011-06-23T16:21:46Z", "creator": "justin.lebar+bug@gmail.com", "count": 16, "id": 5551260, "is_private": false}, {"id": 5551785, "count": 17, "is_private": false, "author": "justin.lebar+bug@gmail.com", "time": "2011-06-23T18:48:40Z", "creation_time": "2011-06-23T18:48:40Z", "creator": "justin.lebar+bug@gmail.com", "raw_text": "> I also need to check that writing to an mmap'ed file on Windows doesn't cause \n> the page out counter to increase.\n\nVerified this with a Python script which writes 1M to an mmap'ed file on Windows 7 VM.  I'll test on Windows XP once I finish downloading the ISO (nobody uses Vista, right?).\n\nThe pages output / sec counter stays firmly pinned at 0 as I use my VM to load programs and browse around, but fires away once I start approaching the machine's memory limit.  That's great to see.", "attachment_id": null, "tags": [], "text": "> I also need to check that writing to an mmap'ed file on Windows doesn't cause \n> the page out counter to increase.\n\nVerified this with a Python script which writes 1M to an mmap'ed file on Windows 7 VM.  I'll test on Windows XP once I finish downloading the ISO (nobody uses Vista, right?).\n\nThe pages output / sec counter stays firmly pinned at 0 as I use my VM to load programs and browse around, but fires away once I start approaching the machine's memory limit.  That's great to see.", "bug_id": 664291}, {"id": 5551839, "count": 18, "is_private": false, "creation_time": "2011-06-23T19:09:10Z", "time": "2011-06-23T19:09:10Z", "creator": "justin.lebar+bug@gmail.com", "author": "justin.lebar+bug@gmail.com", "attachment_id": null, "raw_text": "I'm seeing periodic spikes up to 32 pages output / sec on Win XP, so we should set the threshold above that.\n\nIf you have Windows and want to see what your pages output / sec looks like, run the performance monitor.  It's in the start menu on Win 7 (I think with that name), and on WinXP, you can start it through start, run, perfmon.msc.  Then add the \"pages output / sec\" counter under \"memory\".", "bug_id": 664291, "text": "I'm seeing periodic spikes up to 32 pages output / sec on Win XP, so we should set the threshold above that.\n\nIf you have Windows and want to see what your pages output / sec looks like, run the performance monitor.  It's in the start menu on Win 7 (I think with that name), and on WinXP, you can start it through start, run, perfmon.msc.  Then add the \"pages output / sec\" counter under \"memory\".", "tags": []}, {"attachment_id": null, "raw_text": "With some hammering on my WinXP VM, I can get the pages output / sec number to creep up to 100 or so before there's actually memory pressure.  So maybe this is the wrong metric to use.\n\nWindows does provide an \"Available MBytes\" metric which looks pretty good.  When it hits zero, we start paging like crazy.  Maybe we should just watch that.  I need to test it on Win7 now...\n\nI think we should also be watching our virtual address space, on all platforms.  If we're almost out of address space, we should run out of the room crying for our mother.  Or at least fire a low-memory notification.", "tags": [], "bug_id": 664291, "text": "With some hammering on my WinXP VM, I can get the pages output / sec number to creep up to 100 or so before there's actually memory pressure.  So maybe this is the wrong metric to use.\n\nWindows does provide an \"Available MBytes\" metric which looks pretty good.  When it hits zero, we start paging like crazy.  Maybe we should just watch that.  I need to test it on Win7 now...\n\nI think we should also be watching our virtual address space, on all platforms.  If we're almost out of address space, we should run out of the room crying for our mother.  Or at least fire a low-memory notification.", "is_private": false, "count": 19, "id": 5552019, "creator": "justin.lebar+bug@gmail.com", "creation_time": "2011-06-23T20:10:15Z", "time": "2011-06-23T20:10:15Z", "author": "justin.lebar+bug@gmail.com"}, {"bug_id": 664291, "text": "Would it be going too far to keep a running mean and variance for the number of page counts per second? Then you could impose a dynamic limit like 'more than 5 standard deviations outside the normal range for two measurements in a row' (5 standard deviations being a 1 in ~2 million occurrence for a normal distribution).\n\nA running mean and variance are cheap to compute ('mean = sum / n' and 'variance = mean_of_squares - square_of_mean') as long as you can do it in integers, but it does require keeping some memory around to evict the oldest entry for every new measurement.", "tags": [], "raw_text": "Would it be going too far to keep a running mean and variance for the number of page counts per second? Then you could impose a dynamic limit like 'more than 5 standard deviations outside the normal range for two measurements in a row' (5 standard deviations being a 1 in ~2 million occurrence for a normal distribution).\n\nA running mean and variance are cheap to compute ('mean = sum / n' and 'variance = mean_of_squares - square_of_mean') as long as you can do it in integers, but it does require keeping some memory around to evict the oldest entry for every new measurement.", "attachment_id": null, "author": "emanuel.hoogeveen@protonmail.com", "time": "2011-06-24T02:28:14Z", "creation_time": "2011-06-24T02:28:14Z", "creator": "emanuel.hoogeveen@protonmail.com", "id": 5553091, "count": 20, "is_private": false}, {"author": "justin.lebar+bug@gmail.com", "creator": "justin.lebar+bug@gmail.com", "time": "2011-06-24T14:16:17Z", "creation_time": "2011-06-24T14:16:17Z", "is_private": false, "count": 21, "id": 5553916, "tags": [], "bug_id": 664291, "text": "> Would it be going too far to keep a running mean and variance for the number of \n> page counts per second?\n\nI don't think that would be infeasible or overkill, but I'm also not sure it's better than the alternatives.\n\nOn Windows, there are large spikes in the page fault count when programs load, so we just don't want to use that metric, at least not by itself.  And on *nix, at least in my testing, we see very few page faults until we run out of memory, so I think the mean/variance measurement would be itself pretty noisy.\n\nWe'll hopefully have page fault counting in about:memory soon so others can have a look on *nix.", "raw_text": "> Would it be going too far to keep a running mean and variance for the number of \n> page counts per second?\n\nI don't think that would be infeasible or overkill, but I'm also not sure it's better than the alternatives.\n\nOn Windows, there are large spikes in the page fault count when programs load, so we just don't want to use that metric, at least not by itself.  And on *nix, at least in my testing, we see very few page faults until we run out of memory, so I think the mean/variance measurement would be itself pretty noisy.\n\nWe'll hopefully have page fault counting in about:memory soon so others can have a look on *nix.", "attachment_id": null}, {"author": "rclickenbrock@gmail.com", "tags": [], "text": "(In reply to comment #18)\n> I'm seeing periodic spikes up to 32 pages output / sec on Win XP, so we\n> should set the threshold above that.\n\nI see something similar to this on Win7 except that it happens in bursts of 256 instead of 32. I'm not positive, but I think what we're seeing is Windows preemptively writing infrequently accessed pages to the pagefile so the memory can be reclaimed quickly.\n\n(In reply to comment #19)\n> With some hammering on my WinXP VM, I can get the pages output / sec number\n> to creep up to 100 or so before there's actually memory pressure.  So maybe\n> this is the wrong metric to use.\n\nWhat sort of numbers do you see when there actually is memory pressure?\n\nOn my Win7 box, pages output / sec usually jumps straight from zero to thousands, although the spikes are occasionally in the 700-900 range. I wonder if using a threshold of something like 500 would be reasonable...", "bug_id": 664291, "creator": "rclickenbrock@gmail.com", "time": "2011-06-25T03:25:14Z", "creation_time": "2011-06-25T03:25:14Z", "raw_text": "(In reply to comment #18)\n> I'm seeing periodic spikes up to 32 pages output / sec on Win XP, so we\n> should set the threshold above that.\n\nI see something similar to this on Win7 except that it happens in bursts of 256 instead of 32. I'm not positive, but I think what we're seeing is Windows preemptively writing infrequently accessed pages to the pagefile so the memory can be reclaimed quickly.\n\n(In reply to comment #19)\n> With some hammering on my WinXP VM, I can get the pages output / sec number\n> to creep up to 100 or so before there's actually memory pressure.  So maybe\n> this is the wrong metric to use.\n\nWhat sort of numbers do you see when there actually is memory pressure?\n\nOn my Win7 box, pages output / sec usually jumps straight from zero to thousands, although the spikes are occasionally in the 700-900 range. I wonder if using a threshold of something like 500 would be reasonable...", "is_private": false, "attachment_id": null, "count": 22, "id": 5555629}, {"bug_id": 664291, "text": "For the running-out-of-virtual-space case, we need to figure out how much of the virtual address space is available to userspace programs.\n\nIf you want to follow along at home, I've attached a Python script at the bottom of this comment which tries to mmap until it can't anymore.\n\nWindows's limit is 2GB, unless you boot with some special switch.  I think I'm just going to ignore this and say that the VM limit is 2G, unless anyone objects.\n\nThe Linux-32 box I tested on apparently has a 3GB limit.  I can't find anything authoritative on this, but I think this is hardcoded.\n\nStill looking for a mac-32 box...\n\n    from itertools import count\n    from mmap import mmap\n     \n    maps = []\n    for i in count(1):\n        maps.append(mmap(-1, 1024 * 1024))\n        print('mapped %dmb' % i)", "tags": [], "attachment_id": null, "raw_text": "For the running-out-of-virtual-space case, we need to figure out how much of the virtual address space is available to userspace programs.\n\nIf you want to follow along at home, I've attached a Python script at the bottom of this comment which tries to mmap until it can't anymore.\n\nWindows's limit is 2GB, unless you boot with some special switch.  I think I'm just going to ignore this and say that the VM limit is 2G, unless anyone objects.\n\nThe Linux-32 box I tested on apparently has a 3GB limit.  I can't find anything authoritative on this, but I think this is hardcoded.\n\nStill looking for a mac-32 box...\n\n    from itertools import count\n    from mmap import mmap\n     \n    maps = []\n    for i in count(1):\n        maps.append(mmap(-1, 1024 * 1024))\n        print('mapped %dmb' % i)", "creator": "justin.lebar+bug@gmail.com", "creation_time": "2011-06-28T19:41:12Z", "time": "2011-06-28T19:41:12Z", "author": "justin.lebar+bug@gmail.com", "is_private": false, "id": 5562501, "count": 23}, {"attachment_id": null, "raw_text": "(In reply to comment #23)\n> \n> The Linux-32 box I tested on apparently has a 3GB limit.  I can't find\n> anything authoritative on this, but I think this is hardcoded.\n\nNope.  IIRC you can have various set-ups.  3GB is the most common, but you can have 1GB, 2GB, even 4GB somehow.  So I'm uncomfortable about using a hard-coded value.  I wonder if you can get the number from /proc.", "text": "(In reply to comment #23)\n> \n> The Linux-32 box I tested on apparently has a 3GB limit.  I can't find\n> anything authoritative on this, but I think this is hardcoded.\n\nNope.  IIRC you can have various set-ups.  3GB is the most common, but you can have 1GB, 2GB, even 4GB somehow.  So I'm uncomfortable about using a hard-coded value.  I wonder if you can get the number from /proc.", "bug_id": 664291, "tags": [], "is_private": false, "id": 5563380, "count": 24, "creator": "n.nethercote@gmail.com", "creation_time": "2011-06-29T00:07:54Z", "time": "2011-06-29T00:07:54Z", "author": "n.nethercote@gmail.com"}, {"author": "justin.lebar+bug@gmail.com", "creation_time": "2011-06-29T01:29:38Z", "time": "2011-06-29T01:29:38Z", "creator": "justin.lebar+bug@gmail.com", "count": 25, "id": 5563535, "is_private": false, "tags": [], "bug_id": 664291, "text": "(In reply to comment #24)\n> Nope.  IIRC you can have various set-ups.  3GB is the most common, but you\n> can have 1GB, 2GB, even 4GB somehow.  So I'm uncomfortable about using a\n> hard-coded value.  I wonder if you can get the number from /proc.\n\nHm.  How much of a hack would it be to launch a separate process which does a search to find out how much data it can map?  We'd only have to run it once on that machine, and it's not like mmap'ing 4gb is expensive, if you're not going to use it.", "raw_text": "(In reply to comment #24)\n> Nope.  IIRC you can have various set-ups.  3GB is the most common, but you\n> can have 1GB, 2GB, even 4GB somehow.  So I'm uncomfortable about using a\n> hard-coded value.  I wonder if you can get the number from /proc.\n\nHm.  How much of a hack would it be to launch a separate process which does a search to find out how much data it can map?  We'd only have to run it once on that machine, and it's not like mmap'ing 4gb is expensive, if you're not going to use it.", "attachment_id": null}, {"is_private": false, "id": 5563543, "count": 26, "author": "jstenback+bmo@gmail.com", "creator": "jstenback+bmo@gmail.com", "time": "2011-06-29T01:36:58Z", "creation_time": "2011-06-29T01:36:58Z", "raw_text": "That *seems* a bit much for me, and I don't know that we can cache that, at least not in a fool proof way. What if the profile is moved from one computer to another, or what about university type installs where the home directory is on nfs and you run firefox from various computers? Not sure how much we care, but it seems caching could cause problems...", "attachment_id": null, "tags": [], "text": "That *seems* a bit much for me, and I don't know that we can cache that, at least not in a fool proof way. What if the profile is moved from one computer to another, or what about university type installs where the home directory is on nfs and you run firefox from various computers? Not sure how much we care, but it seems caching could cause problems...", "bug_id": 664291}, {"author": "n.nethercote@gmail.com", "creation_time": "2011-06-29T01:50:29Z", "time": "2011-06-29T01:50:29Z", "creator": "n.nethercote@gmail.com", "id": 5563558, "count": 27, "is_private": false, "bug_id": 664291, "text": "Yeah, just sounds like it's asking for trouble :(", "tags": [], "raw_text": "Yeah, just sounds like it's asking for trouble :(", "attachment_id": null}, {"count": 28, "id": 5563563, "is_private": false, "author": "justin.lebar+bug@gmail.com", "creation_time": "2011-06-29T01:52:20Z", "time": "2011-06-29T01:52:20Z", "creator": "justin.lebar+bug@gmail.com", "raw_text": "Figuring out how much virtual address space you have to play with should *not* be this difficult.", "attachment_id": null, "tags": [], "bug_id": 664291, "text": "Figuring out how much virtual address space you have to play with should *not* be this difficult."}, {"author": "justin.lebar+bug@gmail.com", "text": "It would be nice to say that we usually or always run out of physical memory before we run out of virtual address space, but I don't actually know that's true.  My vmem seems to be about 2 * RSS (on Linux, anyway; we don't report vmem on Windows?), so on a Windows box with 3G of RAM and a 2G per-process vmem limit, it seems that we could hit the vmem limit first.", "bug_id": 664291, "tags": [], "creator": "justin.lebar+bug@gmail.com", "time": "2011-06-29T03:24:52Z", "creation_time": "2011-06-29T03:24:52Z", "raw_text": "It would be nice to say that we usually or always run out of physical memory before we run out of virtual address space, but I don't actually know that's true.  My vmem seems to be about 2 * RSS (on Linux, anyway; we don't report vmem on Windows?), so on a Windows box with 3G of RAM and a 2G per-process vmem limit, it seems that we could hit the vmem limit first.", "attachment_id": null, "is_private": false, "id": 5563671, "count": 29}, {"tags": [], "bug_id": 664291, "text": "Digging through the syscalls, it looks like maybe we can't get the vsize on Windows?  (Seriously?)  If so, I guess we can scrap that for now.", "attachment_id": null, "raw_text": "Digging through the syscalls, it looks like maybe we can't get the vsize on Windows?  (Seriously?)  If so, I guess we can scrap that for now.", "creation_time": "2011-06-29T03:34:14Z", "time": "2011-06-29T03:34:14Z", "creator": "justin.lebar+bug@gmail.com", "author": "justin.lebar+bug@gmail.com", "id": 5563689, "count": 30, "is_private": false}, {"count": 31, "id": 5563693, "is_private": false, "author": "justin.lebar+bug@gmail.com", "creation_time": "2011-06-29T03:37:00Z", "time": "2011-06-29T03:37:00Z", "creator": "justin.lebar+bug@gmail.com", "raw_text": "...well, process explorer somehow gets something it calls \"virtual size\", so maybe all hope is not lost.", "attachment_id": null, "tags": [], "text": "...well, process explorer somehow gets something it calls \"virtual size\", so maybe all hope is not lost.", "bug_id": 664291}, {"attachment_id": null, "raw_text": "Aha.  GlobalMemoryStatusEx.ullAvailVirtual tells you how much virtual memory is available in the current process.\n\nhttp://msdn.microsoft.com/en-us/library/aa366589%28v=vs.85%29.aspx\n\n(How many different ways are there of querying the memory management system in Windows?  It's nuts...)", "tags": [], "text": "Aha.  GlobalMemoryStatusEx.ullAvailVirtual tells you how much virtual memory is available in the current process.\n\nhttp://msdn.microsoft.com/en-us/library/aa366589%28v=vs.85%29.aspx\n\n(How many different ways are there of querying the memory management system in Windows?  It's nuts...)", "bug_id": 664291, "is_private": false, "id": 5563703, "count": 32, "creator": "justin.lebar+bug@gmail.com", "time": "2011-06-29T03:42:27Z", "creation_time": "2011-06-29T03:42:27Z", "author": "justin.lebar+bug@gmail.com"}, {"is_private": false, "count": 33, "id": 5563797, "author": "mh+mozilla@glandium.org", "creator": "mh+mozilla@glandium.org", "creation_time": "2011-06-29T05:17:48Z", "time": "2011-06-29T05:17:48Z", "raw_text": "For Linux, doesn't /proc/meminfo contain what you want? (probably VmallocTotal, but my kernel and system is 64 bits, so the value here is just huge)", "attachment_id": null, "tags": [], "bug_id": 664291, "text": "For Linux, doesn't /proc/meminfo contain what you want? (probably VmallocTotal, but my kernel and system is 64 bits, so the value here is just huge)"}, {"creator": "justin.lebar+bug@gmail.com", "creation_time": "2011-06-29T14:16:25Z", "time": "2011-06-29T14:16:25Z", "author": "justin.lebar+bug@gmail.com", "is_private": false, "id": 5564433, "count": 34, "tags": [], "bug_id": 664291, "text": "I just booted up a 32-bit Linux VM -- I think it's CommitLimit in /proc/meminfo.\n\nTwo down, one to go!", "attachment_id": null, "raw_text": "I just booted up a 32-bit Linux VM -- I think it's CommitLimit in /proc/meminfo.\n\nTwo down, one to go!"}, {"tags": [], "text": "(In reply to comment #34)\n> I just booted up a 32-bit Linux VM -- I think it's CommitLimit in\n> /proc/meminfo.\n> \n> Two down, one to go!\n\nOn my x64 system with 16GB RAM, it reads:\nCommitLimit:    10182392 kB\n\nwhich is much less than the available RAM.\n\nI could happily map 65470mb of virtual address space with your python script.", "bug_id": 664291, "raw_text": "(In reply to comment #34)\n> I just booted up a 32-bit Linux VM -- I think it's CommitLimit in\n> /proc/meminfo.\n> \n> Two down, one to go!\n\nOn my x64 system with 16GB RAM, it reads:\nCommitLimit:    10182392 kB\n\nwhich is much less than the available RAM.\n\nI could happily map 65470mb of virtual address space with your python script.", "attachment_id": null, "author": "mh+mozilla@glandium.org", "time": "2011-06-29T14:34:59Z", "creation_time": "2011-06-29T14:34:59Z", "creator": "mh+mozilla@glandium.org", "id": 5564486, "count": 35, "is_private": false}, {"is_private": false, "id": 5564507, "count": 36, "author": "justin.lebar+bug@gmail.com", "creator": "justin.lebar+bug@gmail.com", "time": "2011-06-29T14:44:23Z", "creation_time": "2011-06-29T14:44:23Z", "raw_text": "Hm.\n\nOn my 32-bit VM, CommitLimit is the only value near 3G (which is where the Python script bails).\n\nMemTotal:        2060396 kB\nMemFree:          434900 kB\nBuffers:          155676 kB\nCached:          1239436 kB\nSwapCached:            0 kB\nActive:           566296 kB\nInactive:         950720 kB\nActive(anon):     122656 kB\nInactive(anon):     2304 kB\nActive(file):     443640 kB\nInactive(file):   948416 kB\nUnevictable:           0 kB\nMlocked:               0 kB\nHighTotal:       1187784 kB\nHighFree:          32724 kB\nLowTotal:         872612 kB\nLowFree:          402176 kB\nSwapTotal:       2095100 kB\nSwapFree:        2095100 kB\nDirty:               116 kB\nWriteback:             0 kB\nAnonPages:        121824 kB\nMapped:            43744 kB\nShmem:              3052 kB\nSlab:              90240 kB\nSReclaimable:      80508 kB\nSUnreclaim:         9732 kB\nKernelStack:        2200 kB\nPageTables:         4320 kB\nNFS_Unstable:          0 kB\nBounce:                0 kB\nWritebackTmp:          0 kB\nCommitLimit:     3125296 kB\nCommitted_AS:    1063988 kB\nVmallocTotal:     122880 kB\nVmallocUsed:       32560 kB\nVmallocChunk:      85492 kB\nHardwareCorrupted:     0 kB\nHugePages_Total:       0\nHugePages_Free:        0\nHugePages_Rsvd:        0\nHugePages_Surp:        0\nHugepagesize:       4096 kB\nDirectMap4k:       12280 kB\nDirectMap4M:      897024 kB", "attachment_id": null, "text": "Hm.\n\nOn my 32-bit VM, CommitLimit is the only value near 3G (which is where the Python script bails).\n\nMemTotal:        2060396 kB\nMemFree:          434900 kB\nBuffers:          155676 kB\nCached:          1239436 kB\nSwapCached:            0 kB\nActive:           566296 kB\nInactive:         950720 kB\nActive(anon):     122656 kB\nInactive(anon):     2304 kB\nActive(file):     443640 kB\nInactive(file):   948416 kB\nUnevictable:           0 kB\nMlocked:               0 kB\nHighTotal:       1187784 kB\nHighFree:          32724 kB\nLowTotal:         872612 kB\nLowFree:          402176 kB\nSwapTotal:       2095100 kB\nSwapFree:        2095100 kB\nDirty:               116 kB\nWriteback:             0 kB\nAnonPages:        121824 kB\nMapped:            43744 kB\nShmem:              3052 kB\nSlab:              90240 kB\nSReclaimable:      80508 kB\nSUnreclaim:         9732 kB\nKernelStack:        2200 kB\nPageTables:         4320 kB\nNFS_Unstable:          0 kB\nBounce:                0 kB\nWritebackTmp:          0 kB\nCommitLimit:     3125296 kB\nCommitted_AS:    1063988 kB\nVmallocTotal:     122880 kB\nVmallocUsed:       32560 kB\nVmallocChunk:      85492 kB\nHardwareCorrupted:     0 kB\nHugePages_Total:       0\nHugePages_Free:        0\nHugePages_Rsvd:        0\nHugePages_Surp:        0\nHugepagesize:       4096 kB\nDirectMap4k:       12280 kB\nDirectMap4M:      897024 kB", "bug_id": 664291, "tags": []}, {"tags": [], "bug_id": 664291, "text": "On my 64-bits system, there is no value near 65GB.", "attachment_id": null, "raw_text": "On my 64-bits system, there is no value near 65GB.", "creation_time": "2011-06-29T14:51:33Z", "time": "2011-06-29T14:51:33Z", "creator": "mh+mozilla@glandium.org", "author": "mh+mozilla@glandium.org", "id": 5564514, "count": 37, "is_private": false}, {"attachment_id": null, "raw_text": "Actually, I just had hit another kind of limit: the number of different mappings we can have in a process. If I change your script to allocate 1GB at a time instead of 1MB, I go up to 65TB mapped...", "text": "Actually, I just had hit another kind of limit: the number of different mappings we can have in a process. If I change your script to allocate 1GB at a time instead of 1MB, I go up to 65TB mapped...", "bug_id": 664291, "tags": [], "is_private": false, "count": 38, "id": 5564524, "creator": "mh+mozilla@glandium.org", "creation_time": "2011-06-29T14:54:36Z", "time": "2011-06-29T14:54:36Z", "author": "mh+mozilla@glandium.org"}, {"is_private": false, "count": 39, "id": 5564529, "author": "justin.lebar+bug@gmail.com", "creator": "justin.lebar+bug@gmail.com", "time": "2011-06-29T14:57:16Z", "creation_time": "2011-06-29T14:57:16Z", "raw_text": "I just tested on office.mozilla.org, a 32-bit system with CommitLimit 2,553MB, and I could map 3068MB.", "attachment_id": null, "text": "I just tested on office.mozilla.org, a 32-bit system with CommitLimit 2,553MB, and I could map 3068MB.", "bug_id": 664291, "tags": []}, {"tags": [], "text": "On the 32-bit system with a measured mapping limit of ~3G, there don't appear to be any values immediately in /proc which are 3 followed by at least 6 digits, aside from meminfo:CommitLimit.\n\nI come up similarly empty-handed when I look in /proc/1.\n\n  find /proc -maxdepth 1 | xargs egrep '\\<3[0-9]{6}' 2>/dev/null", "bug_id": 664291, "raw_text": "On the 32-bit system with a measured mapping limit of ~3G, there don't appear to be any values immediately in /proc which are 3 followed by at least 6 digits, aside from meminfo:CommitLimit.\n\nI come up similarly empty-handed when I look in /proc/1.\n\n  find /proc -maxdepth 1 | xargs egrep '\\<3[0-9]{6}' 2>/dev/null", "attachment_id": null, "author": "justin.lebar+bug@gmail.com", "creator": "justin.lebar+bug@gmail.com", "time": "2011-06-29T15:20:55Z", "creation_time": "2011-06-29T15:20:55Z", "is_private": false, "count": 40, "id": 5564585}, {"is_private": false, "count": 41, "id": 5565385, "creator": "justin.lebar+bug@gmail.com", "creation_time": "2011-06-29T20:12:21Z", "time": "2011-06-29T20:12:21Z", "author": "justin.lebar+bug@gmail.com", "attachment_id": null, "raw_text": "FWIW I was able to get vsize to 1600MB with explicit/private/rss of ~900MB on a Windows 7 x86-32 VM.  Since Windows has a (default) max vsize of 2G, I think it's worth monitoring both explicit and vsize here.", "tags": [], "bug_id": 664291, "text": "FWIW I was able to get vsize to 1600MB with explicit/private/rss of ~900MB on a Windows 7 x86-32 VM.  Since Windows has a (default) max vsize of 2G, I think it's worth monitoring both explicit and vsize here."}, {"attachment_id": null, "raw_text": "Removing the dependency on bug 668137 (add vsize on Windows) -- as I have the patch written, that bug isn't a strict dependency for firing low vmem events.  I think we want it anyway.", "text": "Removing the dependency on bug 668137 (add vsize on Windows) -- as I have the patch written, that bug isn't a strict dependency for firing low vmem events.  I think we want it anyway.", "bug_id": 664291, "tags": [], "is_private": false, "id": 5565395, "count": 42, "creator": "justin.lebar+bug@gmail.com", "time": "2011-06-29T20:16:37Z", "creation_time": "2011-06-29T20:16:37Z", "author": "justin.lebar+bug@gmail.com"}, {"raw_text": "", "attachment_id": 542934, "is_private": false, "id": 5565501, "count": 43, "author": "justin.lebar+bug@gmail.com", "tags": [], "text": "Created attachment 542934\nPatch v1", "bug_id": 664291, "creator": "justin.lebar+bug@gmail.com", "time": "2011-06-29T20:56:57Z", "creation_time": "2011-06-29T20:56:57Z"}, {"tags": [], "text": "I don't think we want to check this in without first auditing all the low-memory listeners and making sure that either:\n\n * it's OK to run them once a second when there's memory pressure, or\n * they back off when they're called too often.\n\nI considered making the LowMemoryDetector back off and not fire lots of events when there's memory pressure, but I think there's an end-to-end argument in favor of pushing the decision about how often to do things like GC down to the code which understands the GC.\n\nI'm going to do this audit next, and I'll report back.", "bug_id": 664291, "attachment_id": null, "raw_text": "I don't think we want to check this in without first auditing all the low-memory listeners and making sure that either:\n\n * it's OK to run them once a second when there's memory pressure, or\n * they back off when they're called too often.\n\nI considered making the LowMemoryDetector back off and not fire lots of events when there's memory pressure, but I think there's an end-to-end argument in favor of pushing the decision about how often to do things like GC down to the code which understands the GC.\n\nI'm going to do this audit next, and I'll report back.", "creation_time": "2011-06-29T21:06:11Z", "time": "2011-06-29T21:06:11Z", "creator": "justin.lebar+bug@gmail.com", "author": "justin.lebar+bug@gmail.com", "count": 44, "id": 5565523, "is_private": false}, {"attachment_id": null, "raw_text": "There are actually more places that listen to memory-pressure than I thought!\n\nThe one I worry about most is gc/cc, especially since if we're swapping, gc/cc might be more expensive than usual.\n\nIt seems like the right thing to do is trigger a gc/cc immediately when we see the first notification in some period of time, but from then on only gc/cc a bit more aggressively, until memory pressure subsides.\n\nnjn, do you have any thoughts on how we should do this?", "tags": [], "text": "There are actually more places that listen to memory-pressure than I thought!\n\nThe one I worry about most is gc/cc, especially since if we're swapping, gc/cc might be more expensive than usual.\n\nIt seems like the right thing to do is trigger a gc/cc immediately when we see the first notification in some period of time, but from then on only gc/cc a bit more aggressively, until memory pressure subsides.\n\nnjn, do you have any thoughts on how we should do this?", "bug_id": 664291, "is_private": false, "id": 5565578, "count": 45, "creator": "justin.lebar+bug@gmail.com", "time": "2011-06-29T21:26:55Z", "creation_time": "2011-06-29T21:26:55Z", "author": "justin.lebar+bug@gmail.com"}, {"author": "justin.lebar+bug@gmail.com", "creator": "justin.lebar+bug@gmail.com", "time": "2011-06-30T04:03:25Z", "creation_time": "2011-06-30T04:03:25Z", "is_private": false, "id": 5566323, "count": 46, "text": "Testing done:\n\n* On Windows, I tested that vsize notifications are fired when vram gets too high.  I just realized I haven't tested the low physical memory notifications in this latest iteration of the patch, and I'll do that in the morning.\n\n* On Linux, I tested that memory notifications are fired when RAM is constrained, using the process at [1].\n\nMy mac has 8G of RAM, and the process at [1] doesn't work on Mac, so I haven't tested there.  But the code is exactly the same as on Linux.\n\nI haven't done any testing to ensure that the memory notifications actually do something useful.  I think we might as well do that in separate bugs.  But of course we don't want to land this until we know that it's at least not deleterious to fire so many low-memory events.\n\n[1] http://jlebar.com/2011/6/15/Limiting_the_amount_of_RAM_a_program_can_use.html", "bug_id": 664291, "tags": [], "raw_text": "Testing done:\n\n* On Windows, I tested that vsize notifications are fired when vram gets too high.  I just realized I haven't tested the low physical memory notifications in this latest iteration of the patch, and I'll do that in the morning.\n\n* On Linux, I tested that memory notifications are fired when RAM is constrained, using the process at [1].\n\nMy mac has 8G of RAM, and the process at [1] doesn't work on Mac, so I haven't tested there.  But the code is exactly the same as on Linux.\n\nI haven't done any testing to ensure that the memory notifications actually do something useful.  I think we might as well do that in separate bugs.  But of course we don't want to land this until we know that it's at least not deleterious to fire so many low-memory events.\n\n[1] http://jlebar.com/2011/6/15/Limiting_the_amount_of_RAM_a_program_can_use.html", "attachment_id": null}, {"author": "n.nethercote@gmail.com", "creator": "n.nethercote@gmail.com", "creation_time": "2011-06-30T04:29:38Z", "time": "2011-06-30T04:29:38Z", "is_private": false, "id": 5566353, "count": 47, "tags": [], "bug_id": 664291, "text": "Comment on attachment 542934\nPatch v1\n\nReview of attachment 542934:\n-----------------------------------------------------------------\n\nLet me double check how this works (forgive me if I'm duplicating anything you've written).  The default behaviour:\n\n- On Linux/Mac\n  - If the number of hard page faults since the last check (1 second ago) exceeds 100, fire a PHYSICAL notification.\n\n- On Windows:\n  - If the available virtual memory is less than 256MB, fire a VIRTUAL notification.\n  - If the available physical memory is less than 32MB, fire a PHYSICAL notification.\n\nIt'd be good to have comments like that in HasMemoryPressure(), even though the code isn't complicated, to make things super clear.\n\nSo the code looks pretty good, ie. it does what you intend it to.  However, I'm a Gecko newbie, so I strongly recommend you get someone else to review this (and then someone else to super-review).  I looked closely at the memory pressure stuff, but I don't know that much about observers and mutexes and initializing children and all that stuff.  So I've given feedback+.\n\nThe big questions are all on the heuristic side:  are these are the right measurements to be taking, are they taken often enough... ie. does it actually work?  As you say, that'll require checking individual listeners, and it shouldn't land until that has happened.  And then, this will need some time to bake, I suggest landing it early in the release cycle if possible.\n\nAnother question: does checking every 1 second cause problems with mobile devices?\n\nAlso, it's a concern that there are no tests, but it's hard to know what tests for this code would look like.  Maybe the prefs could be changed so that the notifications are fired very frequently?  Not sure.\n\n::: toolkit/components/telemetry/TelemetryHistograms.h\n@@ +50,5 @@\n>  HISTOGRAM(MEMORY_JS_GC_HEAP, 1024, 512 * 1024, 10, EXPONENTIAL, \"Memory used by the garbage-collected JavaScript heap (KB)\")\n>  HISTOGRAM(MEMORY_RESIDENT, 32 * 1024, 1024 * 1024, 10, EXPONENTIAL, \"Resident memory size (KB)\")\n>  HISTOGRAM(MEMORY_LAYOUT_ALL, 1024, 64 * 1024, 10, EXPONENTIAL, \"Memory used by layout (KB)\")\n> +HISTOGRAM(LOW_MEMORY_EVENTS, 1, 256, 4, EXPONENTIAL, \"Number of low-memory events fired by LowMemoryDetector (since last telemetry ping)\")\n> +HISTOGRAM(LOW_VMEMORY_EVENTS, 1, 256, 4, EXPONENTIAL, \"Number of low virtual memory events fired by LowMemoryDetector (since last telemetry ping)\")\n\nNit: Inconsistent hyphenation, \"low-memory\" vs. \"low virtual memory\".\n\nMore substantial point:  you have an enum with\nMEMORY_PRESSURE_PHYSICAL, MEMORY_PRESSURE_VIRTUAL.  So you should talk about \"low physical memory\" and \"low virtual memory\" and avoid phrases like \"low memory\"... I'd like you to scrupulously distinguish physical and virtual memory throughout the whole patch, it makes things much clearer.\n\n::: xpcom/base/LowMemoryDetector.cpp\n@@ +81,5 @@\n> + *    check_interval_ms do we need to observe to declare that memory is low?\n> + *\n> + * - low_memory_threshold_mb (megabytes, Windows only)\n> + *    If we're detecting memory pressure by monitoring the amount of available\n> + *    memory, what amount of available memory do we consider to be \"low\"?\n\nSimilar: virtual or physical memory?  Presumably the former.\n\n@@ +111,5 @@\n> +  nsnull\n> +};\n> +\n> +// Mark these as volatile since they may be read and written on different\n> +// threads.  Volatile keeps the compiler from transforming this\n\nThis scares me.  Is it a standard Mozilla idiom?\n\n@@ +132,5 @@\n> +\n> +void\n> +ReloadPrefs()\n> +{\n> +  // You should probably keep these defaults sync'ed with all.js.\n\nIt kinda sucks that the defaults are specified twice, is that unavoidable?\n\n@@ +169,5 @@\n> +  UNITS_COUNT,\n> +  GetNumLowMemoryEvents,\n> +  \"Number of times the process detected that the system was low on available \"\n> +  \"physical memory and tried to reduce its footprint.  On Linux and Mac, we \"\n> +  \"detect low memory by observing page hard page faults in the Firefox \"\n\n\"page hard page\"\n\nAlso, other reporters have avoided mentioning \"Firefox\", using \"the application\" or similar.  Seems a good idea in case this code ends up in some other product.  \"The application\" could replace \"we\", too.  (Oh, I see you used \"the process\" for low-vmemory-events, that's fine too.)\n\n@@ +402,5 @@\n> +#include <inttypes.h>\n> +\n> +// Initialize mLastNumPageFaults to -1 so we don't fire a low-memory\n> +// notification the first time we read this value -- cold startup produces many\n> +// hard page faults.\n\nWon't the \"don't send any notifications for the first N seconds\" feature protect against that?  Then we could initialize it to 0, and then HasMemoryPressure() wouldn't need to check for -1.\n\n@@ +506,5 @@\n> +    NS_WARNING(\"GlobalMemoryStatusEx call failed.\");\n> +    return MEMORY_PRESSURE_NONE;\n> +  }\n> +\n> +  // It's no extra work to check for vmemory presssure on 64-bit processes, so\n\npresssure!\n\n::: xpcom/base/LowMemoryDetector.h\n@@ +116,5 @@\n> +  /**\n> +   * Increment our count of the number of memory pressure events we've fired\n> +   * because we're running out of available physical memory.\n> +   */\n> +  void IncrementNumLowMemoryEvents();\n\nAs above:  it would be clearer if |Memory| was changed to |PMemory| or |PhysicalMemory|.", "raw_text": "Review of attachment 542934:\n-----------------------------------------------------------------\n\nLet me double check how this works (forgive me if I'm duplicating anything you've written).  The default behaviour:\n\n- On Linux/Mac\n  - If the number of hard page faults since the last check (1 second ago) exceeds 100, fire a PHYSICAL notification.\n\n- On Windows:\n  - If the available virtual memory is less than 256MB, fire a VIRTUAL notification.\n  - If the available physical memory is less than 32MB, fire a PHYSICAL notification.\n\nIt'd be good to have comments like that in HasMemoryPressure(), even though the code isn't complicated, to make things super clear.\n\nSo the code looks pretty good, ie. it does what you intend it to.  However, I'm a Gecko newbie, so I strongly recommend you get someone else to review this (and then someone else to super-review).  I looked closely at the memory pressure stuff, but I don't know that much about observers and mutexes and initializing children and all that stuff.  So I've given feedback+.\n\nThe big questions are all on the heuristic side:  are these are the right measurements to be taking, are they taken often enough... ie. does it actually work?  As you say, that'll require checking individual listeners, and it shouldn't land until that has happened.  And then, this will need some time to bake, I suggest landing it early in the release cycle if possible.\n\nAnother question: does checking every 1 second cause problems with mobile devices?\n\nAlso, it's a concern that there are no tests, but it's hard to know what tests for this code would look like.  Maybe the prefs could be changed so that the notifications are fired very frequently?  Not sure.\n\n::: toolkit/components/telemetry/TelemetryHistograms.h\n@@ +50,5 @@\n>  HISTOGRAM(MEMORY_JS_GC_HEAP, 1024, 512 * 1024, 10, EXPONENTIAL, \"Memory used by the garbage-collected JavaScript heap (KB)\")\n>  HISTOGRAM(MEMORY_RESIDENT, 32 * 1024, 1024 * 1024, 10, EXPONENTIAL, \"Resident memory size (KB)\")\n>  HISTOGRAM(MEMORY_LAYOUT_ALL, 1024, 64 * 1024, 10, EXPONENTIAL, \"Memory used by layout (KB)\")\n> +HISTOGRAM(LOW_MEMORY_EVENTS, 1, 256, 4, EXPONENTIAL, \"Number of low-memory events fired by LowMemoryDetector (since last telemetry ping)\")\n> +HISTOGRAM(LOW_VMEMORY_EVENTS, 1, 256, 4, EXPONENTIAL, \"Number of low virtual memory events fired by LowMemoryDetector (since last telemetry ping)\")\n\nNit: Inconsistent hyphenation, \"low-memory\" vs. \"low virtual memory\".\n\nMore substantial point:  you have an enum with\nMEMORY_PRESSURE_PHYSICAL, MEMORY_PRESSURE_VIRTUAL.  So you should talk about \"low physical memory\" and \"low virtual memory\" and avoid phrases like \"low memory\"... I'd like you to scrupulously distinguish physical and virtual memory throughout the whole patch, it makes things much clearer.\n\n::: xpcom/base/LowMemoryDetector.cpp\n@@ +81,5 @@\n> + *    check_interval_ms do we need to observe to declare that memory is low?\n> + *\n> + * - low_memory_threshold_mb (megabytes, Windows only)\n> + *    If we're detecting memory pressure by monitoring the amount of available\n> + *    memory, what amount of available memory do we consider to be \"low\"?\n\nSimilar: virtual or physical memory?  Presumably the former.\n\n@@ +111,5 @@\n> +  nsnull\n> +};\n> +\n> +// Mark these as volatile since they may be read and written on different\n> +// threads.  Volatile keeps the compiler from transforming this\n\nThis scares me.  Is it a standard Mozilla idiom?\n\n@@ +132,5 @@\n> +\n> +void\n> +ReloadPrefs()\n> +{\n> +  // You should probably keep these defaults sync'ed with all.js.\n\nIt kinda sucks that the defaults are specified twice, is that unavoidable?\n\n@@ +169,5 @@\n> +  UNITS_COUNT,\n> +  GetNumLowMemoryEvents,\n> +  \"Number of times the process detected that the system was low on available \"\n> +  \"physical memory and tried to reduce its footprint.  On Linux and Mac, we \"\n> +  \"detect low memory by observing page hard page faults in the Firefox \"\n\n\"page hard page\"\n\nAlso, other reporters have avoided mentioning \"Firefox\", using \"the application\" or similar.  Seems a good idea in case this code ends up in some other product.  \"The application\" could replace \"we\", too.  (Oh, I see you used \"the process\" for low-vmemory-events, that's fine too.)\n\n@@ +402,5 @@\n> +#include <inttypes.h>\n> +\n> +// Initialize mLastNumPageFaults to -1 so we don't fire a low-memory\n> +// notification the first time we read this value -- cold startup produces many\n> +// hard page faults.\n\nWon't the \"don't send any notifications for the first N seconds\" feature protect against that?  Then we could initialize it to 0, and then HasMemoryPressure() wouldn't need to check for -1.\n\n@@ +506,5 @@\n> +    NS_WARNING(\"GlobalMemoryStatusEx call failed.\");\n> +    return MEMORY_PRESSURE_NONE;\n> +  }\n> +\n> +  // It's no extra work to check for vmemory presssure on 64-bit processes, so\n\npresssure!\n\n::: xpcom/base/LowMemoryDetector.h\n@@ +116,5 @@\n> +  /**\n> +   * Increment our count of the number of memory pressure events we've fired\n> +   * because we're running out of available physical memory.\n> +   */\n> +  void IncrementNumLowMemoryEvents();\n\nAs above:  it would be clearer if |Memory| was changed to |PMemory| or |PhysicalMemory|.", "attachment_id": 542934}, {"attachment_id": 543150, "raw_text": "bsmedberg, are you interested in taking a look at this?", "tags": [], "text": "Created attachment 543150\nPatch v2\n\nbsmedberg, are you interested in taking a look at this?", "bug_id": 664291, "is_private": false, "count": 48, "id": 5567290, "creator": "justin.lebar+bug@gmail.com", "time": "2011-06-30T16:03:51Z", "creation_time": "2011-06-30T16:03:51Z", "author": "justin.lebar+bug@gmail.com"}, {"raw_text": "(In reply to comment 47)\n> Let me double check how this works (forgive me if I'm duplicating anything you've written).  The default behaviour:\n> \n> - On Linux/Mac\n>   - If the number of hard page faults since the last check (1 second ago) exceeds 100, fire a PHYSICAL notification.\n> \n> - On Windows:\n>   - If the available virtual memory is less than 256MB, fire a VIRTUAL notification.\n>   - If the available physical memory is less than 32MB, fire a PHYSICAL notification.\n\nYes, that's right.  I've added comments to this effect.\n> \n> The big questions are all on the heuristic side:  are these are the right\n> measurements to be taking, are they taken often enough... ie. does it\n> actually work?  As you say, that'll require checking individual listeners,\n> and it shouldn't land until that has happened.  And then, this will need some\n> time to bake, I suggest landing it early in the release cycle if possible.\n\nI agree.  To be clear, there are two (mostly) separate \"does it work?\" questions:\n\n * Do the memory pressure notifications get fired at the right time?  It has\n   to be before we're totally out of memory, since things like the CC allocate\n   memory, and since walking memory in a GC is going to be bad if we're paged\n   out.  But it shouldn't be too much before we're out of memory, because we\n   don't want to drop caches and whatnot unnecessarily.\n\n * Do the memory-pressure observers react well to the memory pressure\n   notifications?  If it's expensive to run the observer (e.g. the CC), does it\n   back off appropriately upon getting one memory-pressure report a second?\n\n> Another question: does checking every 1 second cause problems with mobile devices?\n\nIt's currently disabled on mobile:\n\n  // The UnixLowMemoryDetector shouldn't break on Android/Maemo, but Android\n  // has no swap and swap is optional on Maemo.  The Unix detector works by\n  // noticing when we swap, so is unlikely to be useful on these platforms.\n\n> Also, it's a concern that there are no tests, but it's hard to know what tests for this code would look like.  Maybe the prefs could be changed so that the notifications are fired very frequently?  Not sure.\n\nI have no idea how to test this.  The problem isn't the frequency of the notifications so much as the fact that we're observing system events.\n\nI guess I could create some JS objects which use a lot of memory and then check that the notifications are fired.  But I'm not sure I could do this in a way which consistently doesn't cause us to run out of virtual address space...\n\n> @@ +111,5 @@\n> > +  nsnull\n> > +};\n> > +\n> > +// Mark these as volatile since they may be read and written on different\n> > +// threads.  Volatile keeps the compiler from transforming this\n> \n> This scares me.  Is it a standard Mozilla idiom?\n\nI could guard with a lock -- Is that what you were asking? -- but it just felt\nunnecessary. But I did this before there were any locking operations in the\nloop -- then I had to add a mutex in the sleep call.  \n\nI think it's safe as it is, because aiui, if atomic operation A happens-before\natomic operation B, all writes which occur before A are visible after B.  So\nthe changes to the prefs are visible as soon as we, for instance, take a lock\non each thread, which surely will happen within one iteration of the detector\nloop.\n\nWhether we should be relying on this behavior is another question entirely.\nLet's see what the next reviewer thinks.\n\n> > +void\n> > +ReloadPrefs()\n> > +{\n> > +  // You should probably keep these defaults sync'ed with all.js.\n> \n> It kinda sucks that the defaults are specified twice, is that unavoidable?\n\nIt is as far as I know.\n\n> @@ +402,5 @@\n> > +#include <inttypes.h>\n> > +\n> > +// Initialize mLastNumPageFaults to -1 so we don't fire a low-memory\n> > +// notification the first time we read this value -- cold startup produces many\n> > +// hard page faults.\n> \n> Won't the \"don't send any notifications for the first N seconds\" feature protect against that?  Then we could initialize it to 0, and then HasMemoryPressure() wouldn't need to check for -1.\n\nSuppose cold startup causes 100 page faults.  We initialize mLastNumPageFaults\nto 0 and wait N seconds before checking.  When we check, we discover that there\nare 100 more page faults than mLastNumPageFaults, so we fire a memory-pressure\nnotification.", "attachment_id": null, "tags": [], "bug_id": 664291, "text": "(In reply to comment 47)\n> Let me double check how this works (forgive me if I'm duplicating anything you've written).  The default behaviour:\n> \n> - On Linux/Mac\n>   - If the number of hard page faults since the last check (1 second ago) exceeds 100, fire a PHYSICAL notification.\n> \n> - On Windows:\n>   - If the available virtual memory is less than 256MB, fire a VIRTUAL notification.\n>   - If the available physical memory is less than 32MB, fire a PHYSICAL notification.\n\nYes, that's right.  I've added comments to this effect.\n> \n> The big questions are all on the heuristic side:  are these are the right\n> measurements to be taking, are they taken often enough... ie. does it\n> actually work?  As you say, that'll require checking individual listeners,\n> and it shouldn't land until that has happened.  And then, this will need some\n> time to bake, I suggest landing it early in the release cycle if possible.\n\nI agree.  To be clear, there are two (mostly) separate \"does it work?\" questions:\n\n * Do the memory pressure notifications get fired at the right time?  It has\n   to be before we're totally out of memory, since things like the CC allocate\n   memory, and since walking memory in a GC is going to be bad if we're paged\n   out.  But it shouldn't be too much before we're out of memory, because we\n   don't want to drop caches and whatnot unnecessarily.\n\n * Do the memory-pressure observers react well to the memory pressure\n   notifications?  If it's expensive to run the observer (e.g. the CC), does it\n   back off appropriately upon getting one memory-pressure report a second?\n\n> Another question: does checking every 1 second cause problems with mobile devices?\n\nIt's currently disabled on mobile:\n\n  // The UnixLowMemoryDetector shouldn't break on Android/Maemo, but Android\n  // has no swap and swap is optional on Maemo.  The Unix detector works by\n  // noticing when we swap, so is unlikely to be useful on these platforms.\n\n> Also, it's a concern that there are no tests, but it's hard to know what tests for this code would look like.  Maybe the prefs could be changed so that the notifications are fired very frequently?  Not sure.\n\nI have no idea how to test this.  The problem isn't the frequency of the notifications so much as the fact that we're observing system events.\n\nI guess I could create some JS objects which use a lot of memory and then check that the notifications are fired.  But I'm not sure I could do this in a way which consistently doesn't cause us to run out of virtual address space...\n\n> @@ +111,5 @@\n> > +  nsnull\n> > +};\n> > +\n> > +// Mark these as volatile since they may be read and written on different\n> > +// threads.  Volatile keeps the compiler from transforming this\n> \n> This scares me.  Is it a standard Mozilla idiom?\n\nI could guard with a lock -- Is that what you were asking? -- but it just felt\nunnecessary. But I did this before there were any locking operations in the\nloop -- then I had to add a mutex in the sleep call.  \n\nI think it's safe as it is, because aiui, if atomic operation A happens-before\natomic operation B, all writes which occur before A are visible after B.  So\nthe changes to the prefs are visible as soon as we, for instance, take a lock\non each thread, which surely will happen within one iteration of the detector\nloop.\n\nWhether we should be relying on this behavior is another question entirely.\nLet's see what the next reviewer thinks.\n\n> > +void\n> > +ReloadPrefs()\n> > +{\n> > +  // You should probably keep these defaults sync'ed with all.js.\n> \n> It kinda sucks that the defaults are specified twice, is that unavoidable?\n\nIt is as far as I know.\n\n> @@ +402,5 @@\n> > +#include <inttypes.h>\n> > +\n> > +// Initialize mLastNumPageFaults to -1 so we don't fire a low-memory\n> > +// notification the first time we read this value -- cold startup produces many\n> > +// hard page faults.\n> \n> Won't the \"don't send any notifications for the first N seconds\" feature protect against that?  Then we could initialize it to 0, and then HasMemoryPressure() wouldn't need to check for -1.\n\nSuppose cold startup causes 100 page faults.  We initialize mLastNumPageFaults\nto 0 and wait N seconds before checking.  When we check, we discover that there\nare 100 more page faults than mLastNumPageFaults, so we fire a memory-pressure\nnotification.", "is_private": false, "count": 49, "id": 5567299, "author": "justin.lebar+bug@gmail.com", "creator": "justin.lebar+bug@gmail.com", "creation_time": "2011-06-30T16:06:23Z", "time": "2011-06-30T16:06:23Z"}, {"id": 5567301, "count": 50, "is_private": false, "time": "2011-06-30T16:06:54Z", "creation_time": "2011-06-30T16:06:54Z", "creator": "justin.lebar+bug@gmail.com", "author": "justin.lebar+bug@gmail.com", "attachment_id": 543150, "raw_text": "Taras, can you take a look at the Telemetry changes here?", "tags": [], "bug_id": 664291, "text": "Comment on attachment 543150\nPatch v2\n\nTaras, can you take a look at the Telemetry changes here?"}, {"id": 5568370, "count": 51, "is_private": false, "author": "taras.mozilla@glek.net", "time": "2011-06-30T22:22:36Z", "creation_time": "2011-06-30T22:22:36Z", "creator": "taras.mozilla@glek.net", "raw_text": "It doesn't make sense to me to poll for OOM on a timer. I think a better way would be to devise an active timer: ie the opposite of nsIIdleService.\n\nStick some time tracking into the event loop. ie every time an event passes and elapsed time exceeds some internal, fire some callback.\n\nTelemetry would benefit from this too.", "attachment_id": 543150, "text": "Comment on attachment 543150\nPatch v2\n\nIt doesn't make sense to me to poll for OOM on a timer. I think a better way would be to devise an active timer: ie the opposite of nsIIdleService.\n\nStick some time tracking into the event loop. ie every time an event passes and elapsed time exceeds some internal, fire some callback.\n\nTelemetry would benefit from this too.", "bug_id": 664291, "tags": []}, {"tags": [], "bug_id": 664291, "text": "In this specific case piggyback onto the cycle collector would work too.", "attachment_id": null, "raw_text": "In this specific case piggyback onto the cycle collector would work too.", "creation_time": "2011-06-30T22:24:43Z", "time": "2011-06-30T22:24:43Z", "creator": "taras.mozilla@glek.net", "author": "taras.mozilla@glek.net", "count": 52, "id": 5568375, "is_private": false}, {"author": "justin.lebar+bug@gmail.com", "creator": "justin.lebar+bug@gmail.com", "creation_time": "2011-06-30T23:25:25Z", "time": "2011-06-30T23:25:25Z", "is_private": false, "id": 5568542, "count": 53, "bug_id": 664291, "text": "(In reply to comment #51)\n> It doesn't make sense to me to poll for OOM on a timer. I think a better way\n> would be to devise an active timer: ie the opposite of nsIIdleService.\n\nWe can become low on physical memory even if we're idle.  Suppose the user minimizes Firefox and loads up Photoshop.  The hope is that we can catch this early and free up a whole bunch of memory, potentially keeping the system from swapping FF out and making us load back up more quickly.\n\nThe *nix code won't catch this case, since it's looking for page faults in the FF process, but the Windows code will, since it looks at overall available memory on the system.  I'm looking into doing something similar on *nix, if only since mobile can't swap.\n\nThat said, it would probably make sense that if we're idle and have fired one low memory notification, we stop checking until we're no longer idle.  Do you think this is reasonable, Taras?\n\nOf course, this whole bug doesn't even make a lot of sense unless we can drop some serious RAM when we notify.  Dropping all of bfcache might help (it currently does this on memory-pressure), but maybe there's more we can do.  (Now that images are discarded on a 10s timer, they're kind of out of the picture.)", "tags": [], "raw_text": "(In reply to comment #51)\n> It doesn't make sense to me to poll for OOM on a timer. I think a better way\n> would be to devise an active timer: ie the opposite of nsIIdleService.\n\nWe can become low on physical memory even if we're idle.  Suppose the user minimizes Firefox and loads up Photoshop.  The hope is that we can catch this early and free up a whole bunch of memory, potentially keeping the system from swapping FF out and making us load back up more quickly.\n\nThe *nix code won't catch this case, since it's looking for page faults in the FF process, but the Windows code will, since it looks at overall available memory on the system.  I'm looking into doing something similar on *nix, if only since mobile can't swap.\n\nThat said, it would probably make sense that if we're idle and have fired one low memory notification, we stop checking until we're no longer idle.  Do you think this is reasonable, Taras?\n\nOf course, this whole bug doesn't even make a lot of sense unless we can drop some serious RAM when we notify.  Dropping all of bfcache might help (it currently does this on memory-pressure), but maybe there's more we can do.  (Now that images are discarded on a 10s timer, they're kind of out of the picture.)", "attachment_id": null}, {"count": 54, "id": 5568559, "is_private": false, "time": "2011-06-30T23:31:34Z", "creation_time": "2011-06-30T23:31:34Z", "creator": "taras.mozilla@glek.net", "author": "taras.mozilla@glek.net", "attachment_id": null, "raw_text": "(In reply to comment #53)\n> (In reply to comment #51)\n> > It doesn't make sense to me to poll for OOM on a timer. I think a better way\n> > would be to devise an active timer: ie the opposite of nsIIdleService.\n> \n> We can become low on physical memory even if we're idle.  Suppose the user\n> minimizes Firefox and loads up Photoshop.  The hope is that we can catch\n> this early and free up a whole bunch of memory, potentially keeping the\n> system from swapping FF out and making us load back up more quickly.\n> \n\nAside: personally I would drop memory when user minimizes the browser anyway. Android needs to do it(not sure if it does  yet), dunno about desktop.\n\nI seriously doubt that Firefox would sit without spinning the event loop for too long. I object to adding yet another reason to spin it.", "tags": [], "bug_id": 664291, "text": "(In reply to comment #53)\n> (In reply to comment #51)\n> > It doesn't make sense to me to poll for OOM on a timer. I think a better way\n> > would be to devise an active timer: ie the opposite of nsIIdleService.\n> \n> We can become low on physical memory even if we're idle.  Suppose the user\n> minimizes Firefox and loads up Photoshop.  The hope is that we can catch\n> this early and free up a whole bunch of memory, potentially keeping the\n> system from swapping FF out and making us load back up more quickly.\n> \n\nAside: personally I would drop memory when user minimizes the browser anyway. Android needs to do it(not sure if it does  yet), dunno about desktop.\n\nI seriously doubt that Firefox would sit without spinning the event loop for too long. I object to adding yet another reason to spin it."}, {"author": "taras.mozilla@glek.net", "creation_time": "2011-06-30T23:32:36Z", "time": "2011-06-30T23:32:36Z", "creator": "taras.mozilla@glek.net", "id": 5568563, "count": 55, "is_private": false, "bug_id": 664291, "text": "Note Linux will fault on Android, since memory mapped files(aka libraries) act as swap.", "tags": [], "raw_text": "Note Linux will fault on Android, since memory mapped files(aka libraries) act as swap.", "attachment_id": null}, {"time": "2011-06-30T23:35:26Z", "creation_time": "2011-06-30T23:35:26Z", "creator": "justin.lebar+bug@gmail.com", "author": "justin.lebar+bug@gmail.com", "id": 5568569, "count": 56, "is_private": false, "tags": [], "text": "(In reply to comment #54)\n> I seriously doubt that Firefox would sit without spinning the event loop for\n> too long. I object to adding yet another reason to spin it.\n\nCould you rephrase this?", "bug_id": 664291, "attachment_id": null, "raw_text": "(In reply to comment #54)\n> I seriously doubt that Firefox would sit without spinning the event loop for\n> too long. I object to adding yet another reason to spin it.\n\nCould you rephrase this?"}, {"time": "2011-06-30T23:42:43Z", "creation_time": "2011-06-30T23:42:43Z", "creator": "justin.lebar+bug@gmail.com", "author": "justin.lebar+bug@gmail.com", "count": 57, "id": 5568584, "is_private": false, "text": "(In reply to comment #56)\n> Could you rephrase this?\n\n<jlebar> taras, You're saying that the \"idle\" state is rare in practice.\n<taras> yes\n<jlebar> taras, But that it's important that when we're in this state, we don't wake up and check to see whether we're out of memory.\n<taras> yes\n<jlebar> taras, Well, why is it so important if that state doesn't happen so often?\n<taras> it is important to not wake up too much to save power, unless you are asking something else\n<taras> so while we wake up too often as is, we should move towards waking up less often, not more\n<jlebar> taras, Okay, I buy that.  :)\n\n(In reply to comment #55)\n> Note Linux will fault on Android, since memory mapped files(aka libraries)\n> act as swap.\n\nThis contradicts dougt in comment 14:\n\n> justin - right, no swapping on most devices.  the n900/maemo had an option\n> to enable swap to sdcard, but that is generally the exception.\n\nCan you guys duke it out?", "bug_id": 664291, "tags": [], "attachment_id": null, "raw_text": "(In reply to comment #56)\n> Could you rephrase this?\n\n<jlebar> taras, You're saying that the \"idle\" state is rare in practice.\n<taras> yes\n<jlebar> taras, But that it's important that when we're in this state, we don't wake up and check to see whether we're out of memory.\n<taras> yes\n<jlebar> taras, Well, why is it so important if that state doesn't happen so often?\n<taras> it is important to not wake up too much to save power, unless you are asking something else\n<taras> so while we wake up too often as is, we should move towards waking up less often, not more\n<jlebar> taras, Okay, I buy that.  :)\n\n(In reply to comment #55)\n> Note Linux will fault on Android, since memory mapped files(aka libraries)\n> act as swap.\n\nThis contradicts dougt in comment 14:\n\n> justin - right, no swapping on most devices.  the n900/maemo had an option\n> to enable swap to sdcard, but that is generally the exception.\n\nCan you guys duke it out?"}, {"attachment_id": null, "raw_text": "(In reply to comment #57)\n\n> > justin - right, no swapping on most devices.  the n900/maemo had an option\n> > to enable swap to sdcard, but that is generally the exception.\n> \n> Can you guys duke it out?\n\nDoug said no swapping, not no paging :)", "text": "(In reply to comment #57)\n\n> > justin - right, no swapping on most devices.  the n900/maemo had an option\n> > to enable swap to sdcard, but that is generally the exception.\n> \n> Can you guys duke it out?\n\nDoug said no swapping, not no paging :)", "bug_id": 664291, "tags": [], "id": 5568599, "count": 58, "is_private": false, "creation_time": "2011-06-30T23:51:09Z", "time": "2011-06-30T23:51:09Z", "creator": "taras.mozilla@glek.net", "author": "taras.mozilla@glek.net"}, {"id": 5568634, "count": 59, "is_private": false, "author": "davemgarrett@gmail.com", "time": "2011-07-01T00:16:03Z", "creation_time": "2011-07-01T00:16:03Z", "creator": "davemgarrett@gmail.com", "raw_text": "Minor suggestion: The threshold prefs are OS-specific so it might be a good idea to #ifdef them out of all.js when not applicable so people don't see non-functioning prefs in about:config if they try to tweak these settings. (the Preferences::GetInt() calls have defaults so the rest of the usages don't really need cluttering up with #ifdefs, though)", "attachment_id": null, "text": "Minor suggestion: The threshold prefs are OS-specific so it might be a good idea to #ifdef them out of all.js when not applicable so people don't see non-functioning prefs in about:config if they try to tweak these settings. (the Preferences::GetInt() calls have defaults so the rest of the usages don't really need cluttering up with #ifdefs, though)", "bug_id": 664291, "tags": []}, {"is_private": false, "id": 5569992, "count": 60, "creator": "justin.lebar+bug@gmail.com", "creation_time": "2011-07-01T18:19:43Z", "time": "2011-07-01T18:19:43Z", "author": "justin.lebar+bug@gmail.com", "attachment_id": 543150, "raw_text": "I'll see if I can make something which wakes us up less-often.", "tags": [], "text": "Comment on attachment 543150\nPatch v2\n\nI'll see if I can make something which wakes us up less-often.", "bug_id": 664291}, {"tags": [], "bug_id": 664291, "text": "Jesse pointed out:\n\n> The Mac \"Activity Monitor\" shows a system-wide value called \"page\n> outs\". That might be useful to record along with the number of hard\n> page faults Firefox encounters. For example, if \"page outs\" is 0 (like\n> it is for me right now), then we know that none of the hard page\n> faults encountered by Firefox are the result of swapping.\n\nIt's something to look into, although at least on my computer, we don't page much after startup except when there's memory pressure.\n\nI'm starting to think that the current Windows approach (look at available bytes) makes more sense than the current *nix approach (look at page faults), since on *nix if the user\n\n 1. minimizes FF,\n 2. loads photoshop, which eats all RAM and causes FF to be paged out,\n 3. closes photoshop, freeing a bunch of ram,\n 4. reopens FF\n\nwe'll only notice memory pressure during the last step, when we get faulted back in.  But that's not the time to free up memory!", "raw_text": "Jesse pointed out:\n\n> The Mac \"Activity Monitor\" shows a system-wide value called \"page\n> outs\". That might be useful to record along with the number of hard\n> page faults Firefox encounters. For example, if \"page outs\" is 0 (like\n> it is for me right now), then we know that none of the hard page\n> faults encountered by Firefox are the result of swapping.\n\nIt's something to look into, although at least on my computer, we don't page much after startup except when there's memory pressure.\n\nI'm starting to think that the current Windows approach (look at available bytes) makes more sense than the current *nix approach (look at page faults), since on *nix if the user\n\n 1. minimizes FF,\n 2. loads photoshop, which eats all RAM and causes FF to be paged out,\n 3. closes photoshop, freeing a bunch of ram,\n 4. reopens FF\n\nwe'll only notice memory pressure during the last step, when we get faulted back in.  But that's not the time to free up memory!", "attachment_id": null, "author": "justin.lebar+bug@gmail.com", "time": "2011-07-02T15:54:47Z", "creation_time": "2011-07-02T15:54:47Z", "creator": "justin.lebar+bug@gmail.com", "count": 61, "id": 5571238, "is_private": false}, {"text": "See bug 669120 for a simpler approach which doesn't involve timer threads or heuristics.  I'm beginning to think that bug may be a better place to start, at least in terms of FF being a good citizen and not obstructing other applications' use of memory.", "bug_id": 664291, "tags": [], "raw_text": "See bug 669120 for a simpler approach which doesn't involve timer threads or heuristics.  I'm beginning to think that bug may be a better place to start, at least in terms of FF being a good citizen and not obstructing other applications' use of memory.", "attachment_id": null, "author": "justin.lebar+bug@gmail.com", "creation_time": "2011-07-04T05:18:56Z", "time": "2011-07-04T05:18:56Z", "creator": "justin.lebar+bug@gmail.com", "count": 62, "id": 5572179, "is_private": false}, {"time": "2011-07-05T15:51:50Z", "creation_time": "2011-07-05T15:51:50Z", "creator": "justin.lebar+bug@gmail.com", "author": "justin.lebar+bug@gmail.com", "id": 5574039, "count": 63, "is_private": false, "text": "I think the way forward here is:\n\n * Bug 669120 - Fire a memory-pressure event when we lose focus for X seconds.  This way, we don't have to check for low memory when we're idle.\n\n * Check for low memory using the same or a similar heuristic to the new periodic GC code.\n\nThe assumption here is that it's likely that if some other program starts using lots of memory, it'll be while we're not focused.  And this strategy doesn't involve any new timer threads.", "bug_id": 664291, "tags": [], "attachment_id": null, "raw_text": "I think the way forward here is:\n\n * Bug 669120 - Fire a memory-pressure event when we lose focus for X seconds.  This way, we don't have to check for low memory when we're idle.\n\n * Check for low memory using the same or a similar heuristic to the new periodic GC code.\n\nThe assumption here is that it's likely that if some other program starts using lots of memory, it'll be while we're not focused.  And this strategy doesn't involve any new timer threads."}, {"creator": "justin.lebar+bug@gmail.com", "creation_time": "2011-07-06T13:45:50Z", "time": "2011-07-06T13:45:50Z", "author": "justin.lebar+bug@gmail.com", "is_private": false, "id": 5576215, "count": 64, "bug_id": 664291, "text": "The GC timer is bug 656120.", "tags": [], "attachment_id": null, "raw_text": "The GC timer is bug 656120."}, {"creator": "mh+mozilla@glandium.org", "time": "2011-07-10T07:10:21Z", "creation_time": "2011-07-10T07:10:21Z", "author": "mh+mozilla@glandium.org", "is_private": false, "count": 65, "id": 5583246, "tags": [], "text": "Note that, now that I think of it, there are ways, at least on Linux, to know if the system is swapping or not, e.g. the taskstats api, which we're probably going to use to get a more accurate process startup time (and is quite painful to setup, so that part could be shared).", "bug_id": 664291, "attachment_id": null, "raw_text": "Note that, now that I think of it, there are ways, at least on Linux, to know if the system is swapping or not, e.g. the taskstats api, which we're probably going to use to get a more accurate process startup time (and is quite painful to setup, so that part could be shared)."}, {"author": "justin.lebar+bug@gmail.com", "creator": "justin.lebar+bug@gmail.com", "time": "2011-07-12T17:08:12Z", "creation_time": "2011-07-12T17:08:12Z", "is_private": false, "id": 5586891, "count": 66, "bug_id": 664291, "text": "I filed a new bug just for tracking Windows vmem: bug 670967.  It seems to me that running out of address space on Windows is the worst manifestation of this issue, and I think I may be able to address that without adding a timer thread.", "tags": [], "raw_text": "I filed a new bug just for tracking Windows vmem: bug 670967.  It seems to me that running out of address space on Windows is the worst manifestation of this issue, and I think I may be able to address that without adding a timer thread.", "attachment_id": null}, {"attachment_id": null, "raw_text": "For those following along at home, I've morphed bug 670967 into tracking both virtual and physical memory on Windows by wrapping VirtualAlloc and the other virtual allocation syscalls.", "tags": [], "bug_id": 664291, "text": "For those following along at home, I've morphed bug 670967 into tracking both virtual and physical memory on Windows by wrapping VirtualAlloc and the other virtual allocation syscalls.", "is_private": false, "id": 5597621, "count": 67, "creator": "justin.lebar+bug@gmail.com", "time": "2011-07-18T21:22:44Z", "creation_time": "2011-07-18T21:22:44Z", "author": "justin.lebar+bug@gmail.com"}, {"text": "For Windows, did you try using the CreateMemoryResourceNotification function for the LowMemoryDetector? From the MSDN description it looks to be exactly what you are looking for here. Its advantage over currently used solution is that it avoids time based polling, you can just include the returned handle in the main event loop and wait for it to become signaled.", "bug_id": 664291, "tags": [], "raw_text": "For Windows, did you try using the CreateMemoryResourceNotification function for the LowMemoryDetector? From the MSDN description it looks to be exactly what you are looking for here. Its advantage over currently used solution is that it avoids time based polling, you can just include the returned handle in the main event loop and wait for it to become signaled.", "attachment_id": null, "author": "ziga.seilnacht@gmail.com", "creation_time": "2011-08-17T19:44:06Z", "time": "2011-08-17T19:44:06Z", "creator": "ziga.seilnacht@gmail.com", "count": 68, "id": 5660540, "is_private": false}, {"is_private": false, "id": 5669695, "count": 69, "creator": "justin.lebar+bug@gmail.com", "time": "2011-08-22T18:02:14Z", "creation_time": "2011-08-22T18:02:14Z", "author": "justin.lebar+bug@gmail.com", "attachment_id": null, "raw_text": "Ah, the hidden gems of the WinAPI.  CreateMemoryResourceNotification looks like it does exactly what I'd want; thanks for pointing it out!\n\nMy current approach in bug 670967 is to watch only for low virtual memory, for reasons explained in the bug.  It doesn't look like CreateMemoryResourceNotificaiton helps here.  I'm currently watching the amount of available virtual memory by wrapping calls to VirtualAlloc and a few other functions.", "text": "Ah, the hidden gems of the WinAPI.  CreateMemoryResourceNotification looks like it does exactly what I'd want; thanks for pointing it out!\n\nMy current approach in bug 670967 is to watch only for low virtual memory, for reasons explained in the bug.  It doesn't look like CreateMemoryResourceNotificaiton helps here.  I'm currently watching the amount of available virtual memory by wrapping calls to VirtualAlloc and a few other functions.", "bug_id": 664291, "tags": []}, {"attachment_id": 581179, "raw_text": "", "tags": [], "bug_id": 664291, "text": "Created attachment 581179\nRev 2, part 3 v1: Pass env var when running PGO-instrumented build", "id": 5911408, "count": 70, "is_private": false, "time": "2011-12-13T06:01:59Z", "creation_time": "2011-12-13T06:01:59Z", "creator": "justin.lebar+bug@gmail.com", "author": "justin.lebar+bug@gmail.com"}, {"tags": [], "text": "Comment on attachment 581179\nRev 2, part 3 v1: Pass env var when running PGO-instrumented build\n\nOops; wrong bug.", "bug_id": 664291, "raw_text": "Oops; wrong bug.", "attachment_id": 581179, "author": "justin.lebar+bug@gmail.com", "creator": "justin.lebar+bug@gmail.com", "time": "2011-12-13T06:07:58Z", "creation_time": "2011-12-13T06:07:58Z", "is_private": false, "id": 5911416, "count": 71}, {"raw_text": "jlebar, can you remind me how this bug relates to bug 670967?  Is this bug now only for Mac and Linux?", "attachment_id": null, "tags": [], "bug_id": 664291, "text": "jlebar, can you remind me how this bug relates to bug 670967?  Is this bug now only for Mac and Linux?", "is_private": false, "count": 72, "id": 5922848, "author": "n.nethercote@gmail.com", "creator": "n.nethercote@gmail.com", "creation_time": "2011-12-16T20:03:26Z", "time": "2011-12-16T20:03:26Z"}, {"bug_id": 664291, "text": "> Is this bug now only for Mac and Linux?\n\nRight.", "tags": [], "raw_text": "> Is this bug now only for Mac and Linux?\n\nRight.", "attachment_id": null, "author": "justin.lebar+bug@gmail.com", "creator": "justin.lebar+bug@gmail.com", "creation_time": "2011-12-16T20:08:53Z", "time": "2011-12-16T20:08:53Z", "is_private": false, "count": 73, "id": 5922862}, {"id": 6018074, "count": 74, "is_private": false, "author": "n.nethercote@gmail.com", "creation_time": "2012-01-29T20:07:08Z", "time": "2012-01-29T20:07:08Z", "creator": "n.nethercote@gmail.com", "raw_text": "http://stackoverflow.com/questions/3019748/how-to-reliably-measure-available-memory-in-linux/ has some interesting info about detecting low memory on Linux.", "attachment_id": null, "text": "http://stackoverflow.com/questions/3019748/how-to-reliably-measure-available-memory-in-linux/ has some interesting info about detecting low memory on Linux.", "bug_id": 664291, "tags": []}]}}}