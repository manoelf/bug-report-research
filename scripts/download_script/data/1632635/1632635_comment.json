{"bugs": {"1632635": {"comments": [{"attachment_id": null, "author": "fbertsch@mozilla.com", "id": 14774823, "text": "As an org we're sending more events to Amplitude than we expected when we signed the contract last year. This bug is specifically for FxA, and understanding the \"cert_signed\" event, which accounts for ~23% of the total number of events we send to Amplitude.\n\nLeif, can you describe what this event is, and if there could be a way to reduce the volume that it's being sent?", "is_private": false, "bug_id": 1632635, "raw_text": "As an org we're sending more events to Amplitude than we expected when we signed the contract last year. This bug is specifically for FxA, and understanding the \"cert_signed\" event, which accounts for ~23% of the total number of events we send to Amplitude.\n\nLeif, can you describe what this event is, and if there could be a way to reduce the volume that it's being sent?", "creation_time": "2020-04-23T20:17:23Z", "count": 0, "tags": [], "time": "2020-04-23T20:17:23Z", "creator": "fbertsch@mozilla.com"}, {"creation_time": "2020-04-23T20:57:56Z", "text": "The event is fired periodically for authenticated and verified sync users on desktop, fennec and ios. It is fired whenever a client hits [this endpoint](https://github.com/mozilla/fxa/blob/master/packages/fxa-auth-server/docs/api.md#post-certificatesign) on the FxA auth server. See also [this](https://github.com/mozilla/fxa-auth-server/wiki/onepw-protocol#signing-certificates). \n\nMy understanding (not an engineer) is that Sync periodically needs to refresh this certificate in order to receive a token from the sync token server that will allow it to continue syncing. \n\nThis is one of only two server-side events that are reliably generated and that will let us infer whether a client is still syncing. The other events are the creation and checking of oauth tokens, which are of even higher volume and which we already filter out before they are sent to amplitude. As such it is the primary event that contributes to measures of FxA/Sync DAU and MAU (a user that syncs at least once on a given day should almost always generate one of these events). I know Alex is critically reliant on it for daily monitoring of our metrics. \n\nThe FxA team is aware that this is a costly event due to its volume. We are actively exploring ways to sample it, see bug 1592123. \n\nCC Jared and Alex", "count": 1, "raw_text": "The event is fired periodically for authenticated and verified sync users on desktop, fennec and ios. It is fired whenever a client hits [this endpoint](https://github.com/mozilla/fxa/blob/master/packages/fxa-auth-server/docs/api.md#post-certificatesign) on the FxA auth server. See also [this](https://github.com/mozilla/fxa-auth-server/wiki/onepw-protocol#signing-certificates). \n\nMy understanding (not an engineer) is that Sync periodically needs to refresh this certificate in order to receive a token from the sync token server that will allow it to continue syncing. \n\nThis is one of only two server-side events that are reliably generated and that will let us infer whether a client is still syncing. The other events are the creation and checking of oauth tokens, which are of even higher volume and which we already filter out before they are sent to amplitude. As such it is the primary event that contributes to measures of FxA/Sync DAU and MAU (a user that syncs at least once on a given day should almost always generate one of these events). I know Alex is critically reliant on it for daily monitoring of our metrics. \n\nThe FxA team is aware that this is a costly event due to its volume. We are actively exploring ways to sample it, see bug 1592123. \n\nCC Jared and Alex", "attachment_id": null, "id": 14774917, "author": "loines@mozilla.com", "creator": "loines@mozilla.com", "time": "2020-04-23T20:57:56Z", "tags": [], "is_private": false, "bug_id": 1632635}, {"id": 14775000, "author": "fbertsch@mozilla.com", "attachment_id": null, "text": "Hey Jared and Jon, we tentatively came up with the idea of sending a single `cert_signed` event per-user at EOD instead of real-time. I have no knowledge of the current pipeline to Amplitude, but Leif has indicated that it's tailed server logs -> Pubsub -> Amplitude HTTP API.\n\nDo either of you have any idea if this is feasible? It would essentially move processing these events to a batch job, and aggregating per-client. My guess is this is too much data to possibly do on one node, so we'd need something like BQ as an intermediate to do that processing. Once we've aggregated, we could use the same pipeline you already do and push the data to Pubsub and then to Amplitude, hopefully resulting in the same schema with minimal work.\n\nWe also need to be clear about which metrics and plots this may affect for any real-time, or daily, visualizations you all use. Any single-event counts should be unaffected, but general user-counting wouldn't be available until EOD. Similarly, retention would be low until these events are sent.", "is_private": false, "bug_id": 1632635, "raw_text": "Hey Jared and Jon, we tentatively came up with the idea of sending a single `cert_signed` event per-user at EOD instead of real-time. I have no knowledge of the current pipeline to Amplitude, but Leif has indicated that it's tailed server logs -> Pubsub -> Amplitude HTTP API.\n\nDo either of you have any idea if this is feasible? It would essentially move processing these events to a batch job, and aggregating per-client. My guess is this is too much data to possibly do on one node, so we'd need something like BQ as an intermediate to do that processing. Once we've aggregated, we could use the same pipeline you already do and push the data to Pubsub and then to Amplitude, hopefully resulting in the same schema with minimal work.\n\nWe also need to be clear about which metrics and plots this may affect for any real-time, or daily, visualizations you all use. Any single-event counts should be unaffected, but general user-counting wouldn't be available until EOD. Similarly, retention would be low until these events are sent.", "count": 2, "creation_time": "2020-04-23T21:42:38Z", "tags": [], "time": "2020-04-23T21:42:38Z", "creator": "fbertsch@mozilla.com"}, {"time": "2020-04-23T21:46:48Z", "creator": "fbertsch@mozilla.com", "tags": [], "creation_time": "2020-04-23T21:46:48Z", "count": 3, "raw_text": "The idea outlined in Comment 2 would reduce the number of events monthly from ~1.4B to ~250M, a reduction of about 1150M, or about a 19% reduction in total events we send to Amplitude.", "bug_id": 1632635, "is_private": false, "text": "The idea outlined in Comment 2 would reduce the number of events monthly from ~1.4B to ~250M, a reduction of about 1150M, or about a 19% reduction in total events we send to Amplitude.", "attachment_id": null, "id": 14775039, "author": "fbertsch@mozilla.com"}, {"raw_text": "> The other events are the creation and checking of oauth tokens, which are of even higher volume and which we already filter out\n> before they are sent to amplitude.\n\nI wanted to chime in here to mention, the fact that we filter these out in Desktop is shaping up to be a blocker for some client-side work the sync team is doing, because we want to move away using BrowserID assertions (which generate cert-signed events) and towards OAuth tokens (which generate oauth-related events). See e.g. Bug 1591312 where we had to back out some work that was heading in that direction, because it would have meant some users disappearing from our MAU.\n\nFrom my perspective, an ideal solution would send a single `activity` event per user at EOD, encompassing both `cert_signed` and `token_created` events. I don't think we particularly need the ability to distinguish *which* event it was, only that some FxA-related activity was registered for that user no that day.", "count": 4, "creation_time": "2020-04-24T01:20:49Z", "tags": [], "time": "2020-04-24T01:20:49Z", "creator": "ryan@rfk.id.au", "author": "ryan@rfk.id.au", "id": 14775343, "attachment_id": null, "text": "> The other events are the creation and checking of oauth tokens, which are of even higher volume and which we already filter out\n> before they are sent to amplitude.\n\nI wanted to chime in here to mention, the fact that we filter these out in Desktop is shaping up to be a blocker for some client-side work the sync team is doing, because we want to move away using BrowserID assertions (which generate cert-signed events) and towards OAuth tokens (which generate oauth-related events). See e.g. Bug 1591312 where we had to back out some work that was heading in that direction, because it would have meant some users disappearing from our MAU.\n\nFrom my perspective, an ideal solution would send a single `activity` event per user at EOD, encompassing both `cert_signed` and `token_created` events. I don't think we particularly need the ability to distinguish *which* event it was, only that some FxA-related activity was registered for that user no that day.", "is_private": false, "bug_id": 1632635}, {"tags": [], "creator": "jklukas@mozilla.com", "time": "2020-04-24T13:36:34Z", "raw_text": "This sounds like it would be _almost_ be trivial to implement. All FxA event logs are already sent to BigQuery via a Stackdriver integration, and Airflow has permission to query those tables. Our FxA KPI reporting is based on a series of queries that hit these Stackdriver-created tables, and it sounds desirable that we'd send exactly the same set of users to Amplitude as what we consider active for KPIs.\n\nThe difficult thing here is that FxA IDs are hashed using an HMAC key before being sent to Amplitude. The logs in BigQuery have the raw IDs. This is a problem we keep running into in discussing various FxA metrics tasks.\n\nIt may be worth at this point considering whether we could make the HMAC key available for Airflow to access. If we did that, we could build a Docker container that would be able to do the same HMAC hashing that the FxA pipeline does. It would pull the list of active IDs for the day via BQ query to the Stackdriver log tables, HMAC them, and write the results to S3 for Amplitude to ingest. We then might be able to reuse that pattern for some other tasks in the FxA metrics migration.", "creation_time": "2020-04-24T13:36:34Z", "count": 5, "is_private": false, "bug_id": 1632635, "attachment_id": null, "id": 14776325, "author": "jklukas@mozilla.com", "text": "This sounds like it would be _almost_ be trivial to implement. All FxA event logs are already sent to BigQuery via a Stackdriver integration, and Airflow has permission to query those tables. Our FxA KPI reporting is based on a series of queries that hit these Stackdriver-created tables, and it sounds desirable that we'd send exactly the same set of users to Amplitude as what we consider active for KPIs.\n\nThe difficult thing here is that FxA IDs are hashed using an HMAC key before being sent to Amplitude. The logs in BigQuery have the raw IDs. This is a problem we keep running into in discussing various FxA metrics tasks.\n\nIt may be worth at this point considering whether we could make the HMAC key available for Airflow to access. If we did that, we could build a Docker container that would be able to do the same HMAC hashing that the FxA pipeline does. It would pull the list of active IDs for the day via BQ query to the Stackdriver log tables, HMAC them, and write the results to S3 for Amplitude to ingest. We then might be able to reuse that pattern for some other tasks in the FxA metrics migration."}, {"id": 14776349, "author": "fbertsch@mozilla.com", "attachment_id": null, "text": "> It may be worth at this point considering whether we could make the HMAC key available for Airflow to access. If we did that, we could build a Docker container that would be able to do the same HMAC hashing that the FxA pipeline does. It would pull the list of active IDs for the day via BQ query to the Stackdriver log tables, HMAC them, and write the results to S3 for Amplitude to ingest. We then might be able to reuse that pattern for some other tasks in the FxA metrics migration.\n\nIf having the HMAC available to Airflow is a blocker at all, we can push to pub/sub from BQ and use their existing pipeline to load the data. Who do we need to get permission from to enable that key use on our end?", "is_private": false, "bug_id": 1632635, "raw_text": "> It may be worth at this point considering whether we could make the HMAC key available for Airflow to access. If we did that, we could build a Docker container that would be able to do the same HMAC hashing that the FxA pipeline does. It would pull the list of active IDs for the day via BQ query to the Stackdriver log tables, HMAC them, and write the results to S3 for Amplitude to ingest. We then might be able to reuse that pattern for some other tasks in the FxA metrics migration.\n\nIf having the HMAC available to Airflow is a blocker at all, we can push to pub/sub from BQ and use their existing pipeline to load the data. Who do we need to get permission from to enable that key use on our end?", "count": 6, "creation_time": "2020-04-24T13:44:23Z", "tags": [], "time": "2020-04-24T13:44:23Z", "creator": "fbertsch@mozilla.com"}, {"bug_id": 1632635, "is_private": false, "tags": [], "creator": "jklukas@mozilla.com", "time": "2020-04-24T13:58:19Z", "id": 14776361, "author": "jklukas@mozilla.com", "raw_text": "> If having the HMAC available to Airflow is a blocker at all, we can push to pub/sub from BQ and use their existing pipeline to load the data.\n\nWe have been essentially relying on that pattern for some other pieces of the FxA migration work. This may indeed be an option.\n\n> Who do we need to get permission from to enable that key use on our end?\n\njbuck may have some good context on that, and perhaps :rfkelly. I really don't know how to reason about the risk surrounding giving enhanced access to that key.", "attachment_id": null, "count": 7, "text": "> If having the HMAC available to Airflow is a blocker at all, we can push to pub/sub from BQ and use their existing pipeline to load the data.\n\nWe have been essentially relying on that pattern for some other pieces of the FxA migration work. This may indeed be an option.\n\n> Who do we need to get permission from to enable that key use on our end?\n\njbuck may have some good context on that, and perhaps :rfkelly. I really don't know how to reason about the risk surrounding giving enhanced access to that key.", "creation_time": "2020-04-24T13:58:19Z"}, {"attachment_id": null, "id": 14776480, "author": "loines@mozilla.com", "text": "(In reply to Ryan Kelly [:rfkelly] from comment #4)\n> From my perspective, an ideal solution would send a single `activity` event per user at EOD, encompassing both `cert_signed` and `token_created` events. I don't think we particularly need the ability to distinguish *which* event it was, only that some FxA-related activity was registered for that user no that day.\n\n+1 we should definitely do this", "bug_id": 1632635, "is_private": false, "raw_text": "(In reply to Ryan Kelly [:rfkelly] from comment #4)\n> From my perspective, an ideal solution would send a single `activity` event per user at EOD, encompassing both `cert_signed` and `token_created` events. I don't think we particularly need the ability to distinguish *which* event it was, only that some FxA-related activity was registered for that user no that day.\n\n+1 we should definitely do this", "creation_time": "2020-04-24T14:51:29Z", "count": 8, "tags": [], "time": "2020-04-24T14:51:29Z", "creator": "loines@mozilla.com"}, {"time": "2020-04-24T14:52:44Z", "creator": "fbertsch@mozilla.com", "is_private": false, "bug_id": 1632635, "tags": [], "count": 9, "text": "> > From my perspective, an ideal solution would send a single `activity` event per user at EOD, encompassing both `cert_signed` and `token_created` events. I don't think we particularly need the ability to distinguish *which* event it was, only that some FxA-related activity was registered for that user no that day.\n> \n> +1 we should definitely do this\n\nAre we already getting the `token_created` events from Stackdriver? If so that would be almost no additional work on top of what we're already looking at here.", "creation_time": "2020-04-24T14:52:44Z", "author": "fbertsch@mozilla.com", "id": 14776482, "raw_text": "> > From my perspective, an ideal solution would send a single `activity` event per user at EOD, encompassing both `cert_signed` and `token_created` events. I don't think we particularly need the ability to distinguish *which* event it was, only that some FxA-related activity was registered for that user no that day.\n> \n> +1 we should definitely do this\n\nAre we already getting the `token_created` events from Stackdriver? If so that would be almost no additional work on top of what we're already looking at here.", "attachment_id": null}, {"count": 10, "creation_time": "2020-04-24T14:53:52Z", "raw_text": "> > If having the HMAC available to Airflow is a blocker at all, we can push to pub/sub from BQ and use their existing pipeline to load the data.\n> \n> We have been essentially relying on that pattern for some other pieces of the FxA migration work. This may indeed be an option.\n> \n> > Who do we need to get permission from to enable that key use on our end?\n> \n> jbuck may have some good context on that, and perhaps :rfkelly. I really don't know how to reason about the risk surrounding giving enhanced access to that key.\n\nRyan, do you have any context on the issues about making the HMAC key available to our Airflow instance?", "time": "2020-04-24T14:53:52Z", "creator": "fbertsch@mozilla.com", "tags": [], "text": "> > If having the HMAC available to Airflow is a blocker at all, we can push to pub/sub from BQ and use their existing pipeline to load the data.\n> \n> We have been essentially relying on that pattern for some other pieces of the FxA migration work. This may indeed be an option.\n> \n> > Who do we need to get permission from to enable that key use on our end?\n> \n> jbuck may have some good context on that, and perhaps :rfkelly. I really don't know how to reason about the risk surrounding giving enhanced access to that key.\n\nRyan, do you have any context on the issues about making the HMAC key available to our Airflow instance?", "id": 14776485, "author": "fbertsch@mozilla.com", "attachment_id": null, "bug_id": 1632635, "is_private": false}, {"count": 11, "creation_time": "2020-04-24T14:59:53Z", "raw_text": "Updating the bug title to more accurately represent current conversation.", "creator": "fbertsch@mozilla.com", "time": "2020-04-24T14:59:53Z", "tags": [], "text": "Updating the bug title to more accurately represent current conversation.", "id": 14776498, "author": "fbertsch@mozilla.com", "attachment_id": null, "bug_id": 1632635, "is_private": false}, {"raw_text": "(In reply to Frank Bertsch [:frank] from comment #9)\n> > > From my perspective, an ideal solution would send a single `activity` event per user at EOD, encompassing both `cert_signed` and `token_created` events. I don't think we particularly need the ability to distinguish *which* event it was, only that some FxA-related activity was registered for that user no that day.\n> > \n> > +1 we should definitely do this\n> \n> Are we already getting the `token_created` events from Stackdriver? If so that would be almost no additional work on top of what we're already looking at here.\n\nYes they are already there. We just ignore them when sending to amplitude currently, so we would just need to remove that filter.", "count": 12, "creation_time": "2020-04-24T15:29:47Z", "tags": [], "creator": "loines@mozilla.com", "time": "2020-04-24T15:29:47Z", "id": 14776551, "author": "loines@mozilla.com", "attachment_id": null, "text": "(In reply to Frank Bertsch [:frank] from comment #9)\n> > > From my perspective, an ideal solution would send a single `activity` event per user at EOD, encompassing both `cert_signed` and `token_created` events. I don't think we particularly need the ability to distinguish *which* event it was, only that some FxA-related activity was registered for that user no that day.\n> > \n> > +1 we should definitely do this\n> \n> Are we already getting the `token_created` events from Stackdriver? If so that would be almost no additional work on top of what we're already looking at here.\n\nYes they are already there. We just ignore them when sending to amplitude currently, so we would just need to remove that filter.", "is_private": false, "bug_id": 1632635}, {"count": 13, "creation_time": "2020-04-27T14:46:12Z", "raw_text": "Hey all, we're hoping to move quickly on this, so responses are appreciated. The current plan is the following:\n\n1. Create a new table, derived from the FxA data in BQ, that groups by user-days and filters to `cert_signed` and `token_created` [0]. For every active day (derived from the `timestamp` field [1]), we will derived a single event for every user, with name `fxa_activity - active`. We will omit the event properties `oauth_client_id` and `service` from the events.\n2. Create a job to send this data to an FxA vacuum, where it will be loaded into the FxA project. This requires working with Amplitude to get that set up.\n3. Once we've confirmed the user count numbers for the new `fx_activity - active` event, we can have the FxA pipeline stop sending the `cert_created` event. There will be some overlap in time where both are sent, but that is acceptable from an analysis perspective.\n\n**Note**: This plan can probably be acted on quickly but requires us to hash the user ids in the same way as the current FxA pipeline does. We are still waiting on confirmation from the FxA team on whether that is possible.\n\n[0] This filtering isn't strictly required. We could use _all_ events and send a single \"activity\" per-user per-day, encompassing any activity.\n[1] `Timestamp` is a bit nebulous. Looking over the tables, I see a `timestamp` field, in addition to a `receiveTimestamp` field. There is a slight delay from `timestamp` -> `recieveTimestamp`. Because the table is partitioned on `timestamp`, I want to ensure we won't miss any activity when `timestamp` and `recieveTimestamp` occur on different dates, where a day boundary occurs between the two.", "time": "2020-04-27T14:46:12Z", "creator": "fbertsch@mozilla.com", "tags": [], "text": "Hey all, we're hoping to move quickly on this, so responses are appreciated. The current plan is the following:\n\n1. Create a new table, derived from the FxA data in BQ, that groups by user-days and filters to `cert_signed` and `token_created` [0]. For every active day (derived from the `timestamp` field [1]), we will derived a single event for every user, with name `fxa_activity - active`. We will omit the event properties `oauth_client_id` and `service` from the events.\n2. Create a job to send this data to an FxA vacuum, where it will be loaded into the FxA project. This requires working with Amplitude to get that set up.\n3. Once we've confirmed the user count numbers for the new `fx_activity - active` event, we can have the FxA pipeline stop sending the `cert_created` event. There will be some overlap in time where both are sent, but that is acceptable from an analysis perspective.\n\n**Note**: This plan can probably be acted on quickly but requires us to hash the user ids in the same way as the current FxA pipeline does. We are still waiting on confirmation from the FxA team on whether that is possible.\n\n[0] This filtering isn't strictly required. We could use _all_ events and send a single \"activity\" per-user per-day, encompassing any activity.\n[1] `Timestamp` is a bit nebulous. Looking over the tables, I see a `timestamp` field, in addition to a `receiveTimestamp` field. There is a slight delay from `timestamp` -> `recieveTimestamp`. Because the table is partitioned on `timestamp`, I want to ensure we won't miss any activity when `timestamp` and `recieveTimestamp` occur on different dates, where a day boundary occurs between the two.", "author": "fbertsch@mozilla.com", "id": 14781717, "attachment_id": null, "is_private": false, "bug_id": 1632635}, {"raw_text": "Couple questions - \n\n1. There is also an `fxa_activity - access_token_checked` amplitude event. Can we add that to the list of events that get sent to the vacuum? This may not be *strictly* necessary, as most clients that generate this event also generate `fxa_activity - access_token_created`, but I believe there are some cases where a client might only generate the `checked` event on a given day, which would cause them not to be counted towards DAU if we omit it. I will double check to see how often this happens (client sends one event but not the other). \n\n2. Is there a plan for adding back in the service and oauth client_id event properties? E.g. could we take the `set` of all the unique values associated with the activity events for a given user-day, and send them as arrays under the `service` / `oauth_client_id` event properties for the rollup event? They are kind of important for segmenting DAU by service. The docs seem to indicate that this at least possible for the HTTP API: https://help.amplitude.com/hc/en-us/articles/204771828-HTTP-API (see the example for `event_properties`) So for example if a user generated a cert signed event for sync and an access token event for monitor we would do something like \n\n`{\"service\": [\"sync\", \"fx-monitor\"],\"oauth_client_id\":[\"802d56ef2a9af9fa\"]}`\n\n(note the `sync` service does not have an `oauth_client_id`)", "creation_time": "2020-04-27T15:12:22Z", "count": 14, "tags": [], "creator": "loines@mozilla.com", "time": "2020-04-27T15:12:22Z", "attachment_id": null, "author": "loines@mozilla.com", "id": 14781781, "text": "Couple questions - \n\n1. There is also an `fxa_activity - access_token_checked` amplitude event. Can we add that to the list of events that get sent to the vacuum? This may not be *strictly* necessary, as most clients that generate this event also generate `fxa_activity - access_token_created`, but I believe there are some cases where a client might only generate the `checked` event on a given day, which would cause them not to be counted towards DAU if we omit it. I will double check to see how often this happens (client sends one event but not the other). \n\n2. Is there a plan for adding back in the service and oauth client_id event properties? E.g. could we take the `set` of all the unique values associated with the activity events for a given user-day, and send them as arrays under the `service` / `oauth_client_id` event properties for the rollup event? They are kind of important for segmenting DAU by service. The docs seem to indicate that this at least possible for the HTTP API: https://help.amplitude.com/hc/en-us/articles/204771828-HTTP-API (see the example for `event_properties`) So for example if a user generated a cert signed event for sync and an access token event for monitor we would do something like \n\n`{\"service\": [\"sync\", \"fx-monitor\"],\"oauth_client_id\":[\"802d56ef2a9af9fa\"]}`\n\n(note the `sync` service does not have an `oauth_client_id`)", "bug_id": 1632635, "is_private": false}, {"attachment_id": null, "author": "fbertsch@mozilla.com", "id": 14781816, "text": "> 1. There is also an `fxa_activity - access_token_checked` amplitude event. Can we add that to the list of events that get sent to the vacuum? This may not be *strictly* necessary, as most clients that generate this event also generate `fxa_activity - access_token_created`, but I believe there are some cases where a client might only generate the `checked` event on a given day, which would cause them not to be counted towards DAU if we omit it. I will double check to see how often this happens (client sends one event but not the other). \n\nDefinitely. I mentioned in [0] that we could actually remove any filtering, so that this `active` event would encompass any activity. I'm not sure how that would play with the event_properties discussed below, though (if e.g. those events are sending different services).\n\n> 2. Is there a plan for adding back in the service and oauth client_id event properties? E.g. could we take the `set` of all the unique values associated with the activity events for a given user-day, and send them as arrays under the `service` / `oauth_client_id` event properties for the rollup event? They are kind of important for segmenting DAU by service. The docs seem to indicate that this at least possible for the HTTP API: https://help.amplitude.com/hc/en-us/articles/204771828-HTTP-API (see the example for `event_properties`) So for example if a user generated a cert signed event for sync and an access token event for monitor we would do something like \n> \n> `{\"service\": [\"sync\", \"fx-monitor\"],\"oauth_client_id\":[\"802d56ef2a9af9fa\"]}`\n\nWe can definitely add these back in. It sounds like we would aggregate all services and all oath_client_id, taking the unique set for each. Does this sound like the right approach, Leif?", "bug_id": 1632635, "is_private": false, "raw_text": "> 1. There is also an `fxa_activity - access_token_checked` amplitude event. Can we add that to the list of events that get sent to the vacuum? This may not be *strictly* necessary, as most clients that generate this event also generate `fxa_activity - access_token_created`, but I believe there are some cases where a client might only generate the `checked` event on a given day, which would cause them not to be counted towards DAU if we omit it. I will double check to see how often this happens (client sends one event but not the other). \n\nDefinitely. I mentioned in [0] that we could actually remove any filtering, so that this `active` event would encompass any activity. I'm not sure how that would play with the event_properties discussed below, though (if e.g. those events are sending different services).\n\n> 2. Is there a plan for adding back in the service and oauth client_id event properties? E.g. could we take the `set` of all the unique values associated with the activity events for a given user-day, and send them as arrays under the `service` / `oauth_client_id` event properties for the rollup event? They are kind of important for segmenting DAU by service. The docs seem to indicate that this at least possible for the HTTP API: https://help.amplitude.com/hc/en-us/articles/204771828-HTTP-API (see the example for `event_properties`) So for example if a user generated a cert signed event for sync and an access token event for monitor we would do something like \n> \n> `{\"service\": [\"sync\", \"fx-monitor\"],\"oauth_client_id\":[\"802d56ef2a9af9fa\"]}`\n\nWe can definitely add these back in. It sounds like we would aggregate all services and all oath_client_id, taking the unique set for each. Does this sound like the right approach, Leif?", "creation_time": "2020-04-27T15:23:40Z", "count": 15, "tags": [], "time": "2020-04-27T15:23:40Z", "creator": "fbertsch@mozilla.com"}, {"count": 16, "creation_time": "2020-04-27T15:28:40Z", "raw_text": "I don't think we need to fret about the event_type -> service mappings, all services except sync can occur with both types of `access_token` events and the vast majority of `cert_signed` events are just sync. By aggregating the services and event properties we lose information about what event type was originally associated with what service, but that is not important for analysis. \n\nYour intuition about how to aggregate the service and oauth_client_id fields is correct.", "creator": "loines@mozilla.com", "time": "2020-04-27T15:28:40Z", "tags": [], "text": "I don't think we need to fret about the event_type -> service mappings, all services except sync can occur with both types of `access_token` events and the vast majority of `cert_signed` events are just sync. By aggregating the services and event properties we lose information about what event type was originally associated with what service, but that is not important for analysis. \n\nYour intuition about how to aggregate the service and oauth_client_id fields is correct.", "author": "loines@mozilla.com", "id": 14781827, "attachment_id": null, "is_private": false, "bug_id": 1632635}, {"is_private": false, "bug_id": 1632635, "attachment_id": null, "author": "loines@mozilla.com", "id": 14781896, "text": "I was too fast to submit my last comment:\n\nI think it would be useful to also aggregate the following user properties in a similar way:\n\n`sync_active_devices_*` (day, week, month), `sync_device_count`. \n\nIf possible we should also aggregate `fxa_services_used` and then update it using `$postInsert` as [documented here](https://help.amplitude.com/hc/en-us/articles/205406617-Identify-API-Modify-User-Properties). Although :jbuck & :_6a68 - this `postInsert` function is only available using the identify API - would that be a problem for us?\n\nIdeally we would also do something similar for `OS`, `Language`, `Country` but reading between the lines [here](https://help.amplitude.com/hc/en-us/articles/204771828-HTTP-API) it doesn't appear we'll be able to do that, which is a shame. It means that we will no longer be able to use the activity events to know which e.g. OS users were active on in a given day, e.g. if they were active on both mobile and desktop. We can still use other events to answer these types of questions, but its not ideal. Maybe as a fast follow we could introduce a new event property like `os_used_on_day` or `activity_event_os_array` and set-aggregate like above.", "tags": [], "creator": "loines@mozilla.com", "time": "2020-04-27T15:49:53Z", "raw_text": "I was too fast to submit my last comment:\n\nI think it would be useful to also aggregate the following user properties in a similar way:\n\n`sync_active_devices_*` (day, week, month), `sync_device_count`. \n\nIf possible we should also aggregate `fxa_services_used` and then update it using `$postInsert` as [documented here](https://help.amplitude.com/hc/en-us/articles/205406617-Identify-API-Modify-User-Properties). Although :jbuck & :_6a68 - this `postInsert` function is only available using the identify API - would that be a problem for us?\n\nIdeally we would also do something similar for `OS`, `Language`, `Country` but reading between the lines [here](https://help.amplitude.com/hc/en-us/articles/204771828-HTTP-API) it doesn't appear we'll be able to do that, which is a shame. It means that we will no longer be able to use the activity events to know which e.g. OS users were active on in a given day, e.g. if they were active on both mobile and desktop. We can still use other events to answer these types of questions, but its not ideal. Maybe as a fast follow we could introduce a new event property like `os_used_on_day` or `activity_event_os_array` and set-aggregate like above.", "creation_time": "2020-04-27T15:49:53Z", "count": 17}, {"author": "jbuckley@mozilla.com", "id": 14782176, "attachment_id": null, "text": "(In reply to Frank Bertsch [:frank] from comment #13)\n> 3. Once we've confirmed the user count numbers for the new `fx_activity - active` event, we can have the FxA pipeline stop sending the `cert_created` event. There will be some overlap in time where both are sent, but that is acceptable from an analysis perspective.\n\nI can stop the flow of the original events whenever - just need to change the filter being used on the FxA side\n\n> **Note**: This plan can probably be acted on quickly but requires us to hash the user ids in the same way as the current FxA pipeline does. We are still waiting on confirmation from the FxA team on whether that is possible.\n\nI can provide the HMAC key to you, can you talk about access control once it's been loaded into the Airflow cluster? I know HMAC's are one-way, but if the key is only visible to ops folks that would be ideal.\n\n> [1] `Timestamp` is a bit nebulous. Looking over the tables, I see a `timestamp` field, in addition to a `receiveTimestamp` field. There is a slight delay from `timestamp` -> `recieveTimestamp`. Because the table is partitioned on `timestamp`, I want to ensure we won't miss any activity when `timestamp` and `recieveTimestamp` occur on different dates, where a day boundary occurs between the two.\n\nIn fxa-amplitude-send we use the `jsonPayload.Fields.time` field when sending data to Amplitude, which I think corresponds to the `timestamp` field.", "bug_id": 1632635, "is_private": false, "raw_text": "(In reply to Frank Bertsch [:frank] from comment #13)\n> 3. Once we've confirmed the user count numbers for the new `fx_activity - active` event, we can have the FxA pipeline stop sending the `cert_created` event. There will be some overlap in time where both are sent, but that is acceptable from an analysis perspective.\n\nI can stop the flow of the original events whenever - just need to change the filter being used on the FxA side\n\n> **Note**: This plan can probably be acted on quickly but requires us to hash the user ids in the same way as the current FxA pipeline does. We are still waiting on confirmation from the FxA team on whether that is possible.\n\nI can provide the HMAC key to you, can you talk about access control once it's been loaded into the Airflow cluster? I know HMAC's are one-way, but if the key is only visible to ops folks that would be ideal.\n\n> [1] `Timestamp` is a bit nebulous. Looking over the tables, I see a `timestamp` field, in addition to a `receiveTimestamp` field. There is a slight delay from `timestamp` -> `recieveTimestamp`. Because the table is partitioned on `timestamp`, I want to ensure we won't miss any activity when `timestamp` and `recieveTimestamp` occur on different dates, where a day boundary occurs between the two.\n\nIn fxa-amplitude-send we use the `jsonPayload.Fields.time` field when sending data to Amplitude, which I think corresponds to the `timestamp` field.", "count": 18, "creation_time": "2020-04-27T17:51:59Z", "tags": [], "time": "2020-04-27T17:51:59Z", "creator": "jbuckley@mozilla.com"}, {"count": 19, "creation_time": "2020-04-27T18:34:45Z", "raw_text": "> I can stop the flow of the original events whenever - just need to change the filter being used on the FxA side\n\nPerfect, we'll plan on that once this work is ready.\n\n> I can provide the HMAC key to you, can you talk about access control once it's been loaded into the Airflow cluster? I know HMAC's are one-way, but if the key is only visible to ops folks that would be ideal.\n\nYes, it should be. You can get in contact with Harold (cc'ed him here) to get the key added to [Airflow](workflow.telemetry.mozilla.org). Once there it is not even visible to admins if stored as a secret, and we can still pass it in as a param to the query.\n\n> In fxa-amplitude-send we use the `jsonPayload.Fields.time` field when sending data to Amplitude, which I think corresponds to the `timestamp` field.\n\nGreat, we'll continue to do this.", "creator": "fbertsch@mozilla.com", "time": "2020-04-27T18:34:45Z", "tags": [], "text": "> I can stop the flow of the original events whenever - just need to change the filter being used on the FxA side\n\nPerfect, we'll plan on that once this work is ready.\n\n> I can provide the HMAC key to you, can you talk about access control once it's been loaded into the Airflow cluster? I know HMAC's are one-way, but if the key is only visible to ops folks that would be ideal.\n\nYes, it should be. You can get in contact with Harold (cc'ed him here) to get the key added to [Airflow](workflow.telemetry.mozilla.org). Once there it is not even visible to admins if stored as a secret, and we can still pass it in as a param to the query.\n\n> In fxa-amplitude-send we use the `jsonPayload.Fields.time` field when sending data to Amplitude, which I think corresponds to the `timestamp` field.\n\nGreat, we'll continue to do this.", "author": "fbertsch@mozilla.com", "id": 14782286, "attachment_id": null, "is_private": false, "bug_id": 1632635}, {"bug_id": 1632635, "is_private": false, "tags": [], "time": "2020-04-27T19:47:34Z", "creator": "fbertsch@mozilla.com", "author": "fbertsch@mozilla.com", "id": 14782411, "raw_text": "(In reply to Leif Oines [:loines] from comment #17)\n> I was too fast to submit my last comment:\n> \n> I think it would be useful to also aggregate the following user properties in a similar way:\n> \n> `sync_active_devices_*` (day, week, month), `sync_device_count`. \n\nLeif, are these user properties filled in currently from the `cert_signed` event? If so, we will indeed need to send those along with the events.\n\n> If possible we should also aggregate `fxa_services_used` and then update it using `$postInsert` as [documented here](https://help.amplitude.com/hc/en-us/articles/205406617-Identify-API-Modify-User-Properties). Although :jbuck & :_6a68 - this `postInsert` function is only available using the identify API - would that be a problem for us?\n\nWe will be using what they call a \"vacuum\", which is essentially an uploaded CSV they they import. I'm not sure offhand what they do/do not support w.r.t. user properties, but we can request they make `$postInsert` available there. When we reach out about creating this vacuum we can ask about those options.\n\n> Ideally we would also do something similar for `OS`, `Language`, `Country` but reading between the lines [here](https://help.amplitude.com/hc/en-us/articles/204771828-HTTP-API) it doesn't appear we'll be able to do that, which is a shame. It means that we will no longer be able to use the activity events to know which e.g. OS users were active on in a given day, e.g. if they were active on both mobile and desktop. We can still use other events to answer these types of questions, but its not ideal. Maybe as a fast follow we could introduce a new event property like `os_used_on_day` or `activity_event_os_array` and set-aggregate like above.\n\nAre these questions that are already answered with the `cert_signed` ping? If so we don't want to lose them. I believe we can do exactly what you mentioned earlier - take the unique set of e.g. OS'.", "attachment_id": null, "text": "(In reply to Leif Oines [:loines] from comment #17)\n> I was too fast to submit my last comment:\n> \n> I think it would be useful to also aggregate the following user properties in a similar way:\n> \n> `sync_active_devices_*` (day, week, month), `sync_device_count`. \n\nLeif, are these user properties filled in currently from the `cert_signed` event? If so, we will indeed need to send those along with the events.\n\n> If possible we should also aggregate `fxa_services_used` and then update it using `$postInsert` as [documented here](https://help.amplitude.com/hc/en-us/articles/205406617-Identify-API-Modify-User-Properties). Although :jbuck & :_6a68 - this `postInsert` function is only available using the identify API - would that be a problem for us?\n\nWe will be using what they call a \"vacuum\", which is essentially an uploaded CSV they they import. I'm not sure offhand what they do/do not support w.r.t. user properties, but we can request they make `$postInsert` available there. When we reach out about creating this vacuum we can ask about those options.\n\n> Ideally we would also do something similar for `OS`, `Language`, `Country` but reading between the lines [here](https://help.amplitude.com/hc/en-us/articles/204771828-HTTP-API) it doesn't appear we'll be able to do that, which is a shame. It means that we will no longer be able to use the activity events to know which e.g. OS users were active on in a given day, e.g. if they were active on both mobile and desktop. We can still use other events to answer these types of questions, but its not ideal. Maybe as a fast follow we could introduce a new event property like `os_used_on_day` or `activity_event_os_array` and set-aggregate like above.\n\nAre these questions that are already answered with the `cert_signed` ping? If so we don't want to lose them. I believe we can do exactly what you mentioned earlier - take the unique set of e.g. OS'.", "count": 20, "creation_time": "2020-04-27T19:47:34Z"}, {"tags": [], "time": "2020-04-27T20:39:27Z", "creator": "loines@mozilla.com", "raw_text": "(In reply to Frank Bertsch [:frank] from comment #20)\n> (In reply to Leif Oines [:loines] from comment #17)\n\n> Leif, are these user properties filled in currently from the `cert_signed` event? If so, we will indeed need to send those along with the events.\n\n> Are these questions that are already answered with the `cert_signed` ping? If so we don't want to lose them. I believe we can do exactly what you mentioned earlier - take the unique set of e.g. OS'.\n\nYes, they are sent with the cert_signed event. You can use this [biguery query](\nhttps://console.cloud.google.com/bigquery?sq=630180991450:b1976978c4c84f70a5840e54a644ab70\n) as a reference for what is sent in the `event_properties` and `user_properties` fields. I believe the value for os is derived from the  `jsonPayload.fields.os_name` column. Country and Language are also there.\n\nEdit: Note that we are using `$append` for `fxa_services_used` here but we should really be using `$postInsert` per amplitude's advice (we just haven't made the change yet)", "creation_time": "2020-04-27T20:39:27Z", "count": 21, "is_private": false, "bug_id": 1632635, "attachment_id": null, "id": 14782527, "author": "loines@mozilla.com", "text": "(In reply to Frank Bertsch [:frank] from comment #20)\n> (In reply to Leif Oines [:loines] from comment #17)\n\n> Leif, are these user properties filled in currently from the `cert_signed` event? If so, we will indeed need to send those along with the events.\n\n> Are these questions that are already answered with the `cert_signed` ping? If so we don't want to lose them. I believe we can do exactly what you mentioned earlier - take the unique set of e.g. OS'.\n\nYes, they are sent with the cert_signed event. You can use this [biguery query](\nhttps://console.cloud.google.com/bigquery?sq=630180991450:b1976978c4c84f70a5840e54a644ab70\n) as a reference for what is sent in the `event_properties` and `user_properties` fields. I believe the value for os is derived from the  `jsonPayload.fields.os_name` column. Country and Language are also there.\n\nEdit: Note that we are using `$append` for `fxa_services_used` here but we should really be using `$postInsert` per amplitude's advice (we just haven't made the change yet)"}, {"raw_text": "> Ryan, do you have any context on the issues about making the HMAC key available to our Airflow instance?\n\n:jbuck will have better context on this than I do. My main question is, who has the ability to calculate HMACs using this key? (Which is a slightly different question to \"who has the ability to access this key?\"). The threats to be concerned about here are:\n\n* Given a raw FxA userid, who is able to calculate the corresponding hashed userid in amplitude?\n* Given a hashed userid from amplitude, who is able to try to brute-force-guess the corresponding raw FxA userid?\n\nIdeally the answer to both of these questions is \"only a restricted set of operational staff at Mozilla\". I've no objection to making that set bigger, but I wouldn't want to allow e.g. anyone at Mozilla to calculate HMACs using this key.\n\n> I believe there are some cases where a client might only generate the checked event on a given day, which would\n> cause them not to be counted towards DAU if we omit it. I will double check to see how often this happens\n\nThis definitely happens, because some of our OAuth tokens live for longer than 1 day. Including `checked` sounds valuable to me.\n\nMy opinions on aggregating services used etc are accurately represented by Leif's comments above, so I won't repeat any of it here apart from \"+1\".", "count": 22, "creation_time": "2020-04-27T22:40:54Z", "tags": [], "creator": "ryan@rfk.id.au", "time": "2020-04-27T22:40:54Z", "id": 14782795, "author": "ryan@rfk.id.au", "attachment_id": null, "text": "> Ryan, do you have any context on the issues about making the HMAC key available to our Airflow instance?\n\n:jbuck will have better context on this than I do. My main question is, who has the ability to calculate HMACs using this key? (Which is a slightly different question to \"who has the ability to access this key?\"). The threats to be concerned about here are:\n\n* Given a raw FxA userid, who is able to calculate the corresponding hashed userid in amplitude?\n* Given a hashed userid from amplitude, who is able to try to brute-force-guess the corresponding raw FxA userid?\n\nIdeally the answer to both of these questions is \"only a restricted set of operational staff at Mozilla\". I've no objection to making that set bigger, but I wouldn't want to allow e.g. anyone at Mozilla to calculate HMACs using this key.\n\n> I believe there are some cases where a client might only generate the checked event on a given day, which would\n> cause them not to be counted towards DAU if we omit it. I will double check to see how often this happens\n\nThis definitely happens, because some of our OAuth tokens live for longer than 1 day. Including `checked` sounds valuable to me.\n\nMy opinions on aggregating services used etc are accurately represented by Leif's comments above, so I won't repeat any of it here apart from \"+1\".", "is_private": false, "bug_id": 1632635}, {"raw_text": "Ryan, the usual path is we create a table that has the exact events we want to send to Amplitude. Currently that means anyone with access to Telemetry data will have access to both the unhashed and hashed userids; however no link between them. We could lock down the hashed userids table, if that would alleviate any issues on your end.\n\nThe HMAC should only be available to Airflow jobs and ops.", "attachment_id": null, "author": "fbertsch@mozilla.com", "id": 14782990, "creation_time": "2020-04-28T02:05:46Z", "count": 23, "text": "Ryan, the usual path is we create a table that has the exact events we want to send to Amplitude. Currently that means anyone with access to Telemetry data will have access to both the unhashed and hashed userids; however no link between them. We could lock down the hashed userids table, if that would alleviate any issues on your end.\n\nThe HMAC should only be available to Airflow jobs and ops.", "tags": [], "is_private": false, "bug_id": 1632635, "time": "2020-04-28T02:05:46Z", "creator": "fbertsch@mozilla.com"}, {"bug_id": 1632635, "is_private": false, "tags": [], "creator": "ryan@rfk.id.au", "time": "2020-04-28T03:23:20Z", "id": 14783032, "author": "ryan@rfk.id.au", "attachment_id": null, "raw_text": "> We could lock down the hashed userids table, if that would alleviate any issues on your end.\n\nIf this is feasible to lock down that table, please do so. Thanks!", "count": 24, "text": "> We could lock down the hashed userids table, if that would alleviate any issues on your end.\n\nIf this is feasible to lock down that table, please do so. Thanks!", "creation_time": "2020-04-28T03:23:20Z"}, {"tags": [], "time": "2020-04-28T13:50:55Z", "creator": "jklukas@mozilla.com", "raw_text": "> Currently that means anyone with access to Telemetry data will have access to both the unhashed and hashed userids\n\nUnhashed FxA user IDs _do not_ exist anywhere in telemetry data. The existing imports of FxA data that we do via Airflow read from fxa-prod project (which has the unhashed IDs) but [hash the IDs as part of the query](https://github.com/mozilla/bigquery-etl/blob/6c7eed5b09ba5f9f6adc4cdce554b0572b6dad7f/sql/telemetry/fxa_auth_events_v1/query.sql#L12) so that the resulting tables that live in the `shared-prod` project do not contain raw FxA IDs.\n\nHMAC-hashed FxA UIDs already exist in `shared-prod` as they are passed in the `sync` ping (it's unclear whether these are hashed with the same key as the events sent to Amplitude).\n\nSo, I don't see any issue with telemetry users having access to the HMAC-hashed UIDs.", "count": 25, "creation_time": "2020-04-28T13:50:55Z", "is_private": false, "bug_id": 1632635, "author": "jklukas@mozilla.com", "id": 14783853, "attachment_id": null, "text": "> Currently that means anyone with access to Telemetry data will have access to both the unhashed and hashed userids\n\nUnhashed FxA user IDs _do not_ exist anywhere in telemetry data. The existing imports of FxA data that we do via Airflow read from fxa-prod project (which has the unhashed IDs) but [hash the IDs as part of the query](https://github.com/mozilla/bigquery-etl/blob/6c7eed5b09ba5f9f6adc4cdce554b0572b6dad7f/sql/telemetry/fxa_auth_events_v1/query.sql#L12) so that the resulting tables that live in the `shared-prod` project do not contain raw FxA IDs.\n\nHMAC-hashed FxA UIDs already exist in `shared-prod` as they are passed in the `sync` ping (it's unclear whether these are hashed with the same key as the events sent to Amplitude).\n\nSo, I don't see any issue with telemetry users having access to the HMAC-hashed UIDs."}, {"is_private": false, "bug_id": 1632635, "id": 14783893, "author": "fbertsch@mozilla.com", "attachment_id": null, "text": "> Unhashed FxA user IDs _do not_ exist anywhere in telemetry data. The existing imports of FxA data that we do via Airflow read from fxa-prod project (which has the unhashed IDs) but [hash the IDs as part of the query](https://github.com/mozilla/bigquery-etl/blob/6c7eed5b09ba5f9f6adc4cdce554b0572b6dad7f/sql/telemetry/fxa_auth_events_v1/query.sql#L12) so that the resulting tables that live in the `shared-prod` project do not contain raw FxA IDs.\n\nThanks for clarifying that, Jeff. This also means we can't use those tables for the Amplitude import. Given this situation I agree that limiting access to the hashed data isn't a big concern.", "tags": [], "time": "2020-04-28T14:03:31Z", "creator": "fbertsch@mozilla.com", "raw_text": "> Unhashed FxA user IDs _do not_ exist anywhere in telemetry data. The existing imports of FxA data that we do via Airflow read from fxa-prod project (which has the unhashed IDs) but [hash the IDs as part of the query](https://github.com/mozilla/bigquery-etl/blob/6c7eed5b09ba5f9f6adc4cdce554b0572b6dad7f/sql/telemetry/fxa_auth_events_v1/query.sql#L12) so that the resulting tables that live in the `shared-prod` project do not contain raw FxA IDs.\n\nThanks for clarifying that, Jeff. This also means we can't use those tables for the Amplitude import. Given this situation I agree that limiting access to the hashed data isn't a big concern.", "count": 26, "creation_time": "2020-04-28T14:03:31Z"}, {"time": "2020-04-28T20:58:41Z", "creator": "loines@mozilla.com", "tags": [], "count": 27, "creation_time": "2020-04-28T20:58:41Z", "raw_text": "Frank and I met today and I agreed to provide a spec for how we should 1. aggregate the user and event properties for the rollup event 2. which operations we should use when sending the event to amplitude. Here goes\n\n\n\n\n|  name |event or user property   | aggregation  |  special amplitude operation (if needed) |\n|---|---|---|---|\n| service  |event   |array   |none   |\n|oauth_client_id   |event   |array   |none   |\n|fxa_services_used  |user   |array   |$postInsert  (we are changing this from $append) |\n| sync_device_count  |user   | max  | none  |\n| sync_active_devices_day  |user   | max  | none  |\n| sync_active_devices_week  |user   | max  | none  |\n| sync_active_devices_month  |user   | max  | none  |\n| OS (os_name in the logs)*|user   |~array, if possible~ mode   |none   |\n| OS Version (os_version in the logs)*|user   |~array, if possible~ mode   |none   |\n| Language*  |user   |mode   |none   |\n|ua_version   |user   | ~array~ mode  | none |\n|ua_browser   |user   |~array~ mode   | none |\n|Version (app_version in the logs, this is the version of the FxA server)   |user   |max  |none   |\n|Country and Region*|user   |~array~ mode   | none |\n\nedited to reflect comments below.\n\n*I'm unsure if we can actually send these properties to amplitude as arrays. lmk if that ends up being a problem. i guess if we can use mode if we don't have much of a choice.\n\nI think that's all of the properties that are relevant to the `fxa_activity - *` events. As I said, we should work under the assumption that all event types can take all of these properties, even if that's not true at the moment (many of them will sometimes be null). I also believe that if you don't specify an operation then it defaults to `$set`, which is what we want, but maybe we should verify that.", "bug_id": 1632635, "is_private": false, "text": "Frank and I met today and I agreed to provide a spec for how we should 1. aggregate the user and event properties for the rollup event 2. which operations we should use when sending the event to amplitude. Here goes\n\n\n\n\n|  name |event or user property   | aggregation  |  special amplitude operation (if needed) |\n|---|---|---|---|\n| service  |event   |array   |none   |\n|oauth_client_id   |event   |array   |none   |\n|fxa_services_used  |user   |array   |$postInsert  (we are changing this from $append) |\n| sync_device_count  |user   | max  | none  |\n| sync_active_devices_day  |user   | max  | none  |\n| sync_active_devices_week  |user   | max  | none  |\n| sync_active_devices_month  |user   | max  | none  |\n| OS (os_name in the logs)*|user   |~array, if possible~ mode   |none   |\n| OS Version (os_version in the logs)*|user   |~array, if possible~ mode   |none   |\n| Language*  |user   |mode   |none   |\n|ua_version   |user   | ~array~ mode  | none |\n|ua_browser   |user   |~array~ mode   | none |\n|Version (app_version in the logs, this is the version of the FxA server)   |user   |max  |none   |\n|Country and Region*|user   |~array~ mode   | none |\n\nedited to reflect comments below.\n\n*I'm unsure if we can actually send these properties to amplitude as arrays. lmk if that ends up being a problem. i guess if we can use mode if we don't have much of a choice.\n\nI think that's all of the properties that are relevant to the `fxa_activity - *` events. As I said, we should work under the assumption that all event types can take all of these properties, even if that's not true at the moment (many of them will sometimes be null). I also believe that if you don't specify an operation then it defaults to `$set`, which is what we want, but maybe we should verify that.", "author": "loines@mozilla.com", "id": 14784974, "attachment_id": null}, {"raw_text": "Thanks for providing that list, Leif. What is currently done for `os`, `os_version`, `language`, and `country`/`region`? Are they currently just set as the latest value from that user?", "creation_time": "2020-04-28T21:13:55Z", "count": 28, "tags": [], "time": "2020-04-28T21:13:55Z", "creator": "fbertsch@mozilla.com", "attachment_id": null, "author": "fbertsch@mozilla.com", "id": 14785003, "text": "Thanks for providing that list, Leif. What is currently done for `os`, `os_version`, `language`, and `country`/`region`? Are they currently just set as the latest value from that user?", "is_private": false, "bug_id": 1632635}, {"attachment_id": null, "raw_text": "Yes they are. So i suppose you're right, it doesn't makes sense to send those as an array. Amplitude does the magic of pulling the correct value for the time interval of your chart. Since we are sending just one event per day now, there will be no way to establish multiple values of those properties per user. I guess that means we use mode for those. I'll edit my chart to reflect this.", "id": 14785028, "author": "loines@mozilla.com", "creation_time": "2020-04-28T21:24:26Z", "text": "Yes they are. So i suppose you're right, it doesn't makes sense to send those as an array. Amplitude does the magic of pulling the correct value for the time interval of your chart. Since we are sending just one event per day now, there will be no way to establish multiple values of those properties per user. I guess that means we use mode for those. I'll edit my chart to reflect this.", "count": 29, "tags": [], "is_private": false, "bug_id": 1632635, "creator": "loines@mozilla.com", "time": "2020-04-28T21:24:26Z"}, {"bug_id": 1632635, "is_private": false, "text": "Leif, why don't we add an array version of said fields as well? We can use the set append operation.", "attachment_id": null, "author": "fbertsch@mozilla.com", "id": 14785082, "creator": "fbertsch@mozilla.com", "time": "2020-04-28T21:52:29Z", "tags": [], "creation_time": "2020-04-28T21:52:29Z", "count": 30, "raw_text": "Leif, why don't we add an array version of said fields as well? We can use the set append operation."}, {"tags": [], "time": "2020-04-28T22:47:13Z", "creator": "loines@mozilla.com", "raw_text": "That works for me. Could be something along the lines of e.g. `os_used_day`", "count": 31, "creation_time": "2020-04-28T22:47:13Z", "bug_id": 1632635, "is_private": false, "id": 14785209, "author": "loines@mozilla.com", "attachment_id": null, "text": "That works for me. Could be something along the lines of e.g. `os_used_day`"}, {"attachment_id": null, "raw_text": "I've gotten confirmation from Amplitude that we can use the entire identity API capabilities with the vacuum ingestion system, so the above user props should be no issue. Here's what's left to do:\n- :jbuck to give :hwoo the HMAC key, who will make it available to Airflow jobs\n- :frank to write the export job for events and user properties\n- Amplitude needs to add that vacuum endpoint to the FxA project\n\nIt will be good to first test this on the dev FxA project.", "id": 14786631, "author": "fbertsch@mozilla.com", "creation_time": "2020-04-29T16:59:16Z", "text": "I've gotten confirmation from Amplitude that we can use the entire identity API capabilities with the vacuum ingestion system, so the above user props should be no issue. Here's what's left to do:\n- :jbuck to give :hwoo the HMAC key, who will make it available to Airflow jobs\n- :frank to write the export job for events and user properties\n- Amplitude needs to add that vacuum endpoint to the FxA project\n\nIt will be good to first test this on the dev FxA project.", "count": 32, "tags": [], "bug_id": 1632635, "is_private": false, "creator": "fbertsch@mozilla.com", "time": "2020-04-29T16:59:16Z"}, {"bug_id": 1632635, "is_private": false, "attachment_id": null, "id": 14786747, "author": "jbuckley@mozilla.com", "text": "I have sent the HMAC keys for stage and prod to :hwoo", "tags": [], "time": "2020-04-29T17:45:22Z", "creator": "jbuckley@mozilla.com", "raw_text": "I have sent the HMAC keys for stage and prod to :hwoo", "creation_time": "2020-04-29T17:45:22Z", "count": 33}, {"is_private": false, "bug_id": 1632635, "tags": [], "time": "2020-04-29T19:33:09Z", "creator": "hwoo@mozilla.com", "author": "hwoo@mozilla.com", "id": 14786975, "raw_text": "added to airflow vars as fxa_amplitude_hmac_secret_key_*", "attachment_id": null, "count": 34, "text": "added to airflow vars as fxa_amplitude_hmac_secret_key_*", "creation_time": "2020-04-29T19:33:09Z"}, {"tags": [], "creator": "fbertsch@mozilla.com", "time": "2020-04-29T20:28:31Z", "raw_text": "Draft PR for what we'd be exporting to Amplitude is [available here](https://github.com/mozilla/bigquery-etl/pull/941).", "creation_time": "2020-04-29T20:28:31Z", "count": 35, "bug_id": 1632635, "is_private": false, "attachment_id": null, "id": 14787097, "author": "fbertsch@mozilla.com", "text": "Draft PR for what we'd be exporting to Amplitude is [available here](https://github.com/mozilla/bigquery-etl/pull/941)."}, {"raw_text": "I'm noticing what may be surprises, and I want to check in with the FxA folks:\n\nRyan:\n~6.6% of user don't report any `cert_signed` events, but do report a `access_token_checked` or `access_token_created`. Is this expected? I was under the impression that right now all users were sending `cert_signed`. Are these users counted in Amplitude through some other event?\n\nLeif:\nOf the users with no `cert_signed` events, their `user_properties` are missing all fields except `fxa_services_used`. Any idea how we want to handle this? Should we try and get this added? For now we could send `null` for those properties.", "creation_time": "2020-05-04T14:30:55Z", "count": 36, "tags": [], "time": "2020-05-04T14:30:55Z", "creator": "fbertsch@mozilla.com", "attachment_id": null, "id": 14795863, "author": "fbertsch@mozilla.com", "text": "I'm noticing what may be surprises, and I want to check in with the FxA folks:\n\nRyan:\n~6.6% of user don't report any `cert_signed` events, but do report a `access_token_checked` or `access_token_created`. Is this expected? I was under the impression that right now all users were sending `cert_signed`. Are these users counted in Amplitude through some other event?\n\nLeif:\nOf the users with no `cert_signed` events, their `user_properties` are missing all fields except `fxa_services_used`. Any idea how we want to handle this? Should we try and get this added? For now we could send `null` for those properties.", "bug_id": 1632635, "is_private": false}, {"author": "loines@mozilla.com", "id": 14795936, "raw_text": "Its definitely NOT the case that all users will generate cert signed. Users of Sync and maybe a small number of other services do, but the rest will generate only the oauth `access_token` events. For the purposes of MAU/DAU we count users who generate ANY `fxa_activity - *` event (there is a \"derived\" event within amplitude that lumps all of these together).\n\nNot all of the user properties make sense for services that generate the `access_token` events. For example, if a user uses monitor and NOT sync, the `sync_active_devices` properties should not be set at all (this is only a property of sync users). Once `cert_signed` goes away however, FxA WILL need to migrate those sync-specific user properties to be set by the `access_token` events. So for now, I think we should allow either event type to set the properties, but also allow the properties to be null (if we don't set the property for a given event, amplitude will continue to use the most recent value for that property, which is fine).", "attachment_id": null, "text": "Its definitely NOT the case that all users will generate cert signed. Users of Sync and maybe a small number of other services do, but the rest will generate only the oauth `access_token` events. For the purposes of MAU/DAU we count users who generate ANY `fxa_activity - *` event (there is a \"derived\" event within amplitude that lumps all of these together).\n\nNot all of the user properties make sense for services that generate the `access_token` events. For example, if a user uses monitor and NOT sync, the `sync_active_devices` properties should not be set at all (this is only a property of sync users). Once `cert_signed` goes away however, FxA WILL need to migrate those sync-specific user properties to be set by the `access_token` events. So for now, I think we should allow either event type to set the properties, but also allow the properties to be null (if we don't set the property for a given event, amplitude will continue to use the most recent value for that property, which is fine).", "count": 37, "creation_time": "2020-05-04T15:09:21Z", "bug_id": 1632635, "is_private": false, "tags": [], "creator": "loines@mozilla.com", "time": "2020-05-04T15:09:21Z"}, {"tags": [], "creator": "ryan@rfk.id.au", "time": "2020-05-04T20:29:25Z", "raw_text": "> ~6.6% of user don't report any cert_signed events, but do report a access_token_checked or access_token_created. Is this expected?\n\nThis sounds about right to be (assuming that it's looking at all users from all FxA-related products, many of which don't generate any `cert_signed` events).", "creation_time": "2020-05-04T20:29:25Z", "count": 38, "is_private": false, "bug_id": 1632635, "attachment_id": null, "author": "ryan@rfk.id.au", "id": 14796524, "text": "> ~6.6% of user don't report any cert_signed events, but do report a access_token_checked or access_token_created. Is this expected?\n\nThis sounds about right to be (assuming that it's looking at all users from all FxA-related products, many of which don't generate any `cert_signed` events)."}, {"creation_time": "2020-05-06T21:30:24Z", "text": "Hi all, we've successfully launched the pipeline and I am testing data in the `FxAccts_Dev` project. I will be loading one day of `fxa_activity - active` and `$identify` events. I've noticed the client count numbers may end up being slightly higher than what we're currently seeing in Amplitude, so we may need to take a look at which events are causing that.\n\nIn addition to the fields that Leif laid out in comment 27, we've added `os_used_week` and `os_used_month`. These are aggregated on our end, and it is straightforward to add more user properties that are aggregated in a similar way across various time periods.", "count": 39, "attachment_id": null, "raw_text": "Hi all, we've successfully launched the pipeline and I am testing data in the `FxAccts_Dev` project. I will be loading one day of `fxa_activity - active` and `$identify` events. I've noticed the client count numbers may end up being slightly higher than what we're currently seeing in Amplitude, so we may need to take a look at which events are causing that.\n\nIn addition to the fields that Leif laid out in comment 27, we've added `os_used_week` and `os_used_month`. These are aggregated on our end, and it is straightforward to add more user properties that are aggregated in a similar way across various time periods.", "author": "fbertsch@mozilla.com", "id": 14801366, "time": "2020-05-06T21:30:24Z", "creator": "fbertsch@mozilla.com", "tags": [], "is_private": false, "bug_id": 1632635}, {"tags": [], "creator": "loines@mozilla.com", "time": "2020-05-07T17:06:13Z", "raw_text": "", "count": 40, "creation_time": "2020-05-07T17:06:13Z", "bug_id": 1632635, "is_private": false, "id": 14802954, "author": "loines@mozilla.com", "attachment_id": 9146505, "text": "Created attachment 9146505\nScreen Shot 2020-05-07 at 10.37.44 AM.png"}, {"creation_time": "2020-05-07T17:06:25Z", "count": 41, "raw_text": "Thanks so much for all your work on this Frank, here's what I'm noticing:\n\n1. The \"official\" amplitude user properties except for User ID (see attached screenshot to see what I'm referring to) are null. However I am seeing non-null values for custom event properties `LANGUAGE` , `country` , `app_version` (the latter looks like we should just use the official `Version` property). I am also seeing `user_country`, `user_locale` etc but they are all null. For user properties that we are not using array-agg on, is it possible to start using the \"official\" versions?\n\n2. I'm also seeing user properties `fxa_uid`, `fxa_uid.data` and `fxa_uid.type`, I'm not sure what those are (possibly some of these properties are just an artifact of your testing in which case feel free to ignore me).\n\n3. The aggregated `os_used` and `sync_devices_used`, `fxa_services_used` properties seem to be working, great!\n\n4. I queried the auth server logs for 2020-04-23 for COUNT(DISTINCT user_id) and got a number that was 1.08% higher than amplitude is showing. I cast the timezone to be PDT to match what amplitude uses. PM me on slack if you want the query/raw numbers. Unsure how I would follow up on this though, maybe you have ideas.", "time": "2020-05-07T17:06:25Z", "creator": "loines@mozilla.com", "tags": [], "text": "Thanks so much for all your work on this Frank, here's what I'm noticing:\n\n1. The \"official\" amplitude user properties except for User ID (see attached screenshot to see what I'm referring to) are null. However I am seeing non-null values for custom event properties `LANGUAGE` , `country` , `app_version` (the latter looks like we should just use the official `Version` property). I am also seeing `user_country`, `user_locale` etc but they are all null. For user properties that we are not using array-agg on, is it possible to start using the \"official\" versions?\n\n2. I'm also seeing user properties `fxa_uid`, `fxa_uid.data` and `fxa_uid.type`, I'm not sure what those are (possibly some of these properties are just an artifact of your testing in which case feel free to ignore me).\n\n3. The aggregated `os_used` and `sync_devices_used`, `fxa_services_used` properties seem to be working, great!\n\n4. I queried the auth server logs for 2020-04-23 for COUNT(DISTINCT user_id) and got a number that was 1.08% higher than amplitude is showing. I cast the timezone to be PDT to match what amplitude uses. PM me on slack if you want the query/raw numbers. Unsure how I would follow up on this though, maybe you have ideas.", "attachment_id": null, "author": "loines@mozilla.com", "id": 14802955, "is_private": false, "bug_id": 1632635}, {"creator": "jklukas@mozilla.com", "time": "2020-05-07T17:58:54Z", "bug_id": 1632635, "is_private": false, "tags": [], "count": 42, "text": "Note that I'm having the same problem with custom vs. \"official\" properties right now in trying to implement sync send_tab events. I'm chatting with Amplitude folks and we can hopefully apply the same solution there and here.", "creation_time": "2020-05-07T17:58:54Z", "id": 14803081, "author": "jklukas@mozilla.com", "raw_text": "Note that I'm having the same problem with custom vs. \"official\" properties right now in trying to implement sync send_tab events. I'm chatting with Amplitude folks and we can hopefully apply the same solution there and here.", "attachment_id": null}, {"bug_id": 1632635, "is_private": false, "text": "> 1. The \"official\" amplitude user properties except for User ID (see attached screenshot to see what I'm referring to) are null. However I am seeing non-null values for custom event properties `LANGUAGE` , `country` , `app_version` (the latter looks like we should just use the official `Version` property). I am also seeing `user_country`, `user_locale` etc but they are all null. For user properties that we are not using array-agg on, is it possible to start using the \"official\" versions?\n\nLet's see what happens with the other import, but we should be able to move those to top-level columns as we do for e.g. the Fenix import to get them available.\n\n> 2. I'm also seeing user properties `fxa_uid`, `fxa_uid.data` and `fxa_uid.type`, I'm not sure what those are (possibly some of these properties are just an artifact of your testing in which case feel free to ignore me).\n\nI bet those are from some historical data in `FxAccts_Dev`. Do they have the associated `fxa_activity - active` events?\n\n> 3. The aggregated `os_used` and `sync_devices_used`, `fxa_services_used` properties seem to be working, great!\n\nGreat!\n\n> 4. I queried the auth server logs for 2020-04-23 for COUNT(DISTINCT user_id) and got a number that was 1.08% higher than amplitude is showing. I cast the timezone to be PDT to match what amplitude uses. PM me on slack if you want the query/raw numbers. Unsure how I would follow up on this though, maybe you have ideas.\n\nThere may be something odd going on around timestamps. I use a UTC 00:00:00 timestamp to load the data, it looks like I should be using a PDT one? That may help make the data match.", "id": 14803253, "author": "fbertsch@mozilla.com", "attachment_id": null, "time": "2020-05-07T19:06:03Z", "creator": "fbertsch@mozilla.com", "tags": [], "count": 43, "creation_time": "2020-05-07T19:06:03Z", "raw_text": "> 1. The \"official\" amplitude user properties except for User ID (see attached screenshot to see what I'm referring to) are null. However I am seeing non-null values for custom event properties `LANGUAGE` , `country` , `app_version` (the latter looks like we should just use the official `Version` property). I am also seeing `user_country`, `user_locale` etc but they are all null. For user properties that we are not using array-agg on, is it possible to start using the \"official\" versions?\n\nLet's see what happens with the other import, but we should be able to move those to top-level columns as we do for e.g. the Fenix import to get them available.\n\n> 2. I'm also seeing user properties `fxa_uid`, `fxa_uid.data` and `fxa_uid.type`, I'm not sure what those are (possibly some of these properties are just an artifact of your testing in which case feel free to ignore me).\n\nI bet those are from some historical data in `FxAccts_Dev`. Do they have the associated `fxa_activity - active` events?\n\n> 3. The aggregated `os_used` and `sync_devices_used`, `fxa_services_used` properties seem to be working, great!\n\nGreat!\n\n> 4. I queried the auth server logs for 2020-04-23 for COUNT(DISTINCT user_id) and got a number that was 1.08% higher than amplitude is showing. I cast the timezone to be PDT to match what amplitude uses. PM me on slack if you want the query/raw numbers. Unsure how I would follow up on this though, maybe you have ideas.\n\nThere may be something odd going on around timestamps. I use a UTC 00:00:00 timestamp to load the data, it looks like I should be using a PDT one? That may help make the data match."}, {"bug_id": 1632635, "is_private": false, "tags": [], "time": "2020-05-07T19:32:51Z", "creator": "loines@mozilla.com", "id": 14803334, "author": "loines@mozilla.com", "attachment_id": null, "raw_text": "(In reply to Frank Bertsch [:frank] from comment #43)\n\n> I bet those are from some historical data in `FxAccts_Dev`. Do they have the associated `fxa_activity - active` events?\n\nAh yep, I think that's right.\n\n> There may be something odd going on around timestamps. I use a UTC 00:00:00 timestamp to load the data, it looks like I should be using a PDT one? That may help make the data match.\n\nActually, maybe what happened here is that you loaded the data from 2020-04-24 relative to UTC, timestamped it as 2020-04-24:00:00:00 but that ended up getting shifted to 2020-04-23:17:00:00 when displayed in amplitude, since the FxA project is set to be relative to PDT (I wish we would change this tbh, but I think too many people are used to it now). When I look at the numbers from the 24th relative to utc from the server logs, I get a closer number off only by +0.008% which I think would be good enough for government work.", "text": "(In reply to Frank Bertsch [:frank] from comment #43)\n\n> I bet those are from some historical data in `FxAccts_Dev`. Do they have the associated `fxa_activity - active` events?\n\nAh yep, I think that's right.\n\n> There may be something odd going on around timestamps. I use a UTC 00:00:00 timestamp to load the data, it looks like I should be using a PDT one? That may help make the data match.\n\nActually, maybe what happened here is that you loaded the data from 2020-04-24 relative to UTC, timestamped it as 2020-04-24:00:00:00 but that ended up getting shifted to 2020-04-23:17:00:00 when displayed in amplitude, since the FxA project is set to be relative to PDT (I wish we would change this tbh, but I think too many people are used to it now). When I look at the numbers from the 24th relative to utc from the server logs, I get a closer number off only by +0.008% which I think would be good enough for government work.", "count": 44, "creation_time": "2020-05-07T19:32:51Z"}, {"tags": [], "is_private": false, "bug_id": 1632635, "creator": "fbertsch@mozilla.com", "time": "2020-05-08T14:18:09Z", "raw_text": "Hey all, we fixed the tz offset and the data is now loaded in the correct day. Amplitude has confirmed that we need top-level properties for their \"official\" user properties, so we'll update that and then do a small test against prod, to confirm that user ids are matching. I'm planning on sending just a few users (O(10)) to prod to see that they already exist there. If that works, we should be good to open the gates on the new events and deprecate the `cert_signed` and co. events.", "attachment_id": null, "id": 14804728, "author": "fbertsch@mozilla.com", "creation_time": "2020-05-08T14:18:09Z", "text": "Hey all, we fixed the tz offset and the data is now loaded in the correct day. Amplitude has confirmed that we need top-level properties for their \"official\" user properties, so we'll update that and then do a small test against prod, to confirm that user ids are matching. I'm planning on sending just a few users (O(10)) to prod to see that they already exist there. If that works, we should be good to open the gates on the new events and deprecate the `cert_signed` and co. events.", "count": 45}, {"creator": "pulgasaur@mozilla.bugs", "time": "2020-05-08T18:26:04Z", "tags": [], "count": 46, "creation_time": "2020-05-08T18:26:04Z", "raw_text": "", "bug_id": 1632635, "is_private": false, "text": "Created attachment 9146867\nLink to GitHub pull-request: https://github.com/mozilla/bigquery-etl/pull/968", "author": "pulgasaur@mozilla.bugs", "id": 14805282, "attachment_id": 9146867}, {"creation_time": "2020-05-11T15:51:54Z", "count": 47, "text": "Created attachment 9147302\nLink to GitHub pull-request: https://github.com/mozilla/bigquery-etl/pull/972", "attachment_id": 9147302, "raw_text": "", "id": 14809852, "author": "pulgasaur@mozilla.bugs", "time": "2020-05-11T15:51:54Z", "creator": "pulgasaur@mozilla.bugs", "tags": [], "bug_id": 1632635, "is_private": false}, {"raw_text": "Still waiting on final verification from Amplitude about the `version` top-level field. Until then we've also updated our ETL to use pacific-based days rather than UTC. I'll need to backfill the dataset and then test against the FxA Dev project again. Once we're happy with those we'll be ready to send these events to prod.", "count": 48, "creation_time": "2020-05-11T20:04:08Z", "tags": [], "creator": "fbertsch@mozilla.com", "time": "2020-05-11T20:04:08Z", "author": "fbertsch@mozilla.com", "id": 14810550, "attachment_id": null, "text": "Still waiting on final verification from Amplitude about the `version` top-level field. Until then we've also updated our ETL to use pacific-based days rather than UTC. I'll need to backfill the dataset and then test against the FxA Dev project again. Once we're happy with those we'll be ready to send these events to prod.", "bug_id": 1632635, "is_private": false}, {"tags": [], "time": "2020-05-13T17:05:32Z", "creator": "fbertsch@mozilla.com", "raw_text": "We have updated the config and successfully added the Amplitude `version` property. We are ready to ingest into prod.", "creation_time": "2020-05-13T17:05:32Z", "count": 49, "is_private": false, "bug_id": 1632635, "attachment_id": null, "id": 14817203, "author": "fbertsch@mozilla.com", "text": "We have updated the config and successfully added the Amplitude `version` property. We are ready to ingest into prod."}, {"is_private": false, "bug_id": 1632635, "tags": [], "time": "2020-05-14T13:38:59Z", "creator": "fbertsch@mozilla.com", "id": 14819363, "author": "fbertsch@mozilla.com", "raw_text": "We've deployed the change to prod and we are currently ingesting both the new `fxa_activity - active` event, as well as the old events we will be replacing. We have two days of data in, an initial comparison can be found [here](https://analytics.amplitude.com/mozilla-corp/chart/7lpzpie).", "attachment_id": null, "text": "We've deployed the change to prod and we are currently ingesting both the new `fxa_activity - active` event, as well as the old events we will be replacing. We have two days of data in, an initial comparison can be found [here](https://analytics.amplitude.com/mozilla-corp/chart/7lpzpie).", "count": 50, "creation_time": "2020-05-14T13:38:59Z"}, {"time": "2020-05-14T14:56:22Z", "creator": "fbertsch@mozilla.com", "bug_id": 1632635, "is_private": false, "tags": [], "count": 51, "text": "Alex, Leif, I want to get sign-off from you both before we pull the plug on the `cert_signed` and oauth `access_token` events. If you have any questions or run into issues, let me know.", "creation_time": "2020-05-14T14:56:22Z", "author": "fbertsch@mozilla.com", "id": 14819520, "raw_text": "Alex, Leif, I want to get sign-off from you both before we pull the plug on the `cert_signed` and oauth `access_token` events. If you have any questions or run into issues, let me know.", "attachment_id": null}, {"is_private": false, "bug_id": 1632635, "attachment_id": null, "author": "loines@mozilla.com", "id": 14820185, "text": "Looking good to me so far. I was thinking of maybe keeping the old events through the weekend to see if the weekend dip in DAU was substantially different from what we'd seen in the past, but maybe that's not necessary. If alex is ok with pulling the plug on the old events earlier then that's fine with me.\n\nFrank, it was my understanding that FxA (:jbuck) would have to do this? Or were you going to do it on your end? Doesn't matter who does it, just want to make sure we're on the same page.", "tags": [], "creator": "loines@mozilla.com", "time": "2020-05-14T16:29:04Z", "raw_text": "Looking good to me so far. I was thinking of maybe keeping the old events through the weekend to see if the weekend dip in DAU was substantially different from what we'd seen in the past, but maybe that's not necessary. If alex is ok with pulling the plug on the old events earlier then that's fine with me.\n\nFrank, it was my understanding that FxA (:jbuck) would have to do this? Or were you going to do it on your end? Doesn't matter who does it, just want to make sure we're on the same page.", "creation_time": "2020-05-14T16:29:04Z", "count": 52}, {"text": "> Frank, it was my understanding that FxA (:jbuck) would have to do this? Or were you going to do it on your end? Doesn't matter who does it, just want to make sure we're on the same page.\n\nYou are correct, :jbuck will need to turn them off. He indicated it's fast and easy on his end, probably updating that config you pointed me to.", "attachment_id": null, "id": 14820267, "author": "fbertsch@mozilla.com", "bug_id": 1632635, "is_private": false, "creation_time": "2020-05-14T16:42:14Z", "count": 53, "raw_text": "> Frank, it was my understanding that FxA (:jbuck) would have to do this? Or were you going to do it on your end? Doesn't matter who does it, just want to make sure we're on the same page.\n\nYou are correct, :jbuck will need to turn them off. He indicated it's fast and easy on his end, probably updating that config you pointed me to.", "time": "2020-05-14T16:42:14Z", "creator": "fbertsch@mozilla.com", "tags": []}, {"bug_id": 1632635, "is_private": false, "id": 14820274, "author": "fbertsch@mozilla.com", "attachment_id": null, "text": "Leif, if you and Alex are okay with turning off the old events sooner rather than later, we can always do future comparison analysis on the BQ data. If there is a serious issue we can also backfill.", "tags": [], "time": "2020-05-14T16:43:23Z", "creator": "fbertsch@mozilla.com", "raw_text": "Leif, if you and Alex are okay with turning off the old events sooner rather than later, we can always do future comparison analysis on the BQ data. If there is a serious issue we can also backfill.", "count": 54, "creation_time": "2020-05-14T16:43:23Z"}, {"raw_text": "Let's go ahead and turn off the old events. Things look good on my end and I think they looked good to alex yesterday.", "creation_time": "2020-05-15T15:57:45Z", "count": 55, "tags": [], "creator": "loines@mozilla.com", "time": "2020-05-15T15:57:45Z", "attachment_id": null, "author": "loines@mozilla.com", "id": 14823112, "text": "Let's go ahead and turn off the old events. Things look good on my end and I think they looked good to alex yesterday.", "bug_id": 1632635, "is_private": false}, {"bug_id": 1632635, "is_private": false, "id": 14823116, "author": "fbertsch@mozilla.com", "attachment_id": null, "text": "Great. Jbuck, can you do the honors? We need to disable the \"fxa_activity - cert_signed\", \"fxa_activity - access_token_checked\", and \"fxa_activity - access_token_created\" events.", "tags": [], "time": "2020-05-15T15:59:05Z", "creator": "fbertsch@mozilla.com", "raw_text": "Great. Jbuck, can you do the honors? We need to disable the \"fxa_activity - cert_signed\", \"fxa_activity - access_token_checked\", and \"fxa_activity - access_token_created\" events.", "count": 56, "creation_time": "2020-05-15T15:59:05Z"}, {"creation_time": "2020-05-15T16:56:39Z", "count": 57, "raw_text": "New filter has been applied in production: https://github.com/mozilla-services/cloudops-infra/pull/2147", "creator": "jbuckley@mozilla.com", "time": "2020-05-15T16:56:39Z", "tags": [], "text": "New filter has been applied in production: https://github.com/mozilla-services/cloudops-infra/pull/2147", "attachment_id": null, "id": 14823251, "author": "jbuckley@mozilla.com", "bug_id": 1632635, "is_private": false}, {"attachment_id": null, "raw_text": "> New filter has been applied in production: https://github.com/mozilla-services/cloudops-infra/pull/2147\n\nWe can close this out! New events are flowed in daily and we've cut off the old ones.", "author": "fbertsch@mozilla.com", "id": 14823252, "creation_time": "2020-05-15T16:57:23Z", "count": 58, "text": "> New filter has been applied in production: https://github.com/mozilla-services/cloudops-infra/pull/2147\n\nWe can close this out! New events are flowed in daily and we've cut off the old ones.", "tags": [], "is_private": false, "bug_id": 1632635, "creator": "fbertsch@mozilla.com", "time": "2020-05-15T16:57:23Z"}, {"is_private": false, "bug_id": 1632635, "text": "Looking at the data in amplitude, I am a little concerned that we might not be de-duplicating these correctly: we have recorded a large number of `fxa_activity - active` events in the past 30 days. Reopening to investigate further", "author": "jhirsch@mozilla.com", "id": 14935442, "attachment_id": null, "creator": "jhirsch@mozilla.com", "time": "2020-07-13T22:20:02Z", "tags": [], "count": 59, "creation_time": "2020-07-13T22:20:02Z", "raw_text": "Looking at the data in amplitude, I am a little concerned that we might not be de-duplicating these correctly: we have recorded a large number of `fxa_activity - active` events in the past 30 days. Reopening to investigate further"}, {"is_private": false, "bug_id": 1632635, "text": "(In reply to Jared Hirsch [:_6a68] [:jhirsch] (Needinfo please) from comment #59)\n> Looking at the data in amplitude, I am a little concerned that we might not be de-duplicating these correctly: we have recorded a large number of `fxa_activity - active` events in the past 30 days. Reopening to investigate further\n\nCurrent event count looks correct for 1-event per-user per-day. Divide the total by 30 to get ~DAU for FxA. Let me know if I'm missing something.", "attachment_id": null, "author": "fbertsch@mozilla.com", "id": 14936626, "time": "2020-07-14T15:32:33Z", "creator": "fbertsch@mozilla.com", "tags": [], "creation_time": "2020-07-14T15:32:33Z", "count": 60, "raw_text": "(In reply to Jared Hirsch [:_6a68] [:jhirsch] (Needinfo please) from comment #59)\n> Looking at the data in amplitude, I am a little concerned that we might not be de-duplicating these correctly: we have recorded a large number of `fxa_activity - active` events in the past 30 days. Reopening to investigate further\n\nCurrent event count looks correct for 1-event per-user per-day. Divide the total by 30 to get ~DAU for FxA. Let me know if I'm missing something."}, {"tags": [], "time": "2020-07-14T17:23:22Z", "creator": "jhirsch@mozilla.com", "raw_text": "Cool, thanks :frank!", "count": 61, "creation_time": "2020-07-14T17:23:22Z", "bug_id": 1632635, "is_private": false, "id": 14937027, "author": "jhirsch@mozilla.com", "attachment_id": null, "text": "Cool, thanks :frank!"}, {"time": "2020-07-14T19:33:15Z", "creator": "alex@alexdavis.ca", "tags": [], "bug_id": 1632635, "is_private": false, "creation_time": "2020-07-14T19:33:15Z", "text": "If it helps, here are the total events I see in Amplitude. I see the drop:\nhttps://analytics.amplitude.com/mozilla-corp/chart/new/rtsvgi6", "count": 62, "raw_text": "If it helps, here are the total events I see in Amplitude. I see the drop:\nhttps://analytics.amplitude.com/mozilla-corp/chart/new/rtsvgi6", "attachment_id": null, "author": "alex@alexdavis.ca", "id": 14937319}, {"creator": "jhirsch@mozilla.com", "time": "2020-07-14T20:52:25Z", "tags": [], "creation_time": "2020-07-14T20:52:25Z", "count": 63, "raw_text": "That is indeed helpful. Thanks, Alex!", "is_private": false, "bug_id": 1632635, "text": "That is indeed helpful. Thanks, Alex!", "attachment_id": null, "author": "jhirsch@mozilla.com", "id": 14937457}]}}, "comments": {}}